{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN Reinforcement Learning on GYM Atari.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxzhaixiang/MachineLearning_demo/blob/master/DQN_Reinforcement_Learning_on_GYM_Atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQ8dw3q91LN",
        "colab_type": "text"
      },
      "source": [
        "# Deep-Q-Network (DQN) Learning on Breakout\n",
        "\n",
        "In this notebook, we will be training a Deep Q Network reinforcement learning model to play Breakout game using the OpenAI GYM game simulator.\n",
        "\n",
        "Breakout is an ideal game for DQN for several reasons\n",
        "\n",
        "- Breakout is deterministic. Given the state of the game (location and velocity of the ball), an optimal decision exists and it is not (that) stochastic. DQN, by its definition, aims to find a deterministic Q function given state and action. Thus DQN is ideal for games like Breakout.\n",
        "- The action space is, TINY. In fact, only left or right. This helps us to construct DQN in a very simple way: input is a vector of game state, and output is the Q value at each action.\n",
        "\n",
        "The Q network takes the screen output of the game (state) as input, and outputs the expected optimal Q value for each action.\n",
        "\n",
        "In this notebook, we will be using \"BreakoutNoFrameskip-v4\" environmnet. Without too much modification, the same workflow should work (almost) seamlessly for many other Atari games, such as Pong, etc. Note that DQN is more for deterministic strategy, so it is more suitable for games requiring fast action and little room to wonder around.\n",
        "\n",
        "After the DQN is trained with 10,000 episodes, it is able to achieve 300+ points!\n",
        "\n",
        "![DQN playing Breakout](https://raw.githubusercontent.com/zxzhaixiang/MachineLearning_demo/master/assets/BreakoutNoFrameskip-v4-4000-489frame_351.0.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yhcdlikck8-",
        "colab_type": "text"
      },
      "source": [
        "To keep Colab from timeout, Press F12 and paste the following JavaScript code the the console.\n",
        "\n",
        "```JavaScript\n",
        "ClickConnect(){\n",
        "    console.log(\"Working\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a0xunL8GJ_X",
        "colab_type": "text"
      },
      "source": [
        "# Colab Installs + Regular Imports\n",
        "If you're running this script outside of a notebook set Colab to 'False'\n",
        "gsync allows this notebook to save pretrained models directly to your Google Drive account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZCQ_tadt2Q1",
        "colab_type": "code",
        "outputId": "fc5063a8-7216-4720-defa-6eab0cb4cb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=f64f4f05420a4390983fa1e4b2a60a57978624c9812305eb74116c4e4872f325\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 156.4 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbNWFaHAEGBi",
        "colab_type": "code",
        "outputId": "81f07fc9-d93f-4be8-8a04-491ab28cceec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install torchviz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3 [783 kB]\n",
            "Fetched 783 kB in 1s (795 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.3_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/69/ec/8221a07850d69fa3c57c02e526edd23d18c7c05d58ed103e3b19172757c1/PyVirtualDisplay-0.2.5-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/63/57755fadd28c989d578862f1ed7995348ed666333e03cdab6f6ea3f26ab0/EasyProcess-0.2.8-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.8 pyvirtualdisplay-0.2.5\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.3.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.17.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=4a198d31e631c6f4f861e443bc776a3391561d6f91709839e2479e4999009608\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Amw1q8s_2vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colab PyTorch utilities\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "import gym\n",
        "import gym.spaces\n",
        "from torchsummary import summary\n",
        "from torchviz import make_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09pa4NBFugi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V19C0zuPAwff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0514368e-d36a-4860-b78c-ef58f60b60ec"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device is {}'.format(device))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_SWzWbBA0D3",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive to save/load model weights (Optional)\n",
        "It is time consuming to train reinforcement learning, even for such a simple game. Colab only gives us 12 hr of usage. Although it is enough for game like Breakout, we still want to save the model weight somewhere eles in case we want to do a hot restart. The simplest solution is to mount your google drive and save the model weight there. It is completely optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3WsPj1TA8_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab9c4d23-1d63-45ee-8192-ca4004eab87e"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsn1-3JxBC6M",
        "colab_type": "text"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6r-2pymBywK",
        "colab_type": "text"
      },
      "source": [
        "Parameters\n",
        "* REPLAY_SIZE: Maximum number of experiences stored in replay memory\n",
        "* TARGET_UPDATE_FREQ: How many frames in between syncing target DQN with behaviour DQN\n",
        "* LEARNING_STARTS: Number of experiences to add to replay memory before training network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bypK0vuqBIgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENV_NAME = \"PongNoFrameskip-v4\"\n",
        "ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
        "MODEL = \"BreakoutNoFrameskip-v4.dat\"\n",
        "GDRIVE_FOLDER = \"BreakoutModels\"\n",
        "\n",
        "MEAN_REWARD_BOUND = 50\n",
        "\n",
        "FRAME_SKIPPING = 8\n",
        "\n",
        "GAMMA = 0.95\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10 ** 5 * 2\n",
        "LEARNING_STARTS = 10**4 * 2\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "TARGET_UPDATE_FREQ = 10000\n",
        "\n",
        "EPSILON_DECAY = 10**5 * 5\n",
        "EPSILON_START = 0.9\n",
        "EPSILON_FINAL = 0.1\n",
        "\n",
        "MODEL_SAVE_STEP = 200 \n",
        "\n",
        "LOAD_MODEL_NAME = 'BreakoutNoFrameskip-v4-4400.dat' #set to null if cold start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_QwnCaBVz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_FOLDER = os.path.join('/content/drive/My Drive/',GDRIVE_FOLDER)\n",
        "if (not os.path.isdir(SAVE_FOLDER)):\n",
        "    os.mkdir(SAVE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpp316gJGXZp",
        "colab_type": "text"
      },
      "source": [
        "# OpenAI Gym Wrappers\n",
        "These wrappers make it easier to interact with OpenAI Gym\n",
        "\n",
        "Wrappers include:\n",
        "\n",
        "\n",
        "*   Frame skipping\n",
        "*   Frame processing (downsampling and greyscaling)\n",
        "* Image normalization and converting to PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZyTsre_3lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taken from OpenAI baseline wrappers\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        super(FireResetEnv, self).__init__(env)\n",
        "        print(env.unwrapped.get_action_meanings())\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)\n",
        "\n",
        "    def reset(self):\n",
        "        self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        return obs\n",
        "\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Downsamples image to 84x84\n",
        "    Greyscales image\n",
        "\n",
        "    Returns numpy array\n",
        "    \"\"\"\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env_name, frame_skip):\n",
        "    env = gym.make(env_name)\n",
        "    env = MaxAndSkipEnv(env,skip = frame_skip)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    return ScaledFloatFrame(env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyeLIpznGhBu",
        "colab_type": "text"
      },
      "source": [
        "# DQN Architecture\n",
        "Deep-Q-Networks (DQNs) are composed of: \n",
        "* 3 convolution layers\n",
        "* 2 fully-connected linear layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyvSSjc1GjIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9fVaD2M0wLc",
        "colab_type": "text"
      },
      "source": [
        "# Experience Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KVzom9K0zIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
        "\n",
        "\n",
        "class ExperienceReplay:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
        "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
        "               np.array(dones, dtype=np.uint8), np.array(next_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyc4Y9bB01t0",
        "colab_type": "text"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCPK9nrO05Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, env, replay_memory):\n",
        "        self.env = env\n",
        "        self.replay_memory = replay_memory\n",
        "        self._reset()\n",
        "        self.last_action = 0\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state = env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Select action\n",
        "        Execute action and step environment\n",
        "        Add state/action/reward to experience replay\n",
        "        \"\"\"\n",
        "        done_reward = None\n",
        "        if np.random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_a = np.array([self.state], copy=False)\n",
        "            state_v = torch.tensor(state_a).to(device)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        # do step in the environment\n",
        "        new_state, reward, is_done, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "        new_state = new_state\n",
        "\n",
        "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
        "        self.replay_memory.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dKt-mco0910",
        "colab_type": "text"
      },
      "source": [
        "# Loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ARCnK-B1C3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_loss(batch, net, target_net, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Calculate MSE between actual state action values,\n",
        "    and expected state action values from DQN\n",
        "    \"\"\"\n",
        "    states, actions, rewards, dones, next_states = batch\n",
        "\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "    done = torch.BoolTensor(dones).to(device)\n",
        "\n",
        "    state_action_values = net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
        "    next_state_values = target_net(next_states_v).max(1)[0]\n",
        "    next_state_values[done] = 0.0\n",
        "    next_state_values = next_state_values.detach()\n",
        "\n",
        "    expected_state_action_values = next_state_values * GAMMA + rewards_v\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYEFJAn1FOK",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWejS6k7OIFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8db67208-5e4d-47d7-be13-e7c93f86ffd0"
      },
      "source": [
        "print(\"ReplayMemory will require {}gb of GPU RAM\".format(round(REPLAY_SIZE * 32 * 84 * 84 / 1e+9, 2)))\n",
        "class ColabArgParse():\n",
        "    def __init__(self, cuda, env, reward, model):\n",
        "        self.cuda = cuda\n",
        "        self.env = env\n",
        "        self.reward = reward\n",
        "        self.model = model\n",
        "\n",
        "args = ColabArgParse(device, ENV_NAME, MEAN_REWARD_BOUND, MODEL)\n",
        "\n",
        "env = make_env(args.env, frame_skip = FRAME_SKIPPING)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "target_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "\n",
        "replay_memory = ExperienceReplay(REPLAY_SIZE)\n",
        "agent = Agent(env, replay_memory)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "summary(net, env.observation_space.shape)\n",
        "print(net)\n",
        "make_dot(net(torch.zeros([1,*env.observation_space.shape]).to(device)), params=dict(net.named_parameters()))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ReplayMemory will require 45.16gb of GPU RAM\n",
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
            "              ReLU-2           [-1, 32, 20, 20]               0\n",
            "            Conv2d-3             [-1, 64, 9, 9]          32,832\n",
            "              ReLU-4             [-1, 64, 9, 9]               0\n",
            "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
            "              ReLU-6             [-1, 64, 7, 7]               0\n",
            "            Linear-7                  [-1, 512]       1,606,144\n",
            "              ReLU-8                  [-1, 512]               0\n",
            "            Linear-9                    [-1, 4]           2,052\n",
            "================================================================\n",
            "Total params: 1,686,180\n",
            "Trainable params: 1,686,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 0.33\n",
            "Params size (MB): 6.43\n",
            "Estimated Total Size (MB): 6.87\n",
            "----------------------------------------------------------------\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fdc74989e80>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"452pt\" height=\"690pt\"\n viewBox=\"0.00 0.00 452.00 690.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 686)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-686 448,-686 448,4 -4,4\"/>\n<!-- 140584825692056 -->\n<g id=\"node1\" class=\"node\">\n<title>140584825692056</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"356.5,-21 252.5,-21 252.5,0 356.5,0 356.5,-21\"/>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140584825690432 -->\n<g id=\"node2\" class=\"node\">\n<title>140584825690432</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"239.5,-91 183.5,-91 183.5,-57 239.5,-57 239.5,-91\"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.2.bias</text>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4)</text>\n</g>\n<!-- 140584825690432&#45;&gt;140584825692056 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140584825690432&#45;&gt;140584825692056</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.4223,-56.9832C250.1045,-47.641 266.9893,-36.1122 280.5201,-26.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"282.5752,-29.7082 288.8602,-21.1788 278.628,-23.9273 282.5752,-29.7082\"/>\n</g>\n<!-- 140584825692112 -->\n<g id=\"node3\" class=\"node\">\n<title>140584825692112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"351.5,-84.5 257.5,-84.5 257.5,-63.5 351.5,-63.5 351.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140584825692112&#45;&gt;140584825692056 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140584825692112&#45;&gt;140584825692056</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M304.5,-63.2281C304.5,-54.5091 304.5,-41.9699 304.5,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.0001,-31.1128 304.5,-21.1128 301.0001,-31.1129 308.0001,-31.1128\"/>\n</g>\n<!-- 140584825691944 -->\n<g id=\"node4\" class=\"node\">\n<title>140584825691944</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"355.5,-154.5 251.5,-154.5 251.5,-133.5 355.5,-133.5 355.5,-154.5\"/>\n<text text-anchor=\"middle\" x=\"303.5\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140584825691944&#45;&gt;140584825692112 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140584825691944&#45;&gt;140584825692112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M303.6519,-133.3685C303.7972,-123.1925 304.0206,-107.5606 304.2016,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.7034,-94.7806 304.3467,-84.7315 300.7041,-94.6805 307.7034,-94.7806\"/>\n</g>\n<!-- 140584825691832 -->\n<g id=\"node5\" class=\"node\">\n<title>140584825691832</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"239.5,-231 183.5,-231 183.5,-197 239.5,-197 239.5,-231\"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.0.bias</text>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140584825691832&#45;&gt;140584825691944 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140584825691832&#45;&gt;140584825691944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.2416,-196.6966C248.6068,-185.7666 267.0787,-171.7119 281.3325,-160.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.7491,-163.4258 289.5881,-154.5852 279.5104,-157.855 283.7491,-163.4258\"/>\n</g>\n<!-- 140584825691496 -->\n<g id=\"node6\" class=\"node\">\n<title>140584825691496</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"349,-224.5 258,-224.5 258,-203.5 349,-203.5 349,-224.5\"/>\n<text text-anchor=\"middle\" x=\"303.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 140584825691496&#45;&gt;140584825691944 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140584825691496&#45;&gt;140584825691944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M303.5,-203.3685C303.5,-193.1925 303.5,-177.5606 303.5,-164.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.0001,-164.7315 303.5,-154.7315 300.0001,-164.7316 307.0001,-164.7315\"/>\n</g>\n<!-- 140584825690768 -->\n<g id=\"node7\" class=\"node\">\n<title>140584825690768</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"349.5,-294.5 255.5,-294.5 255.5,-273.5 349.5,-273.5 349.5,-294.5\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-280.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140584825690768&#45;&gt;140584825691496 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140584825690768&#45;&gt;140584825691496</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.6519,-273.3685C302.7972,-263.1925 303.0206,-247.5606 303.2016,-234.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.7034,-234.7806 303.3467,-224.7315 299.7041,-234.6805 306.7034,-234.7806\"/>\n</g>\n<!-- 140584825691552 -->\n<g id=\"node8\" class=\"node\">\n<title>140584825691552</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"381,-358 224,-358 224,-337 381,-337 381,-358\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140584825691552&#45;&gt;140584825690768 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140584825691552&#45;&gt;140584825690768</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.5,-336.7281C302.5,-328.0091 302.5,-315.4699 302.5,-304.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.0001,-304.6128 302.5,-294.6128 299.0001,-304.6129 306.0001,-304.6128\"/>\n</g>\n<!-- 140584825691440 -->\n<g id=\"node9\" class=\"node\">\n<title>140584825691440</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"242.5,-421.5 148.5,-421.5 148.5,-400.5 242.5,-400.5 242.5,-421.5\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140584825691440&#45;&gt;140584825691552 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140584825691440&#45;&gt;140584825691552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M213.6511,-400.2281C230.7399,-390.0866 256.5382,-374.7764 275.9401,-363.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.8036,-366.2263 284.617,-358.1128 274.2311,-360.2065 277.8036,-366.2263\"/>\n</g>\n<!-- 140584825690880 -->\n<g id=\"node10\" class=\"node\">\n<title>140584825690880</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"274,-485 117,-485 117,-464 274,-464 274,-485\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140584825690880&#45;&gt;140584825691440 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140584825690880&#45;&gt;140584825691440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M195.5,-463.7281C195.5,-455.0091 195.5,-442.4699 195.5,-431.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0001,-431.6128 195.5,-421.6128 192.0001,-431.6129 199.0001,-431.6128\"/>\n</g>\n<!-- 140584825690992 -->\n<g id=\"node11\" class=\"node\">\n<title>140584825690992</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"135.5,-548.5 41.5,-548.5 41.5,-527.5 135.5,-527.5 135.5,-548.5\"/>\n<text text-anchor=\"middle\" x=\"88.5\" y=\"-534.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140584825690992&#45;&gt;140584825690880 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140584825690992&#45;&gt;140584825690880</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.6511,-527.2281C123.7399,-517.0866 149.5382,-501.7764 168.9401,-490.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.8036,-493.2263 177.617,-485.1128 167.2311,-487.2065 170.8036,-493.2263\"/>\n</g>\n<!-- 140584825691216 -->\n<g id=\"node12\" class=\"node\">\n<title>140584825691216</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"167,-612 10,-612 10,-591 167,-591 167,-612\"/>\n<text text-anchor=\"middle\" x=\"88.5\" y=\"-598.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140584825691216&#45;&gt;140584825690992 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140584825691216&#45;&gt;140584825690992</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M88.5,-590.7281C88.5,-582.0091 88.5,-569.4699 88.5,-558.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.0001,-558.6128 88.5,-548.6128 85.0001,-558.6129 92.0001,-558.6128\"/>\n</g>\n<!-- 140584825827400 -->\n<g id=\"node13\" class=\"node\">\n<title>140584825827400</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"83,-682 0,-682 0,-648 83,-648 83,-682\"/>\n<text text-anchor=\"middle\" x=\"41.5\" y=\"-668.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.0.weight</text>\n<text text-anchor=\"middle\" x=\"41.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 4, 8, 8)</text>\n</g>\n<!-- 140584825827400&#45;&gt;140584825691216 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140584825827400&#45;&gt;140584825691216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0951,-647.9832C60.3763,-639.4969 67.9931,-629.2062 74.4616,-620.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.3194,-622.4888 80.4555,-612.3687 71.6929,-618.3243 77.3194,-622.4888\"/>\n</g>\n<!-- 140584825827456 -->\n<g id=\"node14\" class=\"node\">\n<title>140584825827456</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"171.5,-682 101.5,-682 101.5,-648 171.5,-648 171.5,-682\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-668.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.0.bias</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140584825827456&#45;&gt;140584825691216 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140584825827456&#45;&gt;140584825691216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.6369,-647.9832C117.222,-639.4969 109.4433,-629.2062 102.8371,-620.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.5379,-618.2355 96.7157,-612.3687 99.9538,-622.4566 105.5379,-618.2355\"/>\n</g>\n<!-- 140584825691048 -->\n<g id=\"node15\" class=\"node\">\n<title>140584825691048</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"237,-555 154,-555 154,-521 237,-521 237,-555\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.2.weight</text>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 32, 4, 4)</text>\n</g>\n<!-- 140584825691048&#45;&gt;140584825690880 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140584825691048&#45;&gt;140584825690880</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M195.5,-520.9832C195.5,-513.1157 195.5,-503.6973 195.5,-495.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0001,-495.3686 195.5,-485.3687 192.0001,-495.3687 199.0001,-495.3686\"/>\n</g>\n<!-- 140584825691104 -->\n<g id=\"node16\" class=\"node\">\n<title>140584825691104</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"325.5,-555 255.5,-555 255.5,-521 325.5,-521 325.5,-555\"/>\n<text text-anchor=\"middle\" x=\"290.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.2.bias</text>\n<text text-anchor=\"middle\" x=\"290.5\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140584825691104&#45;&gt;140584825690880 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140584825691104&#45;&gt;140584825690880</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M265.0417,-520.9832C251.0653,-511.641 233.8174,-500.1122 219.9956,-490.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"221.735,-487.8261 211.4762,-485.1788 217.845,-493.6458 221.735,-487.8261\"/>\n</g>\n<!-- 140584825691384 -->\n<g id=\"node17\" class=\"node\">\n<title>140584825691384</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"344,-428 261,-428 261,-394 344,-394 344,-428\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.4.weight</text>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 64, 3, 3)</text>\n</g>\n<!-- 140584825691384&#45;&gt;140584825691552 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140584825691384&#45;&gt;140584825691552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.5,-393.9832C302.5,-386.1157 302.5,-376.6973 302.5,-368.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.0001,-368.3686 302.5,-358.3687 299.0001,-368.3687 306.0001,-368.3686\"/>\n</g>\n<!-- 140584825690600 -->\n<g id=\"node18\" class=\"node\">\n<title>140584825690600</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"432.5,-428 362.5,-428 362.5,-394 432.5,-394 432.5,-428\"/>\n<text text-anchor=\"middle\" x=\"397.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.4.bias</text>\n<text text-anchor=\"middle\" x=\"397.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140584825690600&#45;&gt;140584825691552 -->\n<g id=\"edge17\" class=\"edge\">\n<title>140584825690600&#45;&gt;140584825691552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M372.0417,-393.9832C358.0653,-384.641 340.8174,-373.1122 326.9956,-363.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"328.735,-360.8261 318.4762,-358.1788 324.845,-366.6458 328.735,-360.8261\"/>\n</g>\n<!-- 140584825691720 -->\n<g id=\"node19\" class=\"node\">\n<title>140584825691720</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"441,-224.5 368,-224.5 368,-203.5 441,-203.5 441,-224.5\"/>\n<text text-anchor=\"middle\" x=\"404.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140584825691720&#45;&gt;140584825691944 -->\n<g id=\"edge18\" class=\"edge\">\n<title>140584825691720&#45;&gt;140584825691944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M389.1603,-203.3685C372.6024,-191.8927 346.033,-173.4783 326.8726,-160.1988\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"328.8659,-157.3219 318.6532,-154.5022 324.8784,-163.0752 328.8659,-157.3219\"/>\n</g>\n<!-- 140584825691608 -->\n<g id=\"node20\" class=\"node\">\n<title>140584825691608</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"443,-301 368,-301 368,-267 443,-267 443,-301\"/>\n<text text-anchor=\"middle\" x=\"405.5\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.0.weight</text>\n<text text-anchor=\"middle\" x=\"405.5\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512, 3136)</text>\n</g>\n<!-- 140584825691608&#45;&gt;140584825691720 -->\n<g id=\"edge19\" class=\"edge\">\n<title>140584825691608&#45;&gt;140584825691720</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M405.2528,-266.6966C405.1152,-257.0634 404.9429,-245.003 404.7979,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"408.2967,-234.7402 404.6542,-224.7913 401.2975,-234.8403 408.2967,-234.7402\"/>\n</g>\n<!-- 140584825691272 -->\n<g id=\"node21\" class=\"node\">\n<title>140584825691272</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"444,-84.5 371,-84.5 371,-63.5 444,-63.5 444,-84.5\"/>\n<text text-anchor=\"middle\" x=\"407.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140584825691272&#45;&gt;140584825692056 -->\n<g id=\"edge20\" class=\"edge\">\n<title>140584825691272&#45;&gt;140584825692056</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M390.0275,-63.2281C373.6519,-53.1325 348.9682,-37.9149 330.3209,-26.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.0636,-23.3814 321.7145,-21.1128 328.3901,-29.3401 332.0636,-23.3814\"/>\n</g>\n<!-- 140584825691888 -->\n<g id=\"node22\" class=\"node\">\n<title>140584825691888</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"443.5,-161 373.5,-161 373.5,-127 443.5,-127 443.5,-161\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.2.weight</text>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4, 512)</text>\n</g>\n<!-- 140584825691888&#45;&gt;140584825691272 -->\n<g id=\"edge21\" class=\"edge\">\n<title>140584825691888&#45;&gt;140584825691272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M408.2528,-126.6966C408.1152,-117.0634 407.9429,-105.003 407.7979,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"411.2967,-94.7402 407.6542,-84.7913 404.2975,-94.8403 411.2967,-94.7402\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cGRFQ49ySq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_animation(net, args, epsilon = 0.05, device = 'cuda', try_num = 10):\n",
        "\n",
        "    def display_frames_as_gif(frames):\n",
        "        \"\"\"\n",
        "        Displays a list of frames as a gif, with controls\n",
        "        \"\"\"\n",
        "        #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
        "        patch = plt.imshow(frames[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "        def animate(i):\n",
        "            patch.set_data(frames[i])\n",
        "\n",
        "        anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=100)\n",
        "        rc('animation', html='jshtml')\n",
        "        return anim\n",
        "\n",
        "    best_reward, best_frames = -100, None\n",
        "    for i in range(try_num): # try several times and return the best-scored epsisode\n",
        "        agent._reset()\n",
        "        frames = []\n",
        "        for t in range(1000):\n",
        "            tmp_reward = agent.play_step(net, epsilon = 0.05, device = device)\n",
        "            frames.append(agent.env.render(mode = 'rgb_array'))\n",
        "            if tmp_reward is not None:\n",
        "                break\n",
        "        print(f'  --Try {i}: t={t}, reward={tmp_reward}', end = '')\n",
        "        if tmp_reward is not None and tmp_reward>best_reward:\n",
        "            best_reward = tmp_reward\n",
        "            best_frames = frames.copy()\n",
        "            best_t = t\n",
        "            print(f' Best reward updated')\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    print('  --Generating animation..')\n",
        "    anim = display_frames_as_gif(best_frames)\n",
        "    print(f' --Animationm from {len(best_frames)} frames with reward {best_reward} generated')\n",
        "    return anim, len(best_frames), best_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxf6rZ3Q9Z-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model_animation(net, args, T):\n",
        "    torch.save(net.state_dict(), f'{args.env}-{T}.dat')\n",
        "    torch.save(net.state_dict(), os.path.join(SAVE_FOLDER, f'{args.env}-{T}.dat'))\n",
        "    pickle.dump(total_rewards,open(os.path.join(SAVE_FOLDER, 'output.pkl'),'wb'))\n",
        "\n",
        "    anim, t, tot_r = create_animation(net, args, epsilon = 0.05, device = device, try_num=10)\n",
        "\n",
        "    anim_save_file_name = os.path.join(SAVE_FOLDER, f'{args.env}-{T}-{t}frame_{tot_r}')\n",
        "    anim.save(f'{anim_save_file_name}.mp4')\n",
        "    anim.save(f'{anim_save_file_name}.gif', writer='matplotlib.animation.PillowWriter', fps=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onPxTAtp3rhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70f6aa2a-1499-4f59-9168-6b62ba98386a"
      },
      "source": [
        "if LOAD_MODEL_NAME:\n",
        "    net.load_state_dict(torch.load(os.path.join(SAVE_FOLDER, LOAD_MODEL_NAME)))\n",
        "    target_net.load_state_dict(net.state_dict())\n",
        "    total_rewards = pickle.load(open(os.path.join(SAVE_FOLDER, 'output.pkl'), 'rb'))\n",
        "    print(\"Models loaded from Google Drive!\")\n",
        "    # Lower exploration rate IMPORTANT\n",
        "    EPSILON_START = EPSILON_FINAL\n",
        "    print(f'Set epsilon start as {EPSILON_START}')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Models loaded from Google Drive!\n",
            "Set epsilon start as 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFWrNxvRTL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay = 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJIPBW9jScp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_rewards = []\n",
        "best_mean_reward = None\n",
        "frame_idx = 0\n",
        "timestep_frame = 0\n",
        "timestep = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDZ6Kub4Gopl",
        "colab_type": "code",
        "outputId": "c20af1b3-5bab-498d-dbaa-dd184f7e6321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY)\n",
        "\n",
        "    reward = agent.play_step(net, epsilon, device=device)\n",
        "\n",
        "    if reward is not None: #episode finished\n",
        "        total_rewards.append(reward)\n",
        "        delta_frame = frame_idx - timestep_frame\n",
        "        speed = delta_frame / (time.time() - timestep)\n",
        "        timestep_frame = frame_idx\n",
        "        timestep = time.time()\n",
        "        mean_reward = np.mean(total_rewards[-100:])\n",
        "        if (len(total_rewards)%3==0):\n",
        "            print(f\"{frame_idx} frames: done {len(total_rewards)} games, mean reward {round(mean_reward,3)}, \",\n",
        "                    f\"{delta_frame:3d} frame/episode, eps {round(epsilon,3)}, speed {round(speed,2)} f/s\")\n",
        "\n",
        "        #if (best_mean_reward is None or best_mean_reward < mean_reward) and len(total_rewards) % MODEL_SAVE_STEP == 0:\n",
        "        if len(total_rewards) % MODEL_SAVE_STEP == 0:\n",
        "            save_model_animation(net, args, len(total_rewards))\n",
        "            if best_mean_reward is not None:\n",
        "                print(\"New best mean reward {} -> {}, model saved\".format(round(best_mean_reward, 3), round(mean_reward, 3)))\n",
        "            best_mean_reward = mean_reward\n",
        "        if mean_reward > args.reward and len(total_rewards) > 10:\n",
        "            print(\"Game solved in {} frames! Average score of {}\".format(frame_idx, mean_reward))\n",
        "            break\n",
        "\n",
        "    if len(replay_memory) < LEARNING_STARTS:\n",
        "        continue\n",
        "\n",
        "    if frame_idx % TARGET_UPDATE_FREQ == 0:\n",
        "        target_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = replay_memory.sample(BATCH_SIZE)\n",
        "    loss_t = calculate_loss(batch, net, target_net, device=device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "env.close()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "944 frames: done 3 games, mean reward 39.667,  316 frame/episode, eps 0.1, speed 312.54 f/s\n",
            "1708 frames: done 6 games, mean reward 35.833,  188 frame/episode, eps 0.1, speed 316.58 f/s\n",
            "2577 frames: done 9 games, mean reward 35.556,  315 frame/episode, eps 0.1, speed 310.6 f/s\n",
            "3513 frames: done 12 games, mean reward 36.167,  362 frame/episode, eps 0.1, speed 320.78 f/s\n",
            "4370 frames: done 15 games, mean reward 39.267,  268 frame/episode, eps 0.1, speed 336.39 f/s\n",
            "5433 frames: done 18 games, mean reward 49.167,  386 frame/episode, eps 0.1, speed 332.69 f/s\n",
            "6190 frames: done 21 games, mean reward 47.524,  223 frame/episode, eps 0.1, speed 331.55 f/s\n",
            "7204 frames: done 24 games, mean reward 48.375,  286 frame/episode, eps 0.1, speed 334.71 f/s\n",
            "7972 frames: done 27 games, mean reward 46.926,  232 frame/episode, eps 0.1, speed 327.87 f/s\n",
            "8813 frames: done 30 games, mean reward 44.6,  336 frame/episode, eps 0.1, speed 329.46 f/s\n",
            "9672 frames: done 33 games, mean reward 44.121,  249 frame/episode, eps 0.1, speed 316.84 f/s\n",
            "10496 frames: done 36 games, mean reward 43.306,  227 frame/episode, eps 0.1, speed 316.08 f/s\n",
            "11469 frames: done 39 games, mean reward 47.513,  330 frame/episode, eps 0.1, speed 326.68 f/s\n",
            "12218 frames: done 42 games, mean reward 46.69,  234 frame/episode, eps 0.1, speed 327.21 f/s\n",
            "13085 frames: done 45 games, mean reward 45.644,  252 frame/episode, eps 0.1, speed 328.59 f/s\n",
            "14029 frames: done 48 games, mean reward 44.896,  406 frame/episode, eps 0.1, speed 87.36 f/s\n",
            "15088 frames: done 51 games, mean reward 44.098,  332 frame/episode, eps 0.1, speed 86.01 f/s\n",
            "15835 frames: done 54 games, mean reward 43.148,  253 frame/episode, eps 0.1, speed 85.62 f/s\n",
            "16764 frames: done 57 games, mean reward 42.86,  259 frame/episode, eps 0.1, speed 84.19 f/s\n",
            "17888 frames: done 60 games, mean reward 42.267,  373 frame/episode, eps 0.1, speed 85.95 f/s\n",
            "18823 frames: done 63 games, mean reward 44.857,  402 frame/episode, eps 0.1, speed 86.22 f/s\n",
            "19760 frames: done 66 games, mean reward 44.227,  293 frame/episode, eps 0.1, speed 85.55 f/s\n",
            "20631 frames: done 69 games, mean reward 43.928,  274 frame/episode, eps 0.1, speed 86.45 f/s\n",
            "21396 frames: done 72 games, mean reward 43.0,  225 frame/episode, eps 0.1, speed 86.45 f/s\n",
            "22115 frames: done 75 games, mean reward 42.68,  145 frame/episode, eps 0.1, speed 86.35 f/s\n",
            "23324 frames: done 78 games, mean reward 42.09,  378 frame/episode, eps 0.1, speed 86.42 f/s\n",
            "24173 frames: done 81 games, mean reward 41.321,  399 frame/episode, eps 0.1, speed 85.59 f/s\n",
            "24911 frames: done 84 games, mean reward 40.56,  264 frame/episode, eps 0.1, speed 86.12 f/s\n",
            "25618 frames: done 87 games, mean reward 40.069,  199 frame/episode, eps 0.1, speed 83.2 f/s\n",
            "26415 frames: done 90 games, mean reward 40.0,  298 frame/episode, eps 0.1, speed 83.47 f/s\n",
            "27136 frames: done 93 games, mean reward 39.172,  276 frame/episode, eps 0.1, speed 85.43 f/s\n",
            "27975 frames: done 96 games, mean reward 38.677,  342 frame/episode, eps 0.1, speed 85.6 f/s\n",
            "28871 frames: done 99 games, mean reward 38.788,  340 frame/episode, eps 0.1, speed 84.76 f/s\n",
            "29769 frames: done 102 games, mean reward 38.78,  330 frame/episode, eps 0.1, speed 81.61 f/s\n",
            "30662 frames: done 105 games, mean reward 38.68,  348 frame/episode, eps 0.1, speed 80.28 f/s\n",
            "31639 frames: done 108 games, mean reward 39.35,  302 frame/episode, eps 0.1, speed 82.19 f/s\n",
            "32373 frames: done 111 games, mean reward 38.53,  348 frame/episode, eps 0.1, speed 84.08 f/s\n",
            "33184 frames: done 114 games, mean reward 38.19,  272 frame/episode, eps 0.1, speed 83.33 f/s\n",
            "34082 frames: done 117 games, mean reward 38.22,  198 frame/episode, eps 0.1, speed 80.95 f/s\n",
            "34788 frames: done 120 games, mean reward 35.64,  297 frame/episode, eps 0.1, speed 83.84 f/s\n",
            "35758 frames: done 123 games, mean reward 35.21,  297 frame/episode, eps 0.1, speed 81.23 f/s\n",
            "36568 frames: done 126 games, mean reward 35.32,  216 frame/episode, eps 0.1, speed 83.12 f/s\n",
            "37285 frames: done 129 games, mean reward 35.39,  221 frame/episode, eps 0.1, speed 81.72 f/s\n",
            "38213 frames: done 132 games, mean reward 36.02,  274 frame/episode, eps 0.1, speed 82.94 f/s\n",
            "39079 frames: done 135 games, mean reward 35.62,  302 frame/episode, eps 0.1, speed 81.48 f/s\n",
            "40043 frames: done 138 games, mean reward 34.19,  431 frame/episode, eps 0.1, speed 84.02 f/s\n",
            "40875 frames: done 141 games, mean reward 34.37,  255 frame/episode, eps 0.1, speed 84.01 f/s\n",
            "41702 frames: done 144 games, mean reward 34.46,  200 frame/episode, eps 0.1, speed 83.75 f/s\n",
            "42612 frames: done 147 games, mean reward 34.02,  337 frame/episode, eps 0.1, speed 83.02 f/s\n",
            "43314 frames: done 150 games, mean reward 33.41,  303 frame/episode, eps 0.1, speed 83.29 f/s\n",
            "43948 frames: done 153 games, mean reward 33.33,  139 frame/episode, eps 0.1, speed 80.33 f/s\n",
            "44749 frames: done 156 games, mean reward 33.08,  275 frame/episode, eps 0.1, speed 83.26 f/s\n",
            "45570 frames: done 159 games, mean reward 33.37,  260 frame/episode, eps 0.1, speed 80.91 f/s\n",
            "46317 frames: done 162 games, mean reward 33.51,  275 frame/episode, eps 0.1, speed 81.89 f/s\n",
            "47151 frames: done 165 games, mean reward 31.73,  297 frame/episode, eps 0.1, speed 83.73 f/s\n",
            "48075 frames: done 168 games, mean reward 31.86,  320 frame/episode, eps 0.1, speed 82.07 f/s\n",
            "48944 frames: done 171 games, mean reward 32.11,  306 frame/episode, eps 0.1, speed 81.24 f/s\n",
            "49778 frames: done 174 games, mean reward 31.7,  336 frame/episode, eps 0.1, speed 82.49 f/s\n",
            "50684 frames: done 177 games, mean reward 32.57,  265 frame/episode, eps 0.1, speed 80.68 f/s\n",
            "51779 frames: done 180 games, mean reward 33.02,  288 frame/episode, eps 0.1, speed 79.71 f/s\n",
            "52634 frames: done 183 games, mean reward 33.66,  316 frame/episode, eps 0.1, speed 83.48 f/s\n",
            "53373 frames: done 186 games, mean reward 33.92,  271 frame/episode, eps 0.1, speed 83.48 f/s\n",
            "54382 frames: done 189 games, mean reward 34.04,  325 frame/episode, eps 0.1, speed 81.41 f/s\n",
            "55042 frames: done 192 games, mean reward 34.03,  291 frame/episode, eps 0.1, speed 83.92 f/s\n",
            "55776 frames: done 195 games, mean reward 34.44,  277 frame/episode, eps 0.1, speed 82.49 f/s\n",
            "56821 frames: done 198 games, mean reward 34.72,  329 frame/episode, eps 0.1, speed 80.52 f/s\n",
            "  --Try 0: t=347, reward=73.0 Best reward updated\n",
            "  --Try 1: t=273, reward=38.0\n",
            "  --Try 2: t=362, reward=52.0\n",
            "  --Try 3: t=555, reward=40.0\n",
            "  --Try 4: t=369, reward=59.0\n",
            "  --Try 5: t=334, reward=54.0\n",
            "  --Try 6: t=275, reward=48.0\n",
            "  --Try 7: t=326, reward=50.0\n",
            "  --Try 8: t=339, reward=77.0 Best reward updated\n",
            "  --Try 9: t=269, reward=30.0\n",
            "  --Generating animation..\n",
            " --Animationm from 340 frames with reward 77.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "57781 frames: done 201 games, mean reward 34.77,  289 frame/episode, eps 0.1, speed 13.24 f/s\n",
            "58421 frames: done 204 games, mean reward 34.27,  226 frame/episode, eps 0.1, speed 79.22 f/s\n",
            "59341 frames: done 207 games, mean reward 33.93,  304 frame/episode, eps 0.1, speed 81.0 f/s\n",
            "60101 frames: done 210 games, mean reward 34.02,  202 frame/episode, eps 0.1, speed 81.02 f/s\n",
            "60942 frames: done 213 games, mean reward 34.24,  343 frame/episode, eps 0.1, speed 82.46 f/s\n",
            "61744 frames: done 216 games, mean reward 33.62,  282 frame/episode, eps 0.1, speed 81.18 f/s\n",
            "62665 frames: done 219 games, mean reward 34.28,  259 frame/episode, eps 0.1, speed 80.83 f/s\n",
            "63437 frames: done 222 games, mean reward 34.26,  254 frame/episode, eps 0.1, speed 78.67 f/s\n",
            "64441 frames: done 225 games, mean reward 34.42,  305 frame/episode, eps 0.1, speed 80.67 f/s\n",
            "65116 frames: done 228 games, mean reward 34.41,  141 frame/episode, eps 0.1, speed 81.32 f/s\n",
            "66021 frames: done 231 games, mean reward 33.62,  285 frame/episode, eps 0.1, speed 80.5 f/s\n",
            "66799 frames: done 234 games, mean reward 33.85,  329 frame/episode, eps 0.1, speed 80.55 f/s\n",
            "67676 frames: done 237 games, mean reward 34.1,  299 frame/episode, eps 0.1, speed 81.01 f/s\n",
            "68520 frames: done 240 games, mean reward 33.85,  306 frame/episode, eps 0.1, speed 77.8 f/s\n",
            "69179 frames: done 243 games, mean reward 33.63,  266 frame/episode, eps 0.1, speed 80.32 f/s\n",
            "69983 frames: done 246 games, mean reward 33.6,  234 frame/episode, eps 0.1, speed 81.14 f/s\n",
            "70914 frames: done 249 games, mean reward 34.21,  275 frame/episode, eps 0.1, speed 80.14 f/s\n",
            "71870 frames: done 252 games, mean reward 34.72,  329 frame/episode, eps 0.1, speed 80.56 f/s\n",
            "72613 frames: done 255 games, mean reward 34.59,  163 frame/episode, eps 0.1, speed 79.55 f/s\n",
            "73456 frames: done 258 games, mean reward 34.74,  290 frame/episode, eps 0.1, speed 80.8 f/s\n",
            "74479 frames: done 261 games, mean reward 34.94,  324 frame/episode, eps 0.1, speed 79.25 f/s\n",
            "75108 frames: done 264 games, mean reward 34.37,  238 frame/episode, eps 0.1, speed 78.37 f/s\n",
            "75938 frames: done 267 games, mean reward 34.81,  276 frame/episode, eps 0.1, speed 79.45 f/s\n",
            "76892 frames: done 270 games, mean reward 34.33,  380 frame/episode, eps 0.1, speed 79.42 f/s\n",
            "77575 frames: done 273 games, mean reward 34.41,  234 frame/episode, eps 0.1, speed 80.33 f/s\n",
            "78323 frames: done 276 games, mean reward 34.23,  179 frame/episode, eps 0.1, speed 80.15 f/s\n",
            "79186 frames: done 279 games, mean reward 34.06,  297 frame/episode, eps 0.1, speed 79.17 f/s\n",
            "79960 frames: done 282 games, mean reward 33.82,  296 frame/episode, eps 0.1, speed 79.58 f/s\n",
            "81093 frames: done 285 games, mean reward 33.59,  365 frame/episode, eps 0.1, speed 78.69 f/s\n",
            "82085 frames: done 288 games, mean reward 33.3,  396 frame/episode, eps 0.1, speed 79.87 f/s\n",
            "83030 frames: done 291 games, mean reward 33.69,  379 frame/episode, eps 0.1, speed 78.72 f/s\n",
            "84005 frames: done 294 games, mean reward 33.92,  278 frame/episode, eps 0.1, speed 79.35 f/s\n",
            "85022 frames: done 297 games, mean reward 33.6,  490 frame/episode, eps 0.1, speed 79.63 f/s\n",
            "85807 frames: done 300 games, mean reward 32.94,  308 frame/episode, eps 0.1, speed 79.21 f/s\n",
            "86506 frames: done 303 games, mean reward 33.05,  257 frame/episode, eps 0.1, speed 78.73 f/s\n",
            "87407 frames: done 306 games, mean reward 33.42,  318 frame/episode, eps 0.1, speed 77.44 f/s\n",
            "88289 frames: done 309 games, mean reward 32.89,  435 frame/episode, eps 0.1, speed 77.25 f/s\n",
            "89069 frames: done 312 games, mean reward 32.58,  166 frame/episode, eps 0.1, speed 79.24 f/s\n",
            "89786 frames: done 315 games, mean reward 32.35,  292 frame/episode, eps 0.1, speed 78.77 f/s\n",
            "90659 frames: done 318 games, mean reward 32.57,  265 frame/episode, eps 0.1, speed 78.4 f/s\n",
            "91351 frames: done 321 games, mean reward 32.35,  226 frame/episode, eps 0.1, speed 78.96 f/s\n",
            "92131 frames: done 324 games, mean reward 32.24,  341 frame/episode, eps 0.1, speed 78.35 f/s\n",
            "92897 frames: done 327 games, mean reward 32.17,  237 frame/episode, eps 0.1, speed 73.94 f/s\n",
            "93743 frames: done 330 games, mean reward 32.29,  279 frame/episode, eps 0.1, speed 76.44 f/s\n",
            "94547 frames: done 333 games, mean reward 32.66,  314 frame/episode, eps 0.1, speed 78.1 f/s\n",
            "95356 frames: done 336 games, mean reward 32.36,  280 frame/episode, eps 0.1, speed 75.69 f/s\n",
            "96097 frames: done 339 games, mean reward 32.19,  327 frame/episode, eps 0.1, speed 76.85 f/s\n",
            "96863 frames: done 342 games, mean reward 32.23,  241 frame/episode, eps 0.1, speed 75.63 f/s\n",
            "97740 frames: done 345 games, mean reward 32.47,  251 frame/episode, eps 0.1, speed 75.81 f/s\n",
            "98586 frames: done 348 games, mean reward 32.74,  275 frame/episode, eps 0.1, speed 75.92 f/s\n",
            "99333 frames: done 351 games, mean reward 32.16,  245 frame/episode, eps 0.1, speed 77.98 f/s\n",
            "100140 frames: done 354 games, mean reward 31.58,  339 frame/episode, eps 0.1, speed 76.59 f/s\n",
            "100986 frames: done 357 games, mean reward 32.23,  247 frame/episode, eps 0.1, speed 77.93 f/s\n",
            "101831 frames: done 360 games, mean reward 32.16,  249 frame/episode, eps 0.1, speed 77.86 f/s\n",
            "102663 frames: done 363 games, mean reward 32.81,  271 frame/episode, eps 0.1, speed 76.8 f/s\n",
            "103509 frames: done 366 games, mean reward 32.61,  373 frame/episode, eps 0.1, speed 77.95 f/s\n",
            "104284 frames: done 369 games, mean reward 32.7,  227 frame/episode, eps 0.1, speed 77.86 f/s\n",
            "104969 frames: done 372 games, mean reward 32.17,  271 frame/episode, eps 0.1, speed 77.74 f/s\n",
            "105901 frames: done 375 games, mean reward 32.07,  342 frame/episode, eps 0.1, speed 77.11 f/s\n",
            "106782 frames: done 378 games, mean reward 32.55,  402 frame/episode, eps 0.1, speed 76.96 f/s\n",
            "107518 frames: done 381 games, mean reward 32.67,  248 frame/episode, eps 0.1, speed 77.35 f/s\n",
            "108345 frames: done 384 games, mean reward 32.98,  279 frame/episode, eps 0.1, speed 77.27 f/s\n",
            "109185 frames: done 387 games, mean reward 33.58,  334 frame/episode, eps 0.1, speed 76.88 f/s\n",
            "109864 frames: done 390 games, mean reward 33.55,  247 frame/episode, eps 0.1, speed 77.08 f/s\n",
            "110696 frames: done 393 games, mean reward 33.21,  248 frame/episode, eps 0.1, speed 76.5 f/s\n",
            "111518 frames: done 396 games, mean reward 33.35,  272 frame/episode, eps 0.1, speed 74.95 f/s\n",
            "112283 frames: done 399 games, mean reward 33.48,  247 frame/episode, eps 0.1, speed 75.5 f/s\n",
            "  --Try 0: t=307, reward=49.0 Best reward updated\n",
            "  --Try 1: t=297, reward=45.0\n",
            "  --Try 2: t=306, reward=55.0 Best reward updated\n",
            "  --Try 3: t=335, reward=76.0 Best reward updated\n",
            "  --Try 4: t=268, reward=44.0\n",
            "  --Try 5: t=290, reward=50.0\n",
            "  --Try 6: t=318, reward=26.0\n",
            "  --Try 7: t=324, reward=60.0\n",
            "  --Try 8: t=312, reward=47.0\n",
            "  --Try 9: t=254, reward=42.0\n",
            "  --Generating animation..\n",
            " --Animationm from 336 frames with reward 76.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 34.81 -> 33.49, model saved\n",
            "113177 frames: done 402 games, mean reward 34.15,  314 frame/episode, eps 0.1, speed 74.67 f/s\n",
            "114055 frames: done 405 games, mean reward 34.49,  270 frame/episode, eps 0.1, speed 75.7 f/s\n",
            "114827 frames: done 408 games, mean reward 33.94,  197 frame/episode, eps 0.1, speed 76.58 f/s\n",
            "115717 frames: done 411 games, mean reward 34.39,  299 frame/episode, eps 0.1, speed 75.99 f/s\n",
            "116412 frames: done 414 games, mean reward 34.73,  235 frame/episode, eps 0.1, speed 76.02 f/s\n",
            "117342 frames: done 417 games, mean reward 34.38,  306 frame/episode, eps 0.1, speed 75.02 f/s\n",
            "118029 frames: done 420 games, mean reward 34.27,  249 frame/episode, eps 0.1, speed 75.53 f/s\n",
            "118767 frames: done 423 games, mean reward 34.43,  267 frame/episode, eps 0.1, speed 75.91 f/s\n",
            "119621 frames: done 426 games, mean reward 34.15,  300 frame/episode, eps 0.1, speed 75.87 f/s\n",
            "120353 frames: done 429 games, mean reward 34.04,  250 frame/episode, eps 0.1, speed 75.38 f/s\n",
            "121090 frames: done 432 games, mean reward 34.08,  190 frame/episode, eps 0.1, speed 75.2 f/s\n",
            "122069 frames: done 435 games, mean reward 34.11,  281 frame/episode, eps 0.1, speed 75.32 f/s\n",
            "122874 frames: done 438 games, mean reward 34.35,  148 frame/episode, eps 0.1, speed 73.74 f/s\n",
            "123917 frames: done 441 games, mean reward 34.77,  371 frame/episode, eps 0.1, speed 75.67 f/s\n",
            "124845 frames: done 444 games, mean reward 34.75,  437 frame/episode, eps 0.1, speed 75.45 f/s\n",
            "125598 frames: done 447 games, mean reward 34.71,  294 frame/episode, eps 0.1, speed 74.72 f/s\n",
            "126489 frames: done 450 games, mean reward 35.48,  308 frame/episode, eps 0.1, speed 75.09 f/s\n",
            "127192 frames: done 453 games, mean reward 35.74,  216 frame/episode, eps 0.1, speed 75.07 f/s\n",
            "127880 frames: done 456 games, mean reward 35.4,  232 frame/episode, eps 0.1, speed 74.46 f/s\n",
            "128718 frames: done 459 games, mean reward 35.02,  234 frame/episode, eps 0.1, speed 74.13 f/s\n",
            "129767 frames: done 462 games, mean reward 34.37,  342 frame/episode, eps 0.1, speed 74.53 f/s\n",
            "130571 frames: done 465 games, mean reward 34.6,  338 frame/episode, eps 0.1, speed 74.27 f/s\n",
            "131325 frames: done 468 games, mean reward 34.33,  288 frame/episode, eps 0.1, speed 74.65 f/s\n",
            "132269 frames: done 471 games, mean reward 35.1,  304 frame/episode, eps 0.1, speed 74.59 f/s\n",
            "133057 frames: done 474 games, mean reward 34.86,  244 frame/episode, eps 0.1, speed 74.15 f/s\n",
            "133807 frames: done 477 games, mean reward 34.68,  309 frame/episode, eps 0.1, speed 72.78 f/s\n",
            "134598 frames: done 480 games, mean reward 34.26,  238 frame/episode, eps 0.1, speed 73.1 f/s\n",
            "135433 frames: done 483 games, mean reward 33.84,  262 frame/episode, eps 0.1, speed 73.69 f/s\n",
            "136208 frames: done 486 games, mean reward 33.93,  273 frame/episode, eps 0.1, speed 73.32 f/s\n",
            "137165 frames: done 489 games, mean reward 34.52,  339 frame/episode, eps 0.1, speed 72.91 f/s\n",
            "138075 frames: done 492 games, mean reward 34.56,  233 frame/episode, eps 0.1, speed 73.92 f/s\n",
            "139003 frames: done 495 games, mean reward 34.61,  294 frame/episode, eps 0.1, speed 73.01 f/s\n",
            "139709 frames: done 498 games, mean reward 34.44,  232 frame/episode, eps 0.1, speed 72.39 f/s\n",
            "140532 frames: done 501 games, mean reward 34.47,  209 frame/episode, eps 0.1, speed 72.3 f/s\n",
            "141286 frames: done 504 games, mean reward 33.84,  273 frame/episode, eps 0.1, speed 72.06 f/s\n",
            "142060 frames: done 507 games, mean reward 34.19,  286 frame/episode, eps 0.1, speed 73.01 f/s\n",
            "142933 frames: done 510 games, mean reward 34.59,  321 frame/episode, eps 0.1, speed 73.04 f/s\n",
            "143825 frames: done 513 games, mean reward 34.84,  261 frame/episode, eps 0.1, speed 71.76 f/s\n",
            "144550 frames: done 516 games, mean reward 34.94,  231 frame/episode, eps 0.1, speed 72.23 f/s\n",
            "145442 frames: done 519 games, mean reward 34.92,  355 frame/episode, eps 0.1, speed 71.76 f/s\n",
            "146445 frames: done 522 games, mean reward 35.44,  344 frame/episode, eps 0.1, speed 71.16 f/s\n",
            "147183 frames: done 525 games, mean reward 34.95,  321 frame/episode, eps 0.1, speed 71.52 f/s\n",
            "148165 frames: done 528 games, mean reward 35.61,  245 frame/episode, eps 0.1, speed 70.47 f/s\n",
            "148940 frames: done 531 games, mean reward 35.44,  262 frame/episode, eps 0.1, speed 71.41 f/s\n",
            "149800 frames: done 534 games, mean reward 35.37,  357 frame/episode, eps 0.1, speed 71.49 f/s\n",
            "150703 frames: done 537 games, mean reward 34.98,  290 frame/episode, eps 0.1, speed 70.91 f/s\n",
            "151518 frames: done 540 games, mean reward 35.16,  317 frame/episode, eps 0.1, speed 70.95 f/s\n",
            "152121 frames: done 543 games, mean reward 34.31,  104 frame/episode, eps 0.1, speed 70.03 f/s\n",
            "152977 frames: done 546 games, mean reward 33.68,  301 frame/episode, eps 0.1, speed 71.08 f/s\n",
            "153902 frames: done 549 games, mean reward 33.22,  379 frame/episode, eps 0.1, speed 71.14 f/s\n",
            "154710 frames: done 552 games, mean reward 32.86,  246 frame/episode, eps 0.1, speed 70.95 f/s\n",
            "155491 frames: done 555 games, mean reward 32.82,  280 frame/episode, eps 0.1, speed 70.64 f/s\n",
            "156294 frames: done 558 games, mean reward 32.62,  276 frame/episode, eps 0.1, speed 66.2 f/s\n",
            "157045 frames: done 561 games, mean reward 32.41,  271 frame/episode, eps 0.1, speed 67.1 f/s\n",
            "157773 frames: done 564 games, mean reward 32.67,  226 frame/episode, eps 0.1, speed 68.2 f/s\n",
            "158597 frames: done 567 games, mean reward 32.91,  204 frame/episode, eps 0.1, speed 68.67 f/s\n",
            "159332 frames: done 570 games, mean reward 32.39,  193 frame/episode, eps 0.1, speed 66.05 f/s\n",
            "160127 frames: done 573 games, mean reward 32.21,  247 frame/episode, eps 0.1, speed 69.47 f/s\n",
            "161019 frames: done 576 games, mean reward 33.05,  352 frame/episode, eps 0.1, speed 69.78 f/s\n",
            "161708 frames: done 579 games, mean reward 32.95,  229 frame/episode, eps 0.1, speed 68.26 f/s\n",
            "162545 frames: done 582 games, mean reward 33.5,  321 frame/episode, eps 0.1, speed 68.99 f/s\n",
            "163229 frames: done 585 games, mean reward 33.42,  231 frame/episode, eps 0.1, speed 68.53 f/s\n",
            "164007 frames: done 588 games, mean reward 33.23,  249 frame/episode, eps 0.1, speed 68.9 f/s\n",
            "164918 frames: done 591 games, mean reward 32.98,  342 frame/episode, eps 0.1, speed 68.39 f/s\n",
            "165759 frames: done 594 games, mean reward 32.55,  276 frame/episode, eps 0.1, speed 67.95 f/s\n",
            "166640 frames: done 597 games, mean reward 33.33,  280 frame/episode, eps 0.1, speed 69.29 f/s\n",
            "167399 frames: done 600 games, mean reward 33.19,  271 frame/episode, eps 0.1, speed 69.62 f/s\n",
            "  --Try 0: t=289, reward=50.0 Best reward updated\n",
            "  --Try 1: t=292, reward=41.0\n",
            "  --Try 2: t=497, reward=52.0 Best reward updated\n",
            "  --Try 3: t=277, reward=48.0\n",
            "  --Try 4: t=354, reward=48.0\n",
            "  --Try 5: t=291, reward=50.0\n",
            "  --Try 6: t=443, reward=240.0 Best reward updated\n",
            "  --Try 7: t=343, reward=52.0\n",
            "  --Try 8: t=338, reward=52.0\n",
            "  --Try 9: t=346, reward=24.0\n",
            "  --Generating animation..\n",
            " --Animationm from 444 frames with reward 240.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 33.49 -> 33.19, model saved\n",
            "168207 frames: done 603 games, mean reward 33.39,  230 frame/episode, eps 0.1, speed 67.31 f/s\n",
            "169322 frames: done 606 games, mean reward 33.69,  383 frame/episode, eps 0.1, speed 66.15 f/s\n",
            "170190 frames: done 609 games, mean reward 33.78,  285 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "170931 frames: done 612 games, mean reward 33.56,  264 frame/episode, eps 0.1, speed 67.85 f/s\n",
            "171711 frames: done 615 games, mean reward 33.29,  375 frame/episode, eps 0.1, speed 67.04 f/s\n",
            "172443 frames: done 618 games, mean reward 33.25,  204 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "173239 frames: done 621 games, mean reward 33.04,  251 frame/episode, eps 0.1, speed 67.42 f/s\n",
            "173996 frames: done 624 games, mean reward 32.88,  189 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "174675 frames: done 627 games, mean reward 32.27,  217 frame/episode, eps 0.1, speed 66.84 f/s\n",
            "175477 frames: done 630 games, mean reward 31.96,  190 frame/episode, eps 0.1, speed 66.46 f/s\n",
            "176392 frames: done 633 games, mean reward 32.38,  330 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "177194 frames: done 636 games, mean reward 32.23,  301 frame/episode, eps 0.1, speed 66.69 f/s\n",
            "177992 frames: done 639 games, mean reward 32.54,  248 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "178888 frames: done 642 games, mean reward 32.64,  278 frame/episode, eps 0.1, speed 66.39 f/s\n",
            "179704 frames: done 645 games, mean reward 33.36,  308 frame/episode, eps 0.1, speed 66.22 f/s\n",
            "180641 frames: done 648 games, mean reward 33.82,  322 frame/episode, eps 0.1, speed 65.16 f/s\n",
            "181452 frames: done 651 games, mean reward 34.0,  325 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "182206 frames: done 654 games, mean reward 34.32,  274 frame/episode, eps 0.1, speed 66.17 f/s\n",
            "183061 frames: done 657 games, mean reward 34.63,  278 frame/episode, eps 0.1, speed 63.58 f/s\n",
            "183933 frames: done 660 games, mean reward 35.33,  357 frame/episode, eps 0.1, speed 65.67 f/s\n",
            "184486 frames: done 663 games, mean reward 34.88,  124 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "185343 frames: done 666 games, mean reward 34.93,  284 frame/episode, eps 0.1, speed 66.36 f/s\n",
            "186091 frames: done 669 games, mean reward 34.95,  306 frame/episode, eps 0.1, speed 66.26 f/s\n",
            "186954 frames: done 672 games, mean reward 35.32,  249 frame/episode, eps 0.1, speed 65.82 f/s\n",
            "187764 frames: done 675 games, mean reward 35.04,  277 frame/episode, eps 0.1, speed 65.89 f/s\n",
            "188621 frames: done 678 games, mean reward 35.22,  216 frame/episode, eps 0.1, speed 66.43 f/s\n",
            "189455 frames: done 681 games, mean reward 35.45,  324 frame/episode, eps 0.1, speed 66.35 f/s\n",
            "190456 frames: done 684 games, mean reward 35.19,  536 frame/episode, eps 0.1, speed 66.79 f/s\n",
            "191298 frames: done 687 games, mean reward 34.55,  259 frame/episode, eps 0.1, speed 67.3 f/s\n",
            "192031 frames: done 690 games, mean reward 34.47,  282 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "193315 frames: done 693 games, mean reward 34.41,  277 frame/episode, eps 0.1, speed 66.84 f/s\n",
            "194178 frames: done 696 games, mean reward 34.33,  302 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "194971 frames: done 699 games, mean reward 34.48,  289 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "196260 frames: done 702 games, mean reward 34.79,  284 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "197080 frames: done 705 games, mean reward 34.61,  215 frame/episode, eps 0.1, speed 67.16 f/s\n",
            "198029 frames: done 708 games, mean reward 34.76,  379 frame/episode, eps 0.1, speed 66.49 f/s\n",
            "198937 frames: done 711 games, mean reward 34.73,  362 frame/episode, eps 0.1, speed 65.8 f/s\n",
            "199885 frames: done 714 games, mean reward 34.96,  289 frame/episode, eps 0.1, speed 66.93 f/s\n",
            "200801 frames: done 717 games, mean reward 35.59,  269 frame/episode, eps 0.1, speed 67.11 f/s\n",
            "201632 frames: done 720 games, mean reward 36.1,  250 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "202594 frames: done 723 games, mean reward 36.13,  297 frame/episode, eps 0.1, speed 67.3 f/s\n",
            "203304 frames: done 726 games, mean reward 36.52,  340 frame/episode, eps 0.1, speed 65.15 f/s\n",
            "204101 frames: done 729 games, mean reward 36.6,  195 frame/episode, eps 0.1, speed 65.51 f/s\n",
            "204817 frames: done 732 games, mean reward 36.64,  263 frame/episode, eps 0.1, speed 66.42 f/s\n",
            "205700 frames: done 735 games, mean reward 36.52,  258 frame/episode, eps 0.1, speed 67.14 f/s\n",
            "206523 frames: done 738 games, mean reward 36.1,  273 frame/episode, eps 0.1, speed 66.68 f/s\n",
            "207343 frames: done 741 games, mean reward 35.93,  286 frame/episode, eps 0.1, speed 67.35 f/s\n",
            "208178 frames: done 744 games, mean reward 35.97,  235 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "208982 frames: done 747 games, mean reward 35.8,  292 frame/episode, eps 0.1, speed 66.7 f/s\n",
            "209812 frames: done 750 games, mean reward 35.97,  256 frame/episode, eps 0.1, speed 65.47 f/s\n",
            "210561 frames: done 753 games, mean reward 36.13,  217 frame/episode, eps 0.1, speed 66.26 f/s\n",
            "211386 frames: done 756 games, mean reward 36.04,  267 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "212208 frames: done 759 games, mean reward 36.04,  230 frame/episode, eps 0.1, speed 66.4 f/s\n",
            "213099 frames: done 762 games, mean reward 35.98,  242 frame/episode, eps 0.1, speed 67.0 f/s\n",
            "214018 frames: done 765 games, mean reward 36.31,  299 frame/episode, eps 0.1, speed 66.59 f/s\n",
            "214817 frames: done 768 games, mean reward 36.14,  235 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "215700 frames: done 771 games, mean reward 35.88,  363 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "216712 frames: done 774 games, mean reward 36.25,  286 frame/episode, eps 0.1, speed 65.76 f/s\n",
            "217754 frames: done 777 games, mean reward 35.66,  316 frame/episode, eps 0.1, speed 66.13 f/s\n",
            "218718 frames: done 780 games, mean reward 35.87,  332 frame/episode, eps 0.1, speed 65.77 f/s\n",
            "219535 frames: done 783 games, mean reward 35.65,  278 frame/episode, eps 0.1, speed 64.2 f/s\n",
            "220428 frames: done 786 games, mean reward 35.52,  287 frame/episode, eps 0.1, speed 63.0 f/s\n",
            "221273 frames: done 789 games, mean reward 36.2,  285 frame/episode, eps 0.1, speed 65.56 f/s\n",
            "222080 frames: done 792 games, mean reward 35.94,  255 frame/episode, eps 0.1, speed 64.76 f/s\n",
            "222928 frames: done 795 games, mean reward 36.11,  249 frame/episode, eps 0.1, speed 65.48 f/s\n",
            "223723 frames: done 798 games, mean reward 35.61,  276 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "  --Try 0: t=375, reward=68.0 Best reward updated\n",
            "  --Try 1: t=363, reward=41.0\n",
            "  --Try 2: t=338, reward=48.0\n",
            "  --Try 3: t=295, reward=19.0\n",
            "  --Try 4: t=333, reward=38.0\n",
            "  --Try 5: t=334, reward=46.0\n",
            "  --Try 6: t=557, reward=87.0 Best reward updated\n",
            "  --Try 7: t=301, reward=44.0\n",
            "  --Try 8: t=457, reward=44.0\n",
            "  --Try 9: t=537, reward=39.0\n",
            "  --Generating animation..\n",
            " --Animationm from 558 frames with reward 87.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 33.19 -> 35.51, model saved\n",
            "224603 frames: done 801 games, mean reward 35.59,  346 frame/episode, eps 0.1, speed 8.48 f/s\n",
            "225447 frames: done 804 games, mean reward 35.53,  189 frame/episode, eps 0.1, speed 62.8 f/s\n",
            "226320 frames: done 807 games, mean reward 35.11,  301 frame/episode, eps 0.1, speed 63.51 f/s\n",
            "227038 frames: done 810 games, mean reward 34.89,  317 frame/episode, eps 0.1, speed 64.02 f/s\n",
            "228042 frames: done 813 games, mean reward 35.35,  401 frame/episode, eps 0.1, speed 63.59 f/s\n",
            "228865 frames: done 816 games, mean reward 34.55,  316 frame/episode, eps 0.1, speed 64.17 f/s\n",
            "229962 frames: done 819 games, mean reward 34.45,  326 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "230914 frames: done 822 games, mean reward 34.5,  325 frame/episode, eps 0.1, speed 64.09 f/s\n",
            "231844 frames: done 825 games, mean reward 35.26,  313 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "232558 frames: done 828 games, mean reward 34.66,  216 frame/episode, eps 0.1, speed 64.88 f/s\n",
            "233302 frames: done 831 games, mean reward 35.07,  254 frame/episode, eps 0.1, speed 64.15 f/s\n",
            "234164 frames: done 834 games, mean reward 35.28,  358 frame/episode, eps 0.1, speed 62.79 f/s\n",
            "235009 frames: done 837 games, mean reward 35.66,  241 frame/episode, eps 0.1, speed 65.47 f/s\n",
            "235987 frames: done 840 games, mean reward 35.92,  329 frame/episode, eps 0.1, speed 65.07 f/s\n",
            "236816 frames: done 843 games, mean reward 35.95,  216 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "237698 frames: done 846 games, mean reward 36.25,  334 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "238572 frames: done 849 games, mean reward 35.9,  280 frame/episode, eps 0.1, speed 64.53 f/s\n",
            "239418 frames: done 852 games, mean reward 35.6,  277 frame/episode, eps 0.1, speed 65.3 f/s\n",
            "240182 frames: done 855 games, mean reward 35.51,  283 frame/episode, eps 0.1, speed 65.11 f/s\n",
            "240998 frames: done 858 games, mean reward 35.43,  299 frame/episode, eps 0.1, speed 64.28 f/s\n",
            "242099 frames: done 861 games, mean reward 35.86,  295 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "242830 frames: done 864 games, mean reward 35.27,  299 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "243652 frames: done 867 games, mean reward 35.52,  311 frame/episode, eps 0.1, speed 64.22 f/s\n",
            "244567 frames: done 870 games, mean reward 35.51,  309 frame/episode, eps 0.1, speed 64.14 f/s\n",
            "245243 frames: done 873 games, mean reward 35.38,  223 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "246314 frames: done 876 games, mean reward 35.84,  298 frame/episode, eps 0.1, speed 64.76 f/s\n",
            "247255 frames: done 879 games, mean reward 35.75,  250 frame/episode, eps 0.1, speed 64.42 f/s\n",
            "248027 frames: done 882 games, mean reward 35.77,  272 frame/episode, eps 0.1, speed 64.69 f/s\n",
            "248856 frames: done 885 games, mean reward 35.72,  212 frame/episode, eps 0.1, speed 64.56 f/s\n",
            "249683 frames: done 888 games, mean reward 36.05,  280 frame/episode, eps 0.1, speed 65.2 f/s\n",
            "250594 frames: done 891 games, mean reward 35.65,  241 frame/episode, eps 0.1, speed 64.41 f/s\n",
            "251425 frames: done 894 games, mean reward 35.25,  306 frame/episode, eps 0.1, speed 64.58 f/s\n",
            "252324 frames: done 897 games, mean reward 35.85,  281 frame/episode, eps 0.1, speed 64.01 f/s\n",
            "253013 frames: done 900 games, mean reward 35.66,  286 frame/episode, eps 0.1, speed 64.49 f/s\n",
            "253918 frames: done 903 games, mean reward 35.15,  353 frame/episode, eps 0.1, speed 63.01 f/s\n",
            "254915 frames: done 906 games, mean reward 35.67,  246 frame/episode, eps 0.1, speed 63.83 f/s\n",
            "255730 frames: done 909 games, mean reward 36.25,  221 frame/episode, eps 0.1, speed 64.54 f/s\n",
            "256708 frames: done 912 games, mean reward 36.4,  298 frame/episode, eps 0.1, speed 64.71 f/s\n",
            "257454 frames: done 915 games, mean reward 36.27,  280 frame/episode, eps 0.1, speed 65.47 f/s\n",
            "258245 frames: done 918 games, mean reward 36.06,  259 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "259169 frames: done 921 games, mean reward 36.14,  289 frame/episode, eps 0.1, speed 63.86 f/s\n",
            "259901 frames: done 924 games, mean reward 35.7,  205 frame/episode, eps 0.1, speed 63.68 f/s\n",
            "260740 frames: done 927 games, mean reward 35.6,  300 frame/episode, eps 0.1, speed 64.08 f/s\n",
            "261589 frames: done 930 games, mean reward 35.32,  308 frame/episode, eps 0.1, speed 65.01 f/s\n",
            "262490 frames: done 933 games, mean reward 35.33,  368 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "263482 frames: done 936 games, mean reward 35.23,  411 frame/episode, eps 0.1, speed 64.47 f/s\n",
            "264331 frames: done 939 games, mean reward 35.34,  255 frame/episode, eps 0.1, speed 64.63 f/s\n",
            "265448 frames: done 942 games, mean reward 34.89,  138 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "266282 frames: done 945 games, mean reward 34.8,  324 frame/episode, eps 0.1, speed 64.69 f/s\n",
            "267165 frames: done 948 games, mean reward 34.53,  277 frame/episode, eps 0.1, speed 64.77 f/s\n",
            "267892 frames: done 951 games, mean reward 34.56,  298 frame/episode, eps 0.1, speed 65.0 f/s\n",
            "268840 frames: done 954 games, mean reward 35.07,  311 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "269757 frames: done 957 games, mean reward 34.93,  291 frame/episode, eps 0.1, speed 63.66 f/s\n",
            "270593 frames: done 960 games, mean reward 34.86,  299 frame/episode, eps 0.1, speed 64.51 f/s\n",
            "271300 frames: done 963 games, mean reward 34.46,  189 frame/episode, eps 0.1, speed 64.51 f/s\n",
            "272479 frames: done 966 games, mean reward 35.46,  269 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "273340 frames: done 969 games, mean reward 35.74,  298 frame/episode, eps 0.1, speed 65.11 f/s\n",
            "274238 frames: done 972 games, mean reward 35.85,  290 frame/episode, eps 0.1, speed 62.86 f/s\n",
            "275081 frames: done 975 games, mean reward 35.94,  341 frame/episode, eps 0.1, speed 64.3 f/s\n",
            "276051 frames: done 978 games, mean reward 35.94,  299 frame/episode, eps 0.1, speed 64.37 f/s\n",
            "276813 frames: done 981 games, mean reward 35.96,  285 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "277690 frames: done 984 games, mean reward 36.23,  326 frame/episode, eps 0.1, speed 65.42 f/s\n",
            "278723 frames: done 987 games, mean reward 35.8,  338 frame/episode, eps 0.1, speed 64.88 f/s\n",
            "279755 frames: done 990 games, mean reward 36.12,  215 frame/episode, eps 0.1, speed 64.81 f/s\n",
            "280709 frames: done 993 games, mean reward 36.5,  239 frame/episode, eps 0.1, speed 65.46 f/s\n",
            "281512 frames: done 996 games, mean reward 36.19,  253 frame/episode, eps 0.1, speed 65.51 f/s\n",
            "282505 frames: done 999 games, mean reward 36.55,  314 frame/episode, eps 0.1, speed 64.56 f/s\n",
            "  --Try 0: t=260, reward=34.0 Best reward updated\n",
            "  --Try 1: t=233, reward=28.0\n",
            "  --Try 2: t=366, reward=52.0 Best reward updated\n",
            "  --Try 3: t=329, reward=67.0 Best reward updated\n",
            "  --Try 4: t=326, reward=39.0\n",
            "  --Try 5: t=332, reward=55.0\n",
            "  --Try 6: t=319, reward=71.0 Best reward updated\n",
            "  --Try 7: t=315, reward=54.0\n",
            "  --Try 8: t=319, reward=57.0\n",
            "  --Try 9: t=324, reward=44.0\n",
            "  --Generating animation..\n",
            " --Animationm from 320 frames with reward 71.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 35.51 -> 36.26, model saved\n",
            "283202 frames: done 1002 games, mean reward 36.3,  271 frame/episode, eps 0.1, speed 64.41 f/s\n",
            "284221 frames: done 1005 games, mean reward 36.16,  408 frame/episode, eps 0.1, speed 63.95 f/s\n",
            "285018 frames: done 1008 games, mean reward 35.79,  311 frame/episode, eps 0.1, speed 63.98 f/s\n",
            "285972 frames: done 1011 games, mean reward 35.09,  221 frame/episode, eps 0.1, speed 64.88 f/s\n",
            "286577 frames: done 1014 games, mean reward 34.56,  163 frame/episode, eps 0.1, speed 66.01 f/s\n",
            "287388 frames: done 1017 games, mean reward 34.5,  265 frame/episode, eps 0.1, speed 64.85 f/s\n",
            "288122 frames: done 1020 games, mean reward 34.27,  220 frame/episode, eps 0.1, speed 65.83 f/s\n",
            "288985 frames: done 1023 games, mean reward 34.25,  249 frame/episode, eps 0.1, speed 64.89 f/s\n",
            "289850 frames: done 1026 games, mean reward 34.63,  231 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "290746 frames: done 1029 games, mean reward 34.61,  283 frame/episode, eps 0.1, speed 65.93 f/s\n",
            "291721 frames: done 1032 games, mean reward 34.47,  249 frame/episode, eps 0.1, speed 64.4 f/s\n",
            "292483 frames: done 1035 games, mean reward 34.26,  270 frame/episode, eps 0.1, speed 63.16 f/s\n",
            "293358 frames: done 1038 games, mean reward 34.47,  348 frame/episode, eps 0.1, speed 65.94 f/s\n",
            "294187 frames: done 1041 games, mean reward 34.18,  259 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "295234 frames: done 1044 games, mean reward 34.83,  427 frame/episode, eps 0.1, speed 66.35 f/s\n",
            "296116 frames: done 1047 games, mean reward 35.26,  306 frame/episode, eps 0.1, speed 65.91 f/s\n",
            "297150 frames: done 1050 games, mean reward 35.84,  319 frame/episode, eps 0.1, speed 65.72 f/s\n",
            "298003 frames: done 1053 games, mean reward 35.39,  267 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "299099 frames: done 1056 games, mean reward 35.72,  289 frame/episode, eps 0.1, speed 65.44 f/s\n",
            "299845 frames: done 1059 games, mean reward 35.51,  230 frame/episode, eps 0.1, speed 65.46 f/s\n",
            "301103 frames: done 1062 games, mean reward 35.69,  320 frame/episode, eps 0.1, speed 66.2 f/s\n",
            "302033 frames: done 1065 games, mean reward 35.59,  346 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "302909 frames: done 1068 games, mean reward 35.39,  276 frame/episode, eps 0.1, speed 66.38 f/s\n",
            "303738 frames: done 1071 games, mean reward 35.15,  273 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "304495 frames: done 1074 games, mean reward 35.47,  298 frame/episode, eps 0.1, speed 65.93 f/s\n",
            "305358 frames: done 1077 games, mean reward 35.01,  286 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "306332 frames: done 1080 games, mean reward 35.41,  383 frame/episode, eps 0.1, speed 66.29 f/s\n",
            "307230 frames: done 1083 games, mean reward 35.64,  351 frame/episode, eps 0.1, speed 66.92 f/s\n",
            "308185 frames: done 1086 games, mean reward 35.88,  280 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "309134 frames: done 1089 games, mean reward 35.51,  478 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "309824 frames: done 1092 games, mean reward 35.21,  243 frame/episode, eps 0.1, speed 65.66 f/s\n",
            "310712 frames: done 1095 games, mean reward 34.91,  340 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "311713 frames: done 1098 games, mean reward 34.64,  365 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "312524 frames: done 1101 games, mean reward 35.32,  220 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "313375 frames: done 1104 games, mean reward 35.19,  243 frame/episode, eps 0.1, speed 65.44 f/s\n",
            "314122 frames: done 1107 games, mean reward 35.03,  264 frame/episode, eps 0.1, speed 66.33 f/s\n",
            "315018 frames: done 1110 games, mean reward 35.34,  259 frame/episode, eps 0.1, speed 66.27 f/s\n",
            "315787 frames: done 1113 games, mean reward 35.77,  276 frame/episode, eps 0.1, speed 66.25 f/s\n",
            "316750 frames: done 1116 games, mean reward 36.24,  380 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "317616 frames: done 1119 games, mean reward 36.0,  279 frame/episode, eps 0.1, speed 65.86 f/s\n",
            "318480 frames: done 1122 games, mean reward 36.24,  318 frame/episode, eps 0.1, speed 64.98 f/s\n",
            "319344 frames: done 1125 games, mean reward 36.58,  253 frame/episode, eps 0.1, speed 65.91 f/s\n",
            "320339 frames: done 1128 games, mean reward 37.6,  328 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "321193 frames: done 1131 games, mean reward 37.81,  237 frame/episode, eps 0.1, speed 66.33 f/s\n",
            "322192 frames: done 1134 games, mean reward 38.11,  379 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "323069 frames: done 1137 games, mean reward 38.08,  259 frame/episode, eps 0.1, speed 65.22 f/s\n",
            "323980 frames: done 1140 games, mean reward 38.18,  264 frame/episode, eps 0.1, speed 65.3 f/s\n",
            "324894 frames: done 1143 games, mean reward 38.22,  307 frame/episode, eps 0.1, speed 64.56 f/s\n",
            "325619 frames: done 1146 games, mean reward 37.79,  168 frame/episode, eps 0.1, speed 65.02 f/s\n",
            "326467 frames: done 1149 games, mean reward 40.29,  165 frame/episode, eps 0.1, speed 66.01 f/s\n",
            "327493 frames: done 1152 games, mean reward 40.31,  345 frame/episode, eps 0.1, speed 65.69 f/s\n",
            "328346 frames: done 1155 games, mean reward 40.26,  263 frame/episode, eps 0.1, speed 65.87 f/s\n",
            "329198 frames: done 1158 games, mean reward 39.89,  293 frame/episode, eps 0.1, speed 66.19 f/s\n",
            "330218 frames: done 1161 games, mean reward 40.67,  299 frame/episode, eps 0.1, speed 66.01 f/s\n",
            "331073 frames: done 1164 games, mean reward 40.14,  324 frame/episode, eps 0.1, speed 65.36 f/s\n",
            "331945 frames: done 1167 games, mean reward 40.21,  257 frame/episode, eps 0.1, speed 65.54 f/s\n",
            "332772 frames: done 1170 games, mean reward 40.12,  270 frame/episode, eps 0.1, speed 65.18 f/s\n",
            "333736 frames: done 1173 games, mean reward 40.36,  292 frame/episode, eps 0.1, speed 64.97 f/s\n",
            "334603 frames: done 1176 games, mean reward 40.35,  255 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "335355 frames: done 1179 games, mean reward 39.35,  281 frame/episode, eps 0.1, speed 65.65 f/s\n",
            "336402 frames: done 1182 games, mean reward 39.83,  333 frame/episode, eps 0.1, speed 65.13 f/s\n",
            "337155 frames: done 1185 games, mean reward 39.04,  265 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "338010 frames: done 1188 games, mean reward 39.35,  248 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "338671 frames: done 1191 games, mean reward 39.15,  238 frame/episode, eps 0.1, speed 64.48 f/s\n",
            "339612 frames: done 1194 games, mean reward 39.57,  326 frame/episode, eps 0.1, speed 65.67 f/s\n",
            "340413 frames: done 1197 games, mean reward 39.7,  308 frame/episode, eps 0.1, speed 64.96 f/s\n",
            "341377 frames: done 1200 games, mean reward 39.76,  363 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "  --Try 0: t=343, reward=63.0 Best reward updated\n",
            "  --Try 1: t=299, reward=54.0\n",
            "  --Try 2: t=245, reward=36.0\n",
            "  --Try 3: t=289, reward=42.0\n",
            "  --Try 4: t=299, reward=47.0\n",
            "  --Try 5: t=299, reward=42.0\n",
            "  --Try 6: t=368, reward=78.0 Best reward updated\n",
            "  --Try 7: t=326, reward=58.0\n",
            "  --Try 8: t=330, reward=59.0\n",
            "  --Try 9: t=314, reward=54.0\n",
            "  --Generating animation..\n",
            " --Animationm from 369 frames with reward 78.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 36.26 -> 39.76, model saved\n",
            "342425 frames: done 1203 games, mean reward 39.8,  316 frame/episode, eps 0.1, speed 65.3 f/s\n",
            "343218 frames: done 1206 games, mean reward 40.09,  305 frame/episode, eps 0.1, speed 66.03 f/s\n",
            "344202 frames: done 1209 games, mean reward 40.43,  303 frame/episode, eps 0.1, speed 66.25 f/s\n",
            "344965 frames: done 1212 games, mean reward 40.46,  210 frame/episode, eps 0.1, speed 65.01 f/s\n",
            "345801 frames: done 1215 games, mean reward 40.17,  308 frame/episode, eps 0.1, speed 66.18 f/s\n",
            "346472 frames: done 1218 games, mean reward 40.3,  189 frame/episode, eps 0.1, speed 66.45 f/s\n",
            "347471 frames: done 1221 games, mean reward 40.1,  217 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "348186 frames: done 1224 games, mean reward 39.6,  220 frame/episode, eps 0.1, speed 66.85 f/s\n",
            "348997 frames: done 1227 games, mean reward 39.01,  235 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "349703 frames: done 1230 games, mean reward 38.45,  317 frame/episode, eps 0.1, speed 67.15 f/s\n",
            "350349 frames: done 1233 games, mean reward 38.18,  245 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "351188 frames: done 1236 games, mean reward 37.88,  259 frame/episode, eps 0.1, speed 67.06 f/s\n",
            "351919 frames: done 1239 games, mean reward 37.34,  282 frame/episode, eps 0.1, speed 65.41 f/s\n",
            "352692 frames: done 1242 games, mean reward 37.21,  293 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "353760 frames: done 1245 games, mean reward 37.13,  349 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "354583 frames: done 1248 games, mean reward 34.47,  278 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "355384 frames: done 1251 games, mean reward 34.62,  329 frame/episode, eps 0.1, speed 66.58 f/s\n",
            "356095 frames: done 1254 games, mean reward 34.37,  249 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "357055 frames: done 1257 games, mean reward 34.66,  320 frame/episode, eps 0.1, speed 66.59 f/s\n",
            "357903 frames: done 1260 games, mean reward 34.68,  292 frame/episode, eps 0.1, speed 66.96 f/s\n",
            "358646 frames: done 1263 games, mean reward 34.01,  260 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "359483 frames: done 1266 games, mean reward 33.84,  300 frame/episode, eps 0.1, speed 67.29 f/s\n",
            "360408 frames: done 1269 games, mean reward 33.45,  418 frame/episode, eps 0.1, speed 66.63 f/s\n",
            "361355 frames: done 1272 games, mean reward 34.15,  306 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "362284 frames: done 1275 games, mean reward 33.85,  333 frame/episode, eps 0.1, speed 67.12 f/s\n",
            "363125 frames: done 1278 games, mean reward 34.21,  328 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "364008 frames: done 1281 games, mean reward 33.66,  300 frame/episode, eps 0.1, speed 66.76 f/s\n",
            "364739 frames: done 1284 games, mean reward 33.7,  245 frame/episode, eps 0.1, speed 67.15 f/s\n",
            "365497 frames: done 1287 games, mean reward 33.46,  233 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "366175 frames: done 1290 games, mean reward 33.34,  182 frame/episode, eps 0.1, speed 65.16 f/s\n",
            "366790 frames: done 1293 games, mean reward 33.04,  215 frame/episode, eps 0.1, speed 66.17 f/s\n",
            "367532 frames: done 1296 games, mean reward 32.75,  287 frame/episode, eps 0.1, speed 67.23 f/s\n",
            "368445 frames: done 1299 games, mean reward 32.37,  225 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "369312 frames: done 1302 games, mean reward 32.53,  342 frame/episode, eps 0.1, speed 66.83 f/s\n",
            "370216 frames: done 1305 games, mean reward 33.01,  420 frame/episode, eps 0.1, speed 66.58 f/s\n",
            "371339 frames: done 1308 games, mean reward 32.48,  407 frame/episode, eps 0.1, speed 67.19 f/s\n",
            "372061 frames: done 1311 games, mean reward 32.37,  306 frame/episode, eps 0.1, speed 66.51 f/s\n",
            "372916 frames: done 1314 games, mean reward 32.47,  317 frame/episode, eps 0.1, speed 66.94 f/s\n",
            "373742 frames: done 1317 games, mean reward 32.33,  299 frame/episode, eps 0.1, speed 67.87 f/s\n",
            "374550 frames: done 1320 games, mean reward 32.44,  262 frame/episode, eps 0.1, speed 67.57 f/s\n",
            "375349 frames: done 1323 games, mean reward 32.45,  308 frame/episode, eps 0.1, speed 67.82 f/s\n",
            "376296 frames: done 1326 games, mean reward 32.47,  342 frame/episode, eps 0.1, speed 67.4 f/s\n",
            "377168 frames: done 1329 games, mean reward 33.14,  339 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "378081 frames: done 1332 games, mean reward 33.19,  278 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "378677 frames: done 1335 games, mean reward 32.63,  263 frame/episode, eps 0.1, speed 67.64 f/s\n",
            "379594 frames: done 1338 games, mean reward 32.9,  263 frame/episode, eps 0.1, speed 67.54 f/s\n",
            "380335 frames: done 1341 games, mean reward 32.93,  263 frame/episode, eps 0.1, speed 67.6 f/s\n",
            "381096 frames: done 1344 games, mean reward 32.97,  188 frame/episode, eps 0.1, speed 66.75 f/s\n",
            "381958 frames: done 1347 games, mean reward 33.06,  323 frame/episode, eps 0.1, speed 67.84 f/s\n",
            "382791 frames: done 1350 games, mean reward 33.34,  285 frame/episode, eps 0.1, speed 66.77 f/s\n",
            "383555 frames: done 1353 games, mean reward 33.09,  255 frame/episode, eps 0.1, speed 67.2 f/s\n",
            "384433 frames: done 1356 games, mean reward 33.8,  307 frame/episode, eps 0.1, speed 64.01 f/s\n",
            "385284 frames: done 1359 games, mean reward 33.15,  242 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "386060 frames: done 1362 games, mean reward 33.55,  223 frame/episode, eps 0.1, speed 64.35 f/s\n",
            "386879 frames: done 1365 games, mean reward 33.93,  278 frame/episode, eps 0.1, speed 65.31 f/s\n",
            "387791 frames: done 1368 games, mean reward 34.38,  316 frame/episode, eps 0.1, speed 65.18 f/s\n",
            "388632 frames: done 1371 games, mean reward 33.98,  304 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "389471 frames: done 1374 games, mean reward 34.49,  298 frame/episode, eps 0.1, speed 66.64 f/s\n",
            "390575 frames: done 1377 games, mean reward 34.58,  271 frame/episode, eps 0.1, speed 66.82 f/s\n",
            "391247 frames: done 1380 games, mean reward 34.46,  247 frame/episode, eps 0.1, speed 66.78 f/s\n",
            "392164 frames: done 1383 games, mean reward 34.51,  247 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "392959 frames: done 1386 games, mean reward 34.6,  300 frame/episode, eps 0.1, speed 64.54 f/s\n",
            "393880 frames: done 1389 games, mean reward 34.97,  241 frame/episode, eps 0.1, speed 66.58 f/s\n",
            "394761 frames: done 1392 games, mean reward 35.23,  264 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "395737 frames: done 1395 games, mean reward 35.75,  482 frame/episode, eps 0.1, speed 67.31 f/s\n",
            "396645 frames: done 1398 games, mean reward 35.78,  331 frame/episode, eps 0.1, speed 66.89 f/s\n",
            "  --Try 0: t=236, reward=32.0 Best reward updated\n",
            "  --Try 1: t=258, reward=43.0 Best reward updated\n",
            "  --Try 2: t=356, reward=59.0 Best reward updated\n",
            "  --Try 3: t=298, reward=57.0\n",
            "  --Try 4: t=340, reward=54.0\n",
            "  --Try 5: t=339, reward=57.0\n",
            "  --Try 6: t=226, reward=25.0\n",
            "  --Try 7: t=270, reward=9.0\n",
            "  --Try 8: t=282, reward=49.0\n",
            "  --Try 9: t=450, reward=60.0 Best reward updated\n",
            "  --Generating animation..\n",
            " --Animationm from 451 frames with reward 60.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 39.76 -> 35.72, model saved\n",
            "397420 frames: done 1401 games, mean reward 35.68,  293 frame/episode, eps 0.1, speed 6.96 f/s\n",
            "398377 frames: done 1404 games, mean reward 36.05,  299 frame/episode, eps 0.1, speed 65.97 f/s\n",
            "399332 frames: done 1407 games, mean reward 35.12,  402 frame/episode, eps 0.1, speed 67.12 f/s\n",
            "400207 frames: done 1410 games, mean reward 35.16,  227 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "401160 frames: done 1413 games, mean reward 35.85,  325 frame/episode, eps 0.1, speed 66.41 f/s\n",
            "401952 frames: done 1416 games, mean reward 35.86,  238 frame/episode, eps 0.1, speed 65.59 f/s\n",
            "402712 frames: done 1419 games, mean reward 35.79,  270 frame/episode, eps 0.1, speed 66.08 f/s\n",
            "403529 frames: done 1422 games, mean reward 35.8,  240 frame/episode, eps 0.1, speed 66.28 f/s\n",
            "404540 frames: done 1425 games, mean reward 35.96,  303 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "405395 frames: done 1428 games, mean reward 35.67,  288 frame/episode, eps 0.1, speed 67.62 f/s\n",
            "406220 frames: done 1431 games, mean reward 35.67,  261 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "406962 frames: done 1434 games, mean reward 36.03,  251 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "407790 frames: done 1437 games, mean reward 36.28,  291 frame/episode, eps 0.1, speed 66.58 f/s\n",
            "408561 frames: done 1440 games, mean reward 36.21,  279 frame/episode, eps 0.1, speed 67.01 f/s\n",
            "409561 frames: done 1443 games, mean reward 37.13,  265 frame/episode, eps 0.1, speed 67.49 f/s\n",
            "410393 frames: done 1446 games, mean reward 37.14,  312 frame/episode, eps 0.1, speed 66.91 f/s\n",
            "411455 frames: done 1449 games, mean reward 36.55,  254 frame/episode, eps 0.1, speed 63.85 f/s\n",
            "412208 frames: done 1452 games, mean reward 36.17,  237 frame/episode, eps 0.1, speed 61.46 f/s\n",
            "413235 frames: done 1455 games, mean reward 35.94,  284 frame/episode, eps 0.1, speed 64.8 f/s\n",
            "414038 frames: done 1458 games, mean reward 35.98,  326 frame/episode, eps 0.1, speed 63.58 f/s\n",
            "414848 frames: done 1461 games, mean reward 35.94,  261 frame/episode, eps 0.1, speed 65.29 f/s\n",
            "415574 frames: done 1464 games, mean reward 35.92,  201 frame/episode, eps 0.1, speed 63.77 f/s\n",
            "416297 frames: done 1467 games, mean reward 35.6,  300 frame/episode, eps 0.1, speed 64.86 f/s\n",
            "417119 frames: done 1470 games, mean reward 35.64,  318 frame/episode, eps 0.1, speed 62.14 f/s\n",
            "418135 frames: done 1473 games, mean reward 35.48,  366 frame/episode, eps 0.1, speed 63.55 f/s\n",
            "418893 frames: done 1476 games, mean reward 35.17,  299 frame/episode, eps 0.1, speed 62.59 f/s\n",
            "419565 frames: done 1479 games, mean reward 35.18,  123 frame/episode, eps 0.1, speed 63.3 f/s\n",
            "420294 frames: done 1482 games, mean reward 35.04,  169 frame/episode, eps 0.1, speed 64.92 f/s\n",
            "421382 frames: done 1485 games, mean reward 34.99,  343 frame/episode, eps 0.1, speed 65.92 f/s\n",
            "422195 frames: done 1488 games, mean reward 35.3,  219 frame/episode, eps 0.1, speed 64.81 f/s\n",
            "423060 frames: done 1491 games, mean reward 35.7,  245 frame/episode, eps 0.1, speed 65.85 f/s\n",
            "423948 frames: done 1494 games, mean reward 36.18,  227 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "424946 frames: done 1497 games, mean reward 36.77,  377 frame/episode, eps 0.1, speed 67.68 f/s\n",
            "425897 frames: done 1500 games, mean reward 36.9,  210 frame/episode, eps 0.1, speed 67.29 f/s\n",
            "426671 frames: done 1503 games, mean reward 36.36,  234 frame/episode, eps 0.1, speed 65.99 f/s\n",
            "427726 frames: done 1506 games, mean reward 36.29,  400 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "428714 frames: done 1509 games, mean reward 36.79,  379 frame/episode, eps 0.1, speed 67.0 f/s\n",
            "429626 frames: done 1512 games, mean reward 36.53,  347 frame/episode, eps 0.1, speed 67.39 f/s\n",
            "430244 frames: done 1515 games, mean reward 35.92,  121 frame/episode, eps 0.1, speed 66.23 f/s\n",
            "431239 frames: done 1518 games, mean reward 36.68,  289 frame/episode, eps 0.1, speed 65.16 f/s\n",
            "431926 frames: done 1521 games, mean reward 36.61,  216 frame/episode, eps 0.1, speed 65.16 f/s\n",
            "432889 frames: done 1524 games, mean reward 36.17,  266 frame/episode, eps 0.1, speed 65.64 f/s\n",
            "433725 frames: done 1527 games, mean reward 36.63,  299 frame/episode, eps 0.1, speed 66.18 f/s\n",
            "434511 frames: done 1530 games, mean reward 36.09,  212 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "435404 frames: done 1533 games, mean reward 35.92,  359 frame/episode, eps 0.1, speed 66.94 f/s\n",
            "436285 frames: done 1536 games, mean reward 35.99,  250 frame/episode, eps 0.1, speed 66.66 f/s\n",
            "437101 frames: done 1539 games, mean reward 36.13,  239 frame/episode, eps 0.1, speed 66.07 f/s\n",
            "437832 frames: done 1542 games, mean reward 35.22,  290 frame/episode, eps 0.1, speed 66.51 f/s\n",
            "438571 frames: done 1545 games, mean reward 34.75,  265 frame/episode, eps 0.1, speed 65.02 f/s\n",
            "439359 frames: done 1548 games, mean reward 34.93,  299 frame/episode, eps 0.1, speed 66.45 f/s\n",
            "440189 frames: done 1551 games, mean reward 35.13,  280 frame/episode, eps 0.1, speed 67.23 f/s\n",
            "440863 frames: done 1554 games, mean reward 35.27,  192 frame/episode, eps 0.1, speed 66.77 f/s\n",
            "441716 frames: done 1557 games, mean reward 34.82,  234 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "442564 frames: done 1560 games, mean reward 35.0,  198 frame/episode, eps 0.1, speed 66.94 f/s\n",
            "443403 frames: done 1563 games, mean reward 35.18,  253 frame/episode, eps 0.1, speed 65.68 f/s\n",
            "444417 frames: done 1566 games, mean reward 38.01,  498 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "445439 frames: done 1569 games, mean reward 38.41,  349 frame/episode, eps 0.1, speed 66.64 f/s\n",
            "446438 frames: done 1572 games, mean reward 38.06,  292 frame/episode, eps 0.1, speed 65.57 f/s\n",
            "447074 frames: done 1575 games, mean reward 38.12,  153 frame/episode, eps 0.1, speed 67.03 f/s\n",
            "447854 frames: done 1578 games, mean reward 37.6,  269 frame/episode, eps 0.1, speed 65.93 f/s\n",
            "448719 frames: done 1581 games, mean reward 37.71,  215 frame/episode, eps 0.1, speed 66.4 f/s\n",
            "449636 frames: done 1584 games, mean reward 37.84,  249 frame/episode, eps 0.1, speed 67.01 f/s\n",
            "450572 frames: done 1587 games, mean reward 37.6,  309 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "451275 frames: done 1590 games, mean reward 36.98,  197 frame/episode, eps 0.1, speed 64.68 f/s\n",
            "452254 frames: done 1593 games, mean reward 37.03,  329 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "453149 frames: done 1596 games, mean reward 37.69,  352 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "453781 frames: done 1599 games, mean reward 36.65,  123 frame/episode, eps 0.1, speed 66.1 f/s\n",
            "  --Try 0: t=317, reward=49.0 Best reward updated\n",
            "  --Try 1: t=280, reward=46.0\n",
            "  --Try 2: t=368, reward=101.0 Best reward updated\n",
            "  --Try 3: t=292, reward=30.0\n",
            "  --Try 4: t=278, reward=46.0\n",
            "  --Try 5: t=295, reward=48.0\n",
            "  --Try 6: t=384, reward=102.0 Best reward updated\n",
            "  --Try 7: t=217, reward=19.0\n",
            "  --Try 8: t=612, reward=40.0\n",
            "  --Try 9: t=349, reward=87.0\n",
            "  --Generating animation..\n",
            " --Animationm from 385 frames with reward 102.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 35.72 -> 36.89, model saved\n",
            "454627 frames: done 1602 games, mean reward 37.51,  261 frame/episode, eps 0.1, speed 67.18 f/s\n",
            "455567 frames: done 1605 games, mean reward 37.97,  286 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "456490 frames: done 1608 games, mean reward 37.89,  299 frame/episode, eps 0.1, speed 67.66 f/s\n",
            "457282 frames: done 1611 games, mean reward 37.91,  310 frame/episode, eps 0.1, speed 65.34 f/s\n",
            "458124 frames: done 1614 games, mean reward 37.36,  228 frame/episode, eps 0.1, speed 67.18 f/s\n",
            "459050 frames: done 1617 games, mean reward 37.53,  336 frame/episode, eps 0.1, speed 67.39 f/s\n",
            "459905 frames: done 1620 games, mean reward 37.39,  283 frame/episode, eps 0.1, speed 66.09 f/s\n",
            "460667 frames: done 1623 games, mean reward 37.12,  253 frame/episode, eps 0.1, speed 65.96 f/s\n",
            "461804 frames: done 1626 games, mean reward 37.48,  627 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "462833 frames: done 1629 games, mean reward 37.93,  453 frame/episode, eps 0.1, speed 65.67 f/s\n",
            "463789 frames: done 1632 games, mean reward 38.62,  299 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "464733 frames: done 1635 games, mean reward 39.43,  291 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "465487 frames: done 1638 games, mean reward 39.27,  265 frame/episode, eps 0.1, speed 66.78 f/s\n",
            "466381 frames: done 1641 games, mean reward 39.67,  287 frame/episode, eps 0.1, speed 67.61 f/s\n",
            "467035 frames: done 1644 games, mean reward 39.48,  228 frame/episode, eps 0.1, speed 66.77 f/s\n",
            "467785 frames: done 1647 games, mean reward 39.22,  202 frame/episode, eps 0.1, speed 66.03 f/s\n",
            "468710 frames: done 1650 games, mean reward 38.94,  251 frame/episode, eps 0.1, speed 66.19 f/s\n",
            "469645 frames: done 1653 games, mean reward 39.55,  339 frame/episode, eps 0.1, speed 67.36 f/s\n",
            "470451 frames: done 1656 games, mean reward 40.09,  258 frame/episode, eps 0.1, speed 65.09 f/s\n",
            "471243 frames: done 1659 games, mean reward 39.43,  191 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "471794 frames: done 1662 games, mean reward 38.8,  221 frame/episode, eps 0.1, speed 66.67 f/s\n",
            "472688 frames: done 1665 games, mean reward 39.63,  246 frame/episode, eps 0.1, speed 65.8 f/s\n",
            "473407 frames: done 1668 games, mean reward 36.95,  166 frame/episode, eps 0.1, speed 65.61 f/s\n",
            "474269 frames: done 1671 games, mean reward 37.2,  348 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "475051 frames: done 1674 games, mean reward 36.49,  235 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "475958 frames: done 1677 games, mean reward 37.55,  314 frame/episode, eps 0.1, speed 66.66 f/s\n",
            "476646 frames: done 1680 games, mean reward 37.23,  275 frame/episode, eps 0.1, speed 66.66 f/s\n",
            "477438 frames: done 1683 games, mean reward 37.48,  323 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "478380 frames: done 1686 games, mean reward 37.26,  349 frame/episode, eps 0.1, speed 66.24 f/s\n",
            "479207 frames: done 1689 games, mean reward 37.41,  283 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "479943 frames: done 1692 games, mean reward 36.73,  220 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "481000 frames: done 1695 games, mean reward 36.82,  347 frame/episode, eps 0.1, speed 66.96 f/s\n",
            "481642 frames: done 1698 games, mean reward 35.73,  150 frame/episode, eps 0.1, speed 66.65 f/s\n",
            "482569 frames: done 1701 games, mean reward 35.8,  296 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "483398 frames: done 1704 games, mean reward 35.7,  274 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "484133 frames: done 1707 games, mean reward 34.91,  311 frame/episode, eps 0.1, speed 66.29 f/s\n",
            "485030 frames: done 1710 games, mean reward 35.24,  278 frame/episode, eps 0.1, speed 67.33 f/s\n",
            "485856 frames: done 1713 games, mean reward 35.28,  221 frame/episode, eps 0.1, speed 67.81 f/s\n",
            "486635 frames: done 1716 games, mean reward 34.46,  172 frame/episode, eps 0.1, speed 67.49 f/s\n",
            "487573 frames: done 1719 games, mean reward 34.04,  276 frame/episode, eps 0.1, speed 68.02 f/s\n",
            "488235 frames: done 1722 games, mean reward 34.0,  272 frame/episode, eps 0.1, speed 67.22 f/s\n",
            "489006 frames: done 1725 games, mean reward 33.95,  300 frame/episode, eps 0.1, speed 66.67 f/s\n",
            "489747 frames: done 1728 games, mean reward 33.49,  260 frame/episode, eps 0.1, speed 66.93 f/s\n",
            "490472 frames: done 1731 games, mean reward 32.6,  288 frame/episode, eps 0.1, speed 67.14 f/s\n",
            "491275 frames: done 1734 games, mean reward 31.66,  290 frame/episode, eps 0.1, speed 65.44 f/s\n",
            "492173 frames: done 1737 games, mean reward 31.6,  304 frame/episode, eps 0.1, speed 67.42 f/s\n",
            "493049 frames: done 1740 games, mean reward 31.51,  366 frame/episode, eps 0.1, speed 66.84 f/s\n",
            "493731 frames: done 1743 games, mean reward 31.17,  235 frame/episode, eps 0.1, speed 66.88 f/s\n",
            "494367 frames: done 1746 games, mean reward 31.18,  231 frame/episode, eps 0.1, speed 66.53 f/s\n",
            "495051 frames: done 1749 games, mean reward 31.22,  170 frame/episode, eps 0.1, speed 66.37 f/s\n",
            "496031 frames: done 1752 games, mean reward 31.53,  311 frame/episode, eps 0.1, speed 67.1 f/s\n",
            "496802 frames: done 1755 games, mean reward 30.93,  297 frame/episode, eps 0.1, speed 66.5 f/s\n",
            "497483 frames: done 1758 games, mean reward 30.74,  260 frame/episode, eps 0.1, speed 65.82 f/s\n",
            "498359 frames: done 1761 games, mean reward 31.49,  198 frame/episode, eps 0.1, speed 67.41 f/s\n",
            "499116 frames: done 1764 games, mean reward 30.42,  264 frame/episode, eps 0.1, speed 67.58 f/s\n",
            "499865 frames: done 1767 games, mean reward 29.88,  242 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "500849 frames: done 1770 games, mean reward 30.63,  330 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "501657 frames: done 1773 games, mean reward 30.91,  255 frame/episode, eps 0.1, speed 67.87 f/s\n",
            "502462 frames: done 1776 games, mean reward 30.78,  275 frame/episode, eps 0.1, speed 68.09 f/s\n",
            "503303 frames: done 1779 games, mean reward 31.03,  290 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "504058 frames: done 1782 games, mean reward 31.1,  229 frame/episode, eps 0.1, speed 67.91 f/s\n",
            "504911 frames: done 1785 games, mean reward 30.64,  209 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "505669 frames: done 1788 games, mean reward 30.85,  247 frame/episode, eps 0.1, speed 65.53 f/s\n",
            "506538 frames: done 1791 games, mean reward 30.75,  259 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "507282 frames: done 1794 games, mean reward 30.64,  313 frame/episode, eps 0.1, speed 63.99 f/s\n",
            "508064 frames: done 1797 games, mean reward 30.76,  218 frame/episode, eps 0.1, speed 66.75 f/s\n",
            "508908 frames: done 1800 games, mean reward 31.1,  319 frame/episode, eps 0.1, speed 66.94 f/s\n",
            "  --Try 0: t=242, reward=17.0 Best reward updated\n",
            "  --Try 1: t=341, reward=17.0\n",
            "  --Try 2: t=314, reward=34.0 Best reward updated\n",
            "  --Try 3: t=273, reward=38.0 Best reward updated\n",
            "  --Try 4: t=196, reward=12.0\n",
            "  --Try 5: t=497, reward=31.0\n",
            "  --Try 6: t=293, reward=19.0\n",
            "  --Try 7: t=339, reward=39.0 Best reward updated\n",
            "  --Try 8: t=209, reward=24.0\n",
            "  --Try 9: t=297, reward=30.0\n",
            "  --Generating animation..\n",
            " --Animationm from 340 frames with reward 39.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 36.89 -> 31.1, model saved\n",
            "509636 frames: done 1803 games, mean reward 30.73,  202 frame/episode, eps 0.1, speed 66.97 f/s\n",
            "510346 frames: done 1806 games, mean reward 30.7,  247 frame/episode, eps 0.1, speed 67.48 f/s\n",
            "511094 frames: done 1809 games, mean reward 30.03,  257 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "512034 frames: done 1812 games, mean reward 32.46,  389 frame/episode, eps 0.1, speed 67.93 f/s\n",
            "512760 frames: done 1815 games, mean reward 32.68,  220 frame/episode, eps 0.1, speed 67.23 f/s\n",
            "513594 frames: done 1818 games, mean reward 33.12,  252 frame/episode, eps 0.1, speed 65.87 f/s\n",
            "514288 frames: done 1821 games, mean reward 33.47,  171 frame/episode, eps 0.1, speed 65.82 f/s\n",
            "515177 frames: done 1824 games, mean reward 33.95,  299 frame/episode, eps 0.1, speed 66.93 f/s\n",
            "515970 frames: done 1827 games, mean reward 33.78,  263 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "516897 frames: done 1830 games, mean reward 33.71,  324 frame/episode, eps 0.1, speed 67.3 f/s\n",
            "517724 frames: done 1833 games, mean reward 33.9,  260 frame/episode, eps 0.1, speed 67.45 f/s\n",
            "518566 frames: done 1836 games, mean reward 34.32,  300 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "519284 frames: done 1839 games, mean reward 34.18,  184 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "520086 frames: done 1842 games, mean reward 34.18,  284 frame/episode, eps 0.1, speed 67.13 f/s\n",
            "520961 frames: done 1845 games, mean reward 34.67,  317 frame/episode, eps 0.1, speed 67.33 f/s\n",
            "521673 frames: done 1848 games, mean reward 34.47,  220 frame/episode, eps 0.1, speed 66.97 f/s\n",
            "522458 frames: done 1851 games, mean reward 34.53,  300 frame/episode, eps 0.1, speed 67.22 f/s\n",
            "523429 frames: done 1854 games, mean reward 34.82,  233 frame/episode, eps 0.1, speed 67.27 f/s\n",
            "524147 frames: done 1857 games, mean reward 34.92,  260 frame/episode, eps 0.1, speed 65.74 f/s\n",
            "524832 frames: done 1860 games, mean reward 34.12,  216 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "525564 frames: done 1863 games, mean reward 34.4,  285 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "526567 frames: done 1866 games, mean reward 34.83,  313 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "527276 frames: done 1869 games, mean reward 34.44,  231 frame/episode, eps 0.1, speed 67.17 f/s\n",
            "528053 frames: done 1872 games, mean reward 34.0,  263 frame/episode, eps 0.1, speed 67.4 f/s\n",
            "528980 frames: done 1875 games, mean reward 34.21,  343 frame/episode, eps 0.1, speed 67.27 f/s\n",
            "529724 frames: done 1878 games, mean reward 33.8,  197 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "530555 frames: done 1881 games, mean reward 33.9,  315 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "531380 frames: done 1884 games, mean reward 33.96,  227 frame/episode, eps 0.1, speed 67.35 f/s\n",
            "532233 frames: done 1887 games, mean reward 34.0,  261 frame/episode, eps 0.1, speed 67.41 f/s\n",
            "533178 frames: done 1890 games, mean reward 33.68,  369 frame/episode, eps 0.1, speed 67.4 f/s\n",
            "534023 frames: done 1893 games, mean reward 33.99,  245 frame/episode, eps 0.1, speed 67.59 f/s\n",
            "534860 frames: done 1896 games, mean reward 33.53,  266 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "535700 frames: done 1899 games, mean reward 33.89,  277 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "536427 frames: done 1902 games, mean reward 33.72,  266 frame/episode, eps 0.1, speed 67.21 f/s\n",
            "537241 frames: done 1905 games, mean reward 34.06,  260 frame/episode, eps 0.1, speed 66.63 f/s\n",
            "538029 frames: done 1908 games, mean reward 34.26,  312 frame/episode, eps 0.1, speed 67.53 f/s\n",
            "538841 frames: done 1911 games, mean reward 34.45,  201 frame/episode, eps 0.1, speed 66.87 f/s\n",
            "539607 frames: done 1914 games, mean reward 32.3,  298 frame/episode, eps 0.1, speed 67.19 f/s\n",
            "540364 frames: done 1917 games, mean reward 32.46,  249 frame/episode, eps 0.1, speed 66.09 f/s\n",
            "541314 frames: done 1920 games, mean reward 32.24,  282 frame/episode, eps 0.1, speed 67.15 f/s\n",
            "542064 frames: done 1923 games, mean reward 32.38,  233 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "542844 frames: done 1926 games, mean reward 32.19,  223 frame/episode, eps 0.1, speed 67.52 f/s\n",
            "543871 frames: done 1929 games, mean reward 33.03,  334 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "544710 frames: done 1932 games, mean reward 33.27,  272 frame/episode, eps 0.1, speed 67.04 f/s\n",
            "545578 frames: done 1935 games, mean reward 33.34,  256 frame/episode, eps 0.1, speed 66.56 f/s\n",
            "546308 frames: done 1938 games, mean reward 32.99,  178 frame/episode, eps 0.1, speed 66.49 f/s\n",
            "547154 frames: done 1941 games, mean reward 33.32,  329 frame/episode, eps 0.1, speed 67.8 f/s\n",
            "547902 frames: done 1944 games, mean reward 33.28,  204 frame/episode, eps 0.1, speed 67.11 f/s\n",
            "548770 frames: done 1947 games, mean reward 33.79,  312 frame/episode, eps 0.1, speed 67.9 f/s\n",
            "549563 frames: done 1950 games, mean reward 34.09,  260 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "550478 frames: done 1953 games, mean reward 33.74,  318 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "551384 frames: done 1956 games, mean reward 33.94,  331 frame/episode, eps 0.1, speed 66.4 f/s\n",
            "552008 frames: done 1959 games, mean reward 33.52,  234 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "552802 frames: done 1962 games, mean reward 33.64,  389 frame/episode, eps 0.1, speed 67.58 f/s\n",
            "553531 frames: done 1965 games, mean reward 33.36,  221 frame/episode, eps 0.1, speed 66.68 f/s\n",
            "554337 frames: done 1968 games, mean reward 33.47,  260 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "555292 frames: done 1971 games, mean reward 34.43,  306 frame/episode, eps 0.1, speed 67.06 f/s\n",
            "556257 frames: done 1974 games, mean reward 34.64,  293 frame/episode, eps 0.1, speed 66.67 f/s\n",
            "557137 frames: done 1977 games, mean reward 34.84,  285 frame/episode, eps 0.1, speed 67.3 f/s\n",
            "558019 frames: done 1980 games, mean reward 35.36,  305 frame/episode, eps 0.1, speed 67.4 f/s\n",
            "558859 frames: done 1983 games, mean reward 35.21,  204 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "559583 frames: done 1986 games, mean reward 35.0,  138 frame/episode, eps 0.1, speed 67.25 f/s\n",
            "560377 frames: done 1989 games, mean reward 35.18,  260 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "561062 frames: done 1992 games, mean reward 34.83,  212 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "561870 frames: done 1995 games, mean reward 35.19,  254 frame/episode, eps 0.1, speed 62.72 f/s\n",
            "562724 frames: done 1998 games, mean reward 35.44,  319 frame/episode, eps 0.1, speed 66.98 f/s\n",
            "  --Try 0: t=319, reward=54.0 Best reward updated\n",
            "  --Try 1: t=357, reward=50.0\n",
            "  --Try 2: t=262, reward=38.0\n",
            "  --Try 3: t=310, reward=56.0 Best reward updated\n",
            "  --Try 4: t=242, reward=35.0\n",
            "  --Try 5: t=304, reward=58.0 Best reward updated\n",
            "  --Try 6: t=388, reward=195.0 Best reward updated\n",
            "  --Try 7: t=262, reward=41.0\n",
            "  --Try 8: t=245, reward=27.0\n",
            "  --Try 9: t=437, reward=32.0\n",
            "  --Generating animation..\n",
            " --Animationm from 389 frames with reward 195.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 31.1 -> 35.4, model saved\n",
            "563591 frames: done 2001 games, mean reward 35.84,  354 frame/episode, eps 0.1, speed 7.45 f/s\n",
            "564495 frames: done 2004 games, mean reward 36.15,  354 frame/episode, eps 0.1, speed 61.59 f/s\n",
            "565255 frames: done 2007 games, mean reward 36.17,  280 frame/episode, eps 0.1, speed 61.33 f/s\n",
            "566124 frames: done 2010 games, mean reward 35.58,  271 frame/episode, eps 0.1, speed 66.88 f/s\n",
            "566872 frames: done 2013 games, mean reward 35.59,  271 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "567731 frames: done 2016 games, mean reward 35.95,  276 frame/episode, eps 0.1, speed 65.95 f/s\n",
            "568604 frames: done 2019 games, mean reward 36.16,  246 frame/episode, eps 0.1, speed 65.53 f/s\n",
            "569399 frames: done 2022 games, mean reward 36.4,  319 frame/episode, eps 0.1, speed 65.36 f/s\n",
            "570213 frames: done 2025 games, mean reward 36.29,  317 frame/episode, eps 0.1, speed 66.7 f/s\n",
            "571127 frames: done 2028 games, mean reward 36.34,  283 frame/episode, eps 0.1, speed 66.29 f/s\n",
            "572237 frames: done 2031 games, mean reward 36.43,  473 frame/episode, eps 0.1, speed 67.0 f/s\n",
            "573031 frames: done 2034 games, mean reward 36.41,  317 frame/episode, eps 0.1, speed 67.05 f/s\n",
            "573747 frames: done 2037 games, mean reward 36.48,  182 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "574678 frames: done 2040 games, mean reward 36.89,  313 frame/episode, eps 0.1, speed 66.13 f/s\n",
            "575688 frames: done 2043 games, mean reward 37.15,  313 frame/episode, eps 0.1, speed 67.26 f/s\n",
            "576538 frames: done 2046 games, mean reward 38.39,  161 frame/episode, eps 0.1, speed 67.57 f/s\n",
            "577361 frames: done 2049 games, mean reward 38.09,  269 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "578254 frames: done 2052 games, mean reward 37.63,  273 frame/episode, eps 0.1, speed 67.16 f/s\n",
            "579147 frames: done 2055 games, mean reward 37.5,  291 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "580200 frames: done 2058 games, mean reward 39.73,  298 frame/episode, eps 0.1, speed 65.46 f/s\n",
            "581014 frames: done 2061 games, mean reward 40.37,  298 frame/episode, eps 0.1, speed 66.84 f/s\n",
            "581602 frames: done 2064 games, mean reward 39.71,  271 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "582502 frames: done 2067 games, mean reward 39.91,  325 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "583241 frames: done 2070 games, mean reward 39.29,  145 frame/episode, eps 0.1, speed 66.23 f/s\n",
            "584206 frames: done 2073 games, mean reward 38.88,  255 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "585034 frames: done 2076 games, mean reward 38.59,  212 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "585847 frames: done 2079 games, mean reward 38.26,  322 frame/episode, eps 0.1, speed 65.82 f/s\n",
            "586728 frames: done 2082 games, mean reward 37.85,  386 frame/episode, eps 0.1, speed 66.96 f/s\n",
            "587633 frames: done 2085 games, mean reward 38.91,  360 frame/episode, eps 0.1, speed 66.57 f/s\n",
            "588470 frames: done 2088 games, mean reward 39.26,  253 frame/episode, eps 0.1, speed 66.65 f/s\n",
            "589179 frames: done 2091 games, mean reward 39.49,  228 frame/episode, eps 0.1, speed 63.77 f/s\n",
            "589966 frames: done 2094 games, mean reward 39.76,  307 frame/episode, eps 0.1, speed 66.09 f/s\n",
            "590889 frames: done 2097 games, mean reward 39.43,  287 frame/episode, eps 0.1, speed 65.6 f/s\n",
            "591646 frames: done 2100 games, mean reward 39.3,  304 frame/episode, eps 0.1, speed 65.46 f/s\n",
            "592600 frames: done 2103 games, mean reward 38.9,  277 frame/episode, eps 0.1, speed 66.78 f/s\n",
            "593687 frames: done 2106 games, mean reward 39.48,  340 frame/episode, eps 0.1, speed 66.66 f/s\n",
            "594630 frames: done 2109 games, mean reward 39.62,  321 frame/episode, eps 0.1, speed 66.66 f/s\n",
            "595512 frames: done 2112 games, mean reward 39.98,  230 frame/episode, eps 0.1, speed 66.59 f/s\n",
            "596439 frames: done 2115 games, mean reward 39.77,  250 frame/episode, eps 0.1, speed 66.1 f/s\n",
            "597279 frames: done 2118 games, mean reward 39.76,  403 frame/episode, eps 0.1, speed 66.88 f/s\n",
            "598573 frames: done 2121 games, mean reward 39.95,  246 frame/episode, eps 0.1, speed 66.35 f/s\n",
            "599384 frames: done 2124 games, mean reward 39.39,  142 frame/episode, eps 0.1, speed 67.04 f/s\n",
            "600148 frames: done 2127 games, mean reward 39.8,  329 frame/episode, eps 0.1, speed 66.7 f/s\n",
            "601131 frames: done 2130 games, mean reward 39.9,  291 frame/episode, eps 0.1, speed 66.35 f/s\n",
            "601887 frames: done 2133 games, mean reward 39.59,  215 frame/episode, eps 0.1, speed 65.41 f/s\n",
            "602661 frames: done 2136 games, mean reward 38.92,  291 frame/episode, eps 0.1, speed 66.85 f/s\n",
            "603451 frames: done 2139 games, mean reward 38.5,  316 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "604296 frames: done 2142 games, mean reward 38.1,  350 frame/episode, eps 0.1, speed 65.77 f/s\n",
            "604909 frames: done 2145 games, mean reward 36.12,  207 frame/episode, eps 0.1, speed 66.52 f/s\n",
            "605597 frames: done 2148 games, mean reward 36.3,  190 frame/episode, eps 0.1, speed 65.9 f/s\n",
            "606622 frames: done 2151 games, mean reward 36.69,  428 frame/episode, eps 0.1, speed 66.09 f/s\n",
            "607552 frames: done 2154 games, mean reward 37.26,  299 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "608504 frames: done 2157 games, mean reward 36.31,  352 frame/episode, eps 0.1, speed 65.47 f/s\n",
            "609282 frames: done 2160 games, mean reward 36.13,  235 frame/episode, eps 0.1, speed 65.18 f/s\n",
            "610266 frames: done 2163 games, mean reward 36.85,  270 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "611212 frames: done 2166 games, mean reward 36.24,  289 frame/episode, eps 0.1, speed 66.2 f/s\n",
            "612174 frames: done 2169 games, mean reward 36.22,  254 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "613220 frames: done 2172 games, mean reward 37.0,  290 frame/episode, eps 0.1, speed 67.05 f/s\n",
            "613927 frames: done 2175 games, mean reward 36.79,  207 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "614733 frames: done 2178 games, mean reward 37.35,  303 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "615579 frames: done 2181 games, mean reward 37.22,  361 frame/episode, eps 0.1, speed 66.68 f/s\n",
            "616435 frames: done 2184 games, mean reward 37.34,  332 frame/episode, eps 0.1, speed 66.86 f/s\n",
            "617273 frames: done 2187 games, mean reward 36.93,  234 frame/episode, eps 0.1, speed 66.69 f/s\n",
            "617957 frames: done 2190 games, mean reward 36.81,  226 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "619163 frames: done 2193 games, mean reward 37.1,  548 frame/episode, eps 0.1, speed 66.9 f/s\n",
            "619871 frames: done 2196 games, mean reward 37.05,  261 frame/episode, eps 0.1, speed 66.12 f/s\n",
            "620640 frames: done 2199 games, mean reward 37.01,  233 frame/episode, eps 0.1, speed 67.14 f/s\n",
            "  --Try 0: t=339, reward=45.0 Best reward updated\n",
            "  --Try 1: t=298, reward=51.0 Best reward updated\n",
            "  --Try 2: t=335, reward=51.0\n",
            "  --Try 3: t=300, reward=51.0\n",
            "  --Try 4: t=387, reward=50.0\n",
            "  --Try 5: t=198, reward=25.0\n",
            "  --Try 6: t=312, reward=52.0 Best reward updated\n",
            "  --Try 7: t=344, reward=59.0 Best reward updated\n",
            "  --Try 8: t=272, reward=42.0\n",
            "  --Try 9: t=280, reward=35.0\n",
            "  --Generating animation..\n",
            " --Animationm from 345 frames with reward 59.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 35.4 -> 37.18, model saved\n",
            "621324 frames: done 2202 games, mean reward 37.14,  116 frame/episode, eps 0.1, speed 65.94 f/s\n",
            "622164 frames: done 2205 games, mean reward 36.34,  272 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "623069 frames: done 2208 games, mean reward 36.72,  353 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "623981 frames: done 2211 games, mean reward 36.3,  413 frame/episode, eps 0.1, speed 67.18 f/s\n",
            "624781 frames: done 2214 games, mean reward 36.0,  209 frame/episode, eps 0.1, speed 67.6 f/s\n",
            "625800 frames: done 2217 games, mean reward 36.15,  287 frame/episode, eps 0.1, speed 65.94 f/s\n",
            "626619 frames: done 2220 games, mean reward 35.63,  315 frame/episode, eps 0.1, speed 66.82 f/s\n",
            "627380 frames: done 2223 games, mean reward 35.8,  277 frame/episode, eps 0.1, speed 63.75 f/s\n",
            "628298 frames: done 2226 games, mean reward 36.26,  318 frame/episode, eps 0.1, speed 66.82 f/s\n",
            "629061 frames: done 2229 games, mean reward 35.64,  223 frame/episode, eps 0.1, speed 66.32 f/s\n",
            "629826 frames: done 2232 games, mean reward 35.58,  307 frame/episode, eps 0.1, speed 66.22 f/s\n",
            "630576 frames: done 2235 games, mean reward 35.76,  246 frame/episode, eps 0.1, speed 66.32 f/s\n",
            "631314 frames: done 2238 games, mean reward 35.98,  232 frame/episode, eps 0.1, speed 67.48 f/s\n",
            "632265 frames: done 2241 games, mean reward 35.91,  249 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "633057 frames: done 2244 games, mean reward 36.5,  238 frame/episode, eps 0.1, speed 67.35 f/s\n",
            "633831 frames: done 2247 games, mean reward 36.69,  271 frame/episode, eps 0.1, speed 67.34 f/s\n",
            "634635 frames: done 2250 games, mean reward 36.64,  265 frame/episode, eps 0.1, speed 67.26 f/s\n",
            "635626 frames: done 2253 games, mean reward 36.26,  390 frame/episode, eps 0.1, speed 67.6 f/s\n",
            "636417 frames: done 2256 games, mean reward 35.94,  294 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "637289 frames: done 2259 games, mean reward 35.97,  289 frame/episode, eps 0.1, speed 66.56 f/s\n",
            "638177 frames: done 2262 games, mean reward 35.83,  290 frame/episode, eps 0.1, speed 67.47 f/s\n",
            "639080 frames: done 2265 games, mean reward 35.82,  431 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "639958 frames: done 2268 games, mean reward 35.56,  275 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "640908 frames: done 2271 games, mean reward 35.35,  497 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "641705 frames: done 2274 games, mean reward 35.28,  227 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "642703 frames: done 2277 games, mean reward 36.13,  308 frame/episode, eps 0.1, speed 66.07 f/s\n",
            "643755 frames: done 2280 games, mean reward 36.12,  444 frame/episode, eps 0.1, speed 66.19 f/s\n",
            "644589 frames: done 2283 games, mean reward 36.17,  276 frame/episode, eps 0.1, speed 64.47 f/s\n",
            "645317 frames: done 2286 games, mean reward 35.81,  252 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "646143 frames: done 2289 games, mean reward 36.09,  313 frame/episode, eps 0.1, speed 64.63 f/s\n",
            "646949 frames: done 2292 games, mean reward 36.32,  288 frame/episode, eps 0.1, speed 65.78 f/s\n",
            "647647 frames: done 2295 games, mean reward 35.96,  223 frame/episode, eps 0.1, speed 66.38 f/s\n",
            "648466 frames: done 2298 games, mean reward 35.72,  282 frame/episode, eps 0.1, speed 65.78 f/s\n",
            "649225 frames: done 2301 games, mean reward 35.38,  302 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "650013 frames: done 2304 games, mean reward 35.91,  241 frame/episode, eps 0.1, speed 66.94 f/s\n",
            "650739 frames: done 2307 games, mean reward 35.71,  227 frame/episode, eps 0.1, speed 65.66 f/s\n",
            "651410 frames: done 2310 games, mean reward 35.5,  297 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "652230 frames: done 2313 games, mean reward 35.53,  341 frame/episode, eps 0.1, speed 64.72 f/s\n",
            "653073 frames: done 2316 games, mean reward 35.53,  252 frame/episode, eps 0.1, speed 66.44 f/s\n",
            "653916 frames: done 2319 games, mean reward 35.6,  326 frame/episode, eps 0.1, speed 67.08 f/s\n",
            "654862 frames: done 2322 games, mean reward 37.13,  394 frame/episode, eps 0.1, speed 66.07 f/s\n",
            "655578 frames: done 2325 games, mean reward 36.76,  284 frame/episode, eps 0.1, speed 67.57 f/s\n",
            "656318 frames: done 2328 games, mean reward 36.7,  219 frame/episode, eps 0.1, speed 67.12 f/s\n",
            "657157 frames: done 2331 games, mean reward 37.19,  271 frame/episode, eps 0.1, speed 66.23 f/s\n",
            "657905 frames: done 2334 games, mean reward 37.06,  281 frame/episode, eps 0.1, speed 67.16 f/s\n",
            "658748 frames: done 2337 games, mean reward 37.05,  281 frame/episode, eps 0.1, speed 66.15 f/s\n",
            "659567 frames: done 2340 games, mean reward 37.44,  257 frame/episode, eps 0.1, speed 67.88 f/s\n",
            "660502 frames: done 2343 games, mean reward 37.45,  276 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "661389 frames: done 2346 games, mean reward 37.77,  321 frame/episode, eps 0.1, speed 67.02 f/s\n",
            "662019 frames: done 2349 games, mean reward 37.33,  197 frame/episode, eps 0.1, speed 67.58 f/s\n",
            "662797 frames: done 2352 games, mean reward 37.1,  269 frame/episode, eps 0.1, speed 66.19 f/s\n",
            "663718 frames: done 2355 games, mean reward 37.48,  265 frame/episode, eps 0.1, speed 67.44 f/s\n",
            "664554 frames: done 2358 games, mean reward 37.54,  275 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "665406 frames: done 2361 games, mean reward 37.26,  357 frame/episode, eps 0.1, speed 66.9 f/s\n",
            "666210 frames: done 2364 games, mean reward 37.42,  244 frame/episode, eps 0.1, speed 67.0 f/s\n",
            "667188 frames: done 2367 games, mean reward 37.83,  342 frame/episode, eps 0.1, speed 66.97 f/s\n",
            "667832 frames: done 2370 games, mean reward 37.8,  233 frame/episode, eps 0.1, speed 66.93 f/s\n",
            "668895 frames: done 2373 games, mean reward 37.34,  410 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "669649 frames: done 2376 games, mean reward 36.52,  231 frame/episode, eps 0.1, speed 67.13 f/s\n",
            "670509 frames: done 2379 games, mean reward 36.59,  221 frame/episode, eps 0.1, speed 67.03 f/s\n",
            "671390 frames: done 2382 games, mean reward 36.73,  174 frame/episode, eps 0.1, speed 66.46 f/s\n",
            "672016 frames: done 2385 games, mean reward 36.31,  265 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "672837 frames: done 2388 games, mean reward 36.35,  324 frame/episode, eps 0.1, speed 66.51 f/s\n",
            "673693 frames: done 2391 games, mean reward 36.35,  270 frame/episode, eps 0.1, speed 65.44 f/s\n",
            "674427 frames: done 2394 games, mean reward 36.11,  206 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "675215 frames: done 2397 games, mean reward 36.55,  226 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "676080 frames: done 2400 games, mean reward 37.03,  311 frame/episode, eps 0.1, speed 65.66 f/s\n",
            "  --Try 0: t=368, reward=95.0 Best reward updated\n",
            "  --Try 1: t=341, reward=68.0\n",
            "  --Try 2: t=263, reward=41.0\n",
            "  --Try 3: t=213, reward=20.0\n",
            "  --Try 4: t=215, reward=16.0\n",
            "  --Try 5: t=331, reward=53.0\n",
            "  --Try 6: t=370, reward=101.0 Best reward updated\n",
            "  --Try 7: t=176, reward=13.0\n",
            "  --Try 8: t=348, reward=48.0\n",
            "  --Try 9: t=322, reward=51.0\n",
            "  --Generating animation..\n",
            " --Animationm from 371 frames with reward 101.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 37.18 -> 37.03, model saved\n",
            "676933 frames: done 2403 games, mean reward 36.89,  287 frame/episode, eps 0.1, speed 66.33 f/s\n",
            "677739 frames: done 2406 games, mean reward 37.32,  267 frame/episode, eps 0.1, speed 66.52 f/s\n",
            "678724 frames: done 2409 games, mean reward 37.97,  310 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "679556 frames: done 2412 games, mean reward 38.42,  277 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "680386 frames: done 2415 games, mean reward 38.28,  257 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "681161 frames: done 2418 games, mean reward 38.09,  303 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "681964 frames: done 2421 games, mean reward 37.89,  301 frame/episode, eps 0.1, speed 66.67 f/s\n",
            "682691 frames: done 2424 games, mean reward 36.23,  210 frame/episode, eps 0.1, speed 66.91 f/s\n",
            "683611 frames: done 2427 games, mean reward 36.33,  279 frame/episode, eps 0.1, speed 66.49 f/s\n",
            "684341 frames: done 2430 games, mean reward 36.28,  182 frame/episode, eps 0.1, speed 66.99 f/s\n",
            "685144 frames: done 2433 games, mean reward 36.24,  371 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "685729 frames: done 2436 games, mean reward 35.49,  221 frame/episode, eps 0.1, speed 65.88 f/s\n",
            "686396 frames: done 2439 games, mean reward 35.0,  191 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "687294 frames: done 2442 games, mean reward 35.28,  264 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "688227 frames: done 2445 games, mean reward 35.31,  399 frame/episode, eps 0.1, speed 66.42 f/s\n",
            "689045 frames: done 2448 games, mean reward 35.08,  433 frame/episode, eps 0.1, speed 66.05 f/s\n",
            "689805 frames: done 2451 games, mean reward 35.01,  216 frame/episode, eps 0.1, speed 65.95 f/s\n",
            "690575 frames: done 2454 games, mean reward 34.6,  309 frame/episode, eps 0.1, speed 67.15 f/s\n",
            "691240 frames: done 2457 games, mean reward 34.13,  191 frame/episode, eps 0.1, speed 67.41 f/s\n",
            "692191 frames: done 2460 games, mean reward 34.35,  323 frame/episode, eps 0.1, speed 66.85 f/s\n",
            "692963 frames: done 2463 games, mean reward 34.33,  293 frame/episode, eps 0.1, speed 66.97 f/s\n",
            "693714 frames: done 2466 games, mean reward 33.79,  282 frame/episode, eps 0.1, speed 67.08 f/s\n",
            "694375 frames: done 2469 games, mean reward 33.49,  198 frame/episode, eps 0.1, speed 66.07 f/s\n",
            "695265 frames: done 2472 games, mean reward 34.02,  270 frame/episode, eps 0.1, speed 66.43 f/s\n",
            "696228 frames: done 2475 games, mean reward 33.81,  208 frame/episode, eps 0.1, speed 66.56 f/s\n",
            "697029 frames: done 2478 games, mean reward 33.24,  209 frame/episode, eps 0.1, speed 64.1 f/s\n",
            "697780 frames: done 2481 games, mean reward 32.66,  197 frame/episode, eps 0.1, speed 65.71 f/s\n",
            "698698 frames: done 2484 games, mean reward 33.35,  310 frame/episode, eps 0.1, speed 66.82 f/s\n",
            "699716 frames: done 2487 games, mean reward 33.1,  328 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "700676 frames: done 2490 games, mean reward 33.27,  411 frame/episode, eps 0.1, speed 67.69 f/s\n",
            "701847 frames: done 2493 games, mean reward 33.25,  456 frame/episode, eps 0.1, speed 67.19 f/s\n",
            "702650 frames: done 2496 games, mean reward 33.27,  239 frame/episode, eps 0.1, speed 65.68 f/s\n",
            "703265 frames: done 2499 games, mean reward 32.78,  265 frame/episode, eps 0.1, speed 67.29 f/s\n",
            "704163 frames: done 2502 games, mean reward 33.06,  307 frame/episode, eps 0.1, speed 67.03 f/s\n",
            "705113 frames: done 2505 games, mean reward 33.15,  263 frame/episode, eps 0.1, speed 67.03 f/s\n",
            "705848 frames: done 2508 games, mean reward 32.95,  238 frame/episode, eps 0.1, speed 66.77 f/s\n",
            "706772 frames: done 2511 games, mean reward 32.15,  412 frame/episode, eps 0.1, speed 66.65 f/s\n",
            "707969 frames: done 2514 games, mean reward 32.06,  342 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "708887 frames: done 2517 games, mean reward 32.68,  313 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "709725 frames: done 2520 games, mean reward 32.7,  283 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "710504 frames: done 2523 games, mean reward 32.63,  284 frame/episode, eps 0.1, speed 65.31 f/s\n",
            "711374 frames: done 2526 games, mean reward 32.71,  308 frame/episode, eps 0.1, speed 65.58 f/s\n",
            "712365 frames: done 2529 games, mean reward 32.84,  300 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "713282 frames: done 2532 games, mean reward 32.98,  260 frame/episode, eps 0.1, speed 66.16 f/s\n",
            "714226 frames: done 2535 games, mean reward 33.51,  398 frame/episode, eps 0.1, speed 66.75 f/s\n",
            "715255 frames: done 2538 games, mean reward 33.65,  281 frame/episode, eps 0.1, speed 67.62 f/s\n",
            "716034 frames: done 2541 games, mean reward 32.81,  288 frame/episode, eps 0.1, speed 67.04 f/s\n",
            "716839 frames: done 2544 games, mean reward 32.86,  236 frame/episode, eps 0.1, speed 67.08 f/s\n",
            "717625 frames: done 2547 games, mean reward 32.23,  296 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "718426 frames: done 2550 games, mean reward 32.18,  266 frame/episode, eps 0.1, speed 66.24 f/s\n",
            "719377 frames: done 2553 games, mean reward 32.94,  367 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "720277 frames: done 2556 games, mean reward 33.07,  314 frame/episode, eps 0.1, speed 67.44 f/s\n",
            "721256 frames: done 2559 games, mean reward 34.03,  307 frame/episode, eps 0.1, speed 67.3 f/s\n",
            "722082 frames: done 2562 games, mean reward 33.6,  233 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "722942 frames: done 2565 games, mean reward 34.05,  373 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "723843 frames: done 2568 games, mean reward 33.9,  260 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "724777 frames: done 2571 games, mean reward 34.7,  333 frame/episode, eps 0.1, speed 67.11 f/s\n",
            "725477 frames: done 2574 games, mean reward 34.14,  262 frame/episode, eps 0.1, speed 66.53 f/s\n",
            "726458 frames: done 2577 games, mean reward 34.9,  352 frame/episode, eps 0.1, speed 66.87 f/s\n",
            "727278 frames: done 2580 games, mean reward 34.53,  252 frame/episode, eps 0.1, speed 65.64 f/s\n",
            "728011 frames: done 2583 games, mean reward 34.11,  341 frame/episode, eps 0.1, speed 65.2 f/s\n",
            "728934 frames: done 2586 games, mean reward 34.43,  263 frame/episode, eps 0.1, speed 66.37 f/s\n",
            "729827 frames: done 2589 games, mean reward 34.76,  297 frame/episode, eps 0.1, speed 66.84 f/s\n",
            "730746 frames: done 2592 games, mean reward 35.97,  224 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "731384 frames: done 2595 games, mean reward 35.51,  167 frame/episode, eps 0.1, speed 66.49 f/s\n",
            "732284 frames: done 2598 games, mean reward 36.23,  323 frame/episode, eps 0.1, speed 67.69 f/s\n",
            "  --Try 0: t=295, reward=35.0 Best reward updated\n",
            "  --Try 1: t=296, reward=39.0 Best reward updated\n",
            "  --Try 2: t=493, reward=238.0 Best reward updated\n",
            "  --Try 3: t=300, reward=54.0\n",
            "  --Try 4: t=278, reward=31.0\n",
            "  --Try 5: t=321, reward=56.0\n",
            "  --Try 6: t=368, reward=54.0\n",
            "  --Try 7: t=264, reward=35.0\n",
            "  --Try 8: t=257, reward=33.0\n",
            "  --Try 9: t=462, reward=67.0\n",
            "  --Generating animation..\n",
            " --Animationm from 494 frames with reward 238.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 37.03 -> 35.71, model saved\n",
            "733084 frames: done 2601 games, mean reward 35.64,  398 frame/episode, eps 0.1, speed 5.94 f/s\n",
            "733859 frames: done 2604 games, mean reward 34.9,  271 frame/episode, eps 0.1, speed 66.62 f/s\n",
            "734666 frames: done 2607 games, mean reward 35.09,  229 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "735445 frames: done 2610 games, mean reward 35.39,  255 frame/episode, eps 0.1, speed 65.86 f/s\n",
            "736310 frames: done 2613 games, mean reward 35.39,  207 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "737053 frames: done 2616 games, mean reward 35.09,  347 frame/episode, eps 0.1, speed 66.75 f/s\n",
            "737895 frames: done 2619 games, mean reward 35.31,  287 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "738634 frames: done 2622 games, mean reward 35.27,  256 frame/episode, eps 0.1, speed 67.6 f/s\n",
            "739565 frames: done 2625 games, mean reward 35.62,  296 frame/episode, eps 0.1, speed 67.22 f/s\n",
            "740394 frames: done 2628 games, mean reward 34.98,  244 frame/episode, eps 0.1, speed 66.9 f/s\n",
            "741139 frames: done 2631 games, mean reward 34.67,  233 frame/episode, eps 0.1, speed 66.77 f/s\n",
            "741792 frames: done 2634 games, mean reward 34.35,  196 frame/episode, eps 0.1, speed 67.53 f/s\n",
            "742573 frames: done 2637 games, mean reward 34.46,  228 frame/episode, eps 0.1, speed 66.89 f/s\n",
            "743514 frames: done 2640 games, mean reward 35.35,  299 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "744483 frames: done 2643 games, mean reward 35.43,  278 frame/episode, eps 0.1, speed 65.59 f/s\n",
            "745320 frames: done 2646 games, mean reward 35.94,  334 frame/episode, eps 0.1, speed 67.26 f/s\n",
            "746186 frames: done 2649 games, mean reward 36.61,  321 frame/episode, eps 0.1, speed 67.47 f/s\n",
            "747058 frames: done 2652 games, mean reward 36.88,  311 frame/episode, eps 0.1, speed 66.63 f/s\n",
            "748164 frames: done 2655 games, mean reward 36.78,  352 frame/episode, eps 0.1, speed 67.15 f/s\n",
            "749204 frames: done 2658 games, mean reward 37.86,  370 frame/episode, eps 0.1, speed 67.28 f/s\n",
            "750056 frames: done 2661 games, mean reward 38.19,  281 frame/episode, eps 0.1, speed 67.63 f/s\n",
            "750766 frames: done 2664 games, mean reward 37.62,  197 frame/episode, eps 0.1, speed 67.52 f/s\n",
            "751728 frames: done 2667 games, mean reward 38.44,  369 frame/episode, eps 0.1, speed 67.32 f/s\n",
            "752537 frames: done 2670 games, mean reward 38.58,  250 frame/episode, eps 0.1, speed 67.65 f/s\n",
            "753279 frames: done 2673 games, mean reward 38.3,  228 frame/episode, eps 0.1, speed 67.32 f/s\n",
            "754054 frames: done 2676 games, mean reward 37.95,  288 frame/episode, eps 0.1, speed 67.29 f/s\n",
            "754894 frames: done 2679 games, mean reward 38.33,  324 frame/episode, eps 0.1, speed 67.16 f/s\n",
            "755710 frames: done 2682 games, mean reward 38.5,  261 frame/episode, eps 0.1, speed 66.91 f/s\n",
            "756517 frames: done 2685 games, mean reward 38.15,  327 frame/episode, eps 0.1, speed 66.96 f/s\n",
            "757482 frames: done 2688 games, mean reward 38.07,  208 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "758351 frames: done 2691 games, mean reward 36.55,  334 frame/episode, eps 0.1, speed 67.42 f/s\n",
            "759080 frames: done 2694 games, mean reward 36.23,  261 frame/episode, eps 0.1, speed 66.4 f/s\n",
            "759736 frames: done 2697 games, mean reward 36.31,  133 frame/episode, eps 0.1, speed 67.14 f/s\n",
            "760608 frames: done 2700 games, mean reward 36.79,  283 frame/episode, eps 0.1, speed 67.4 f/s\n",
            "761355 frames: done 2703 games, mean reward 36.9,  293 frame/episode, eps 0.1, speed 64.89 f/s\n",
            "762170 frames: done 2706 games, mean reward 36.98,  274 frame/episode, eps 0.1, speed 67.22 f/s\n",
            "762959 frames: done 2709 games, mean reward 36.58,  217 frame/episode, eps 0.1, speed 62.86 f/s\n",
            "763827 frames: done 2712 games, mean reward 36.23,  221 frame/episode, eps 0.1, speed 62.96 f/s\n",
            "764777 frames: done 2715 games, mean reward 36.63,  341 frame/episode, eps 0.1, speed 62.53 f/s\n",
            "765662 frames: done 2718 games, mean reward 36.15,  231 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "766447 frames: done 2721 games, mean reward 36.42,  208 frame/episode, eps 0.1, speed 65.0 f/s\n",
            "767328 frames: done 2724 games, mean reward 36.0,  281 frame/episode, eps 0.1, speed 65.66 f/s\n",
            "768200 frames: done 2727 games, mean reward 35.77,  304 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "769033 frames: done 2730 games, mean reward 36.28,  267 frame/episode, eps 0.1, speed 66.75 f/s\n",
            "769665 frames: done 2733 games, mean reward 35.93,  188 frame/episode, eps 0.1, speed 67.09 f/s\n",
            "770430 frames: done 2736 games, mean reward 35.72,  201 frame/episode, eps 0.1, speed 66.58 f/s\n",
            "771241 frames: done 2739 games, mean reward 35.26,  272 frame/episode, eps 0.1, speed 66.43 f/s\n",
            "772025 frames: done 2742 games, mean reward 34.99,  337 frame/episode, eps 0.1, speed 66.71 f/s\n",
            "773012 frames: done 2745 games, mean reward 37.67,  307 frame/episode, eps 0.1, speed 66.13 f/s\n",
            "773881 frames: done 2748 games, mean reward 37.82,  330 frame/episode, eps 0.1, speed 62.84 f/s\n",
            "774554 frames: done 2751 games, mean reward 37.19,  207 frame/episode, eps 0.1, speed 66.46 f/s\n",
            "775418 frames: done 2754 games, mean reward 37.71,  288 frame/episode, eps 0.1, speed 61.9 f/s\n",
            "776194 frames: done 2757 games, mean reward 35.69,  282 frame/episode, eps 0.1, speed 64.64 f/s\n",
            "777112 frames: done 2760 games, mean reward 35.3,  268 frame/episode, eps 0.1, speed 61.69 f/s\n",
            "777868 frames: done 2763 games, mean reward 35.03,  234 frame/episode, eps 0.1, speed 61.04 f/s\n",
            "778813 frames: done 2766 games, mean reward 35.65,  331 frame/episode, eps 0.1, speed 64.29 f/s\n",
            "779648 frames: done 2769 games, mean reward 34.96,  365 frame/episode, eps 0.1, speed 64.6 f/s\n",
            "780584 frames: done 2772 games, mean reward 35.35,  289 frame/episode, eps 0.1, speed 65.51 f/s\n",
            "781389 frames: done 2775 games, mean reward 35.21,  262 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "782243 frames: done 2778 games, mean reward 34.99,  270 frame/episode, eps 0.1, speed 63.16 f/s\n",
            "783116 frames: done 2781 games, mean reward 35.2,  320 frame/episode, eps 0.1, speed 65.02 f/s\n",
            "783925 frames: done 2784 games, mean reward 35.73,  296 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "784695 frames: done 2787 games, mean reward 35.18,  239 frame/episode, eps 0.1, speed 64.0 f/s\n",
            "785598 frames: done 2790 games, mean reward 35.2,  397 frame/episode, eps 0.1, speed 65.0 f/s\n",
            "786422 frames: done 2793 games, mean reward 35.79,  239 frame/episode, eps 0.1, speed 65.48 f/s\n",
            "787249 frames: done 2796 games, mean reward 35.14,  274 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "787969 frames: done 2799 games, mean reward 34.68,  227 frame/episode, eps 0.1, speed 65.22 f/s\n",
            "  --Try 0: t=252, reward=14.0 Best reward updated\n",
            "  --Try 1: t=420, reward=190.0 Best reward updated\n",
            "  --Try 2: t=286, reward=47.0\n",
            "  --Try 3: t=385, reward=67.0\n",
            "  --Try 4: t=179, reward=10.0\n",
            "  --Try 5: t=280, reward=34.0\n",
            "  --Try 6: t=262, reward=18.0\n",
            "  --Try 7: t=261, reward=34.0\n",
            "  --Try 8: t=558, reward=330.0 Best reward updated\n",
            "  --Try 9: t=326, reward=75.0\n",
            "  --Generating animation..\n",
            " --Animationm from 559 frames with reward 330.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 35.71 -> 34.93, model saved\n",
            "788957 frames: done 2802 games, mean reward 35.37,  314 frame/episode, eps 0.1, speed 62.33 f/s\n",
            "789681 frames: done 2805 games, mean reward 35.03,  257 frame/episode, eps 0.1, speed 63.54 f/s\n",
            "790412 frames: done 2808 games, mean reward 34.74,  155 frame/episode, eps 0.1, speed 63.41 f/s\n",
            "791221 frames: done 2811 games, mean reward 35.35,  298 frame/episode, eps 0.1, speed 63.64 f/s\n",
            "792171 frames: done 2814 games, mean reward 35.93,  320 frame/episode, eps 0.1, speed 62.3 f/s\n",
            "793033 frames: done 2817 games, mean reward 36.22,  226 frame/episode, eps 0.1, speed 61.27 f/s\n",
            "793712 frames: done 2820 games, mean reward 35.74,  255 frame/episode, eps 0.1, speed 59.84 f/s\n",
            "794845 frames: done 2823 games, mean reward 37.69,  386 frame/episode, eps 0.1, speed 63.82 f/s\n",
            "795832 frames: done 2826 games, mean reward 39.63,  374 frame/episode, eps 0.1, speed 62.9 f/s\n",
            "796558 frames: done 2829 games, mean reward 39.71,  254 frame/episode, eps 0.1, speed 62.66 f/s\n",
            "797550 frames: done 2832 games, mean reward 40.0,  381 frame/episode, eps 0.1, speed 60.8 f/s\n",
            "798297 frames: done 2835 games, mean reward 39.96,  296 frame/episode, eps 0.1, speed 60.65 f/s\n",
            "799156 frames: done 2838 games, mean reward 40.11,  187 frame/episode, eps 0.1, speed 61.0 f/s\n",
            "800084 frames: done 2841 games, mean reward 40.73,  284 frame/episode, eps 0.1, speed 59.6 f/s\n",
            "800828 frames: done 2844 games, mean reward 38.49,  292 frame/episode, eps 0.1, speed 59.94 f/s\n",
            "801584 frames: done 2847 games, mean reward 38.22,  211 frame/episode, eps 0.1, speed 59.44 f/s\n",
            "802405 frames: done 2850 games, mean reward 38.34,  298 frame/episode, eps 0.1, speed 59.91 f/s\n",
            "803265 frames: done 2853 games, mean reward 37.85,  202 frame/episode, eps 0.1, speed 60.68 f/s\n",
            "804070 frames: done 2856 games, mean reward 38.09,  148 frame/episode, eps 0.1, speed 58.11 f/s\n",
            "804920 frames: done 2859 games, mean reward 38.15,  312 frame/episode, eps 0.1, speed 60.84 f/s\n",
            "805748 frames: done 2862 games, mean reward 38.55,  279 frame/episode, eps 0.1, speed 63.22 f/s\n",
            "806596 frames: done 2865 games, mean reward 38.76,  334 frame/episode, eps 0.1, speed 64.84 f/s\n",
            "807423 frames: done 2868 games, mean reward 38.26,  284 frame/episode, eps 0.1, speed 65.05 f/s\n",
            "808173 frames: done 2871 games, mean reward 37.69,  275 frame/episode, eps 0.1, speed 63.01 f/s\n",
            "809093 frames: done 2874 games, mean reward 37.75,  207 frame/episode, eps 0.1, speed 63.76 f/s\n",
            "809884 frames: done 2877 games, mean reward 37.91,  274 frame/episode, eps 0.1, speed 64.67 f/s\n",
            "810738 frames: done 2880 games, mean reward 37.52,  400 frame/episode, eps 0.1, speed 64.15 f/s\n",
            "811658 frames: done 2883 games, mean reward 37.67,  393 frame/episode, eps 0.1, speed 64.26 f/s\n",
            "812560 frames: done 2886 games, mean reward 37.9,  354 frame/episode, eps 0.1, speed 64.47 f/s\n",
            "813345 frames: done 2889 games, mean reward 37.9,  247 frame/episode, eps 0.1, speed 64.6 f/s\n",
            "814140 frames: done 2892 games, mean reward 37.49,  271 frame/episode, eps 0.1, speed 63.25 f/s\n",
            "815001 frames: done 2895 games, mean reward 37.78,  323 frame/episode, eps 0.1, speed 64.11 f/s\n",
            "815772 frames: done 2898 games, mean reward 38.1,  348 frame/episode, eps 0.1, speed 64.13 f/s\n",
            "816551 frames: done 2901 games, mean reward 37.15,  229 frame/episode, eps 0.1, speed 64.65 f/s\n",
            "817384 frames: done 2904 games, mean reward 37.43,  362 frame/episode, eps 0.1, speed 63.73 f/s\n",
            "818184 frames: done 2907 games, mean reward 37.49,  241 frame/episode, eps 0.1, speed 64.21 f/s\n",
            "819064 frames: done 2910 games, mean reward 37.35,  195 frame/episode, eps 0.1, speed 61.59 f/s\n",
            "819932 frames: done 2913 games, mean reward 37.08,  227 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "820829 frames: done 2916 games, mean reward 37.01,  235 frame/episode, eps 0.1, speed 64.14 f/s\n",
            "821811 frames: done 2919 games, mean reward 39.79,  297 frame/episode, eps 0.1, speed 65.11 f/s\n",
            "822632 frames: done 2922 games, mean reward 38.08,  263 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "823391 frames: done 2925 games, mean reward 37.49,  272 frame/episode, eps 0.1, speed 64.25 f/s\n",
            "824054 frames: done 2928 games, mean reward 35.36,  159 frame/episode, eps 0.1, speed 63.74 f/s\n",
            "824840 frames: done 2931 games, mean reward 34.72,  240 frame/episode, eps 0.1, speed 63.28 f/s\n",
            "825821 frames: done 2934 games, mean reward 34.85,  449 frame/episode, eps 0.1, speed 64.27 f/s\n",
            "826832 frames: done 2937 games, mean reward 36.19,  402 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "827647 frames: done 2940 games, mean reward 36.47,  357 frame/episode, eps 0.1, speed 62.83 f/s\n",
            "828447 frames: done 2943 games, mean reward 35.88,  436 frame/episode, eps 0.1, speed 65.34 f/s\n",
            "829434 frames: done 2946 games, mean reward 35.68,  410 frame/episode, eps 0.1, speed 64.43 f/s\n",
            "830203 frames: done 2949 games, mean reward 35.22,  227 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "831052 frames: done 2952 games, mean reward 35.71,  291 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "831818 frames: done 2955 games, mean reward 35.15,  181 frame/episode, eps 0.1, speed 63.93 f/s\n",
            "832576 frames: done 2958 games, mean reward 35.48,  277 frame/episode, eps 0.1, speed 63.56 f/s\n",
            "833317 frames: done 2961 games, mean reward 34.88,  199 frame/episode, eps 0.1, speed 64.12 f/s\n",
            "833974 frames: done 2964 games, mean reward 34.53,  330 frame/episode, eps 0.1, speed 64.33 f/s\n",
            "834672 frames: done 2967 games, mean reward 34.24,  142 frame/episode, eps 0.1, speed 63.81 f/s\n",
            "835386 frames: done 2970 games, mean reward 34.42,  252 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "836365 frames: done 2973 games, mean reward 34.75,  329 frame/episode, eps 0.1, speed 64.77 f/s\n",
            "837376 frames: done 2976 games, mean reward 35.7,  337 frame/episode, eps 0.1, speed 64.56 f/s\n",
            "838072 frames: done 2979 games, mean reward 35.6,  278 frame/episode, eps 0.1, speed 64.86 f/s\n",
            "838949 frames: done 2982 games, mean reward 35.98,  212 frame/episode, eps 0.1, speed 63.52 f/s\n",
            "839899 frames: done 2985 games, mean reward 35.92,  315 frame/episode, eps 0.1, speed 64.16 f/s\n",
            "840590 frames: done 2988 games, mean reward 35.74,  220 frame/episode, eps 0.1, speed 64.27 f/s\n",
            "841328 frames: done 2991 games, mean reward 36.05,  210 frame/episode, eps 0.1, speed 64.67 f/s\n",
            "842188 frames: done 2994 games, mean reward 36.41,  320 frame/episode, eps 0.1, speed 64.67 f/s\n",
            "843037 frames: done 2997 games, mean reward 36.41,  315 frame/episode, eps 0.1, speed 65.03 f/s\n",
            "843930 frames: done 3000 games, mean reward 36.84,  284 frame/episode, eps 0.1, speed 65.08 f/s\n",
            "  --Try 0: t=408, reward=31.0 Best reward updated\n",
            "  --Try 1: t=272, reward=40.0 Best reward updated\n",
            "  --Try 2: t=408, reward=41.0 Best reward updated\n",
            "  --Try 3: t=336, reward=42.0 Best reward updated\n",
            "  --Try 4: t=288, reward=14.0\n",
            "  --Try 5: t=262, reward=38.0\n",
            "  --Try 6: t=311, reward=56.0 Best reward updated\n",
            "  --Try 7: t=401, reward=195.0 Best reward updated\n",
            "  --Try 8: t=276, reward=46.0\n",
            "  --Try 9: t=415, reward=237.0 Best reward updated\n",
            "  --Generating animation..\n",
            " --Animationm from 416 frames with reward 237.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 34.93 -> 36.84, model saved\n",
            "844707 frames: done 3003 games, mean reward 37.01,  300 frame/episode, eps 0.1, speed 66.08 f/s\n",
            "845520 frames: done 3006 games, mean reward 36.59,  291 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "846376 frames: done 3009 games, mean reward 37.77,  372 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "847191 frames: done 3012 games, mean reward 37.49,  198 frame/episode, eps 0.1, speed 64.54 f/s\n",
            "847950 frames: done 3015 games, mean reward 36.94,  281 frame/episode, eps 0.1, speed 65.48 f/s\n",
            "848591 frames: done 3018 games, mean reward 34.4,  230 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "849381 frames: done 3021 games, mean reward 33.93,  222 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "850181 frames: done 3024 games, mean reward 34.32,  261 frame/episode, eps 0.1, speed 64.79 f/s\n",
            "851153 frames: done 3027 games, mean reward 34.49,  457 frame/episode, eps 0.1, speed 64.96 f/s\n",
            "851977 frames: done 3030 games, mean reward 34.53,  272 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "852849 frames: done 3033 games, mean reward 34.07,  301 frame/episode, eps 0.1, speed 64.92 f/s\n",
            "853671 frames: done 3036 games, mean reward 33.57,  214 frame/episode, eps 0.1, speed 65.61 f/s\n",
            "854596 frames: done 3039 games, mean reward 32.12,  354 frame/episode, eps 0.1, speed 65.76 f/s\n",
            "855425 frames: done 3042 games, mean reward 32.57,  323 frame/episode, eps 0.1, speed 64.27 f/s\n",
            "856167 frames: done 3045 games, mean reward 32.76,  277 frame/episode, eps 0.1, speed 67.21 f/s\n",
            "857086 frames: done 3048 games, mean reward 32.69,  184 frame/episode, eps 0.1, speed 66.2 f/s\n",
            "857903 frames: done 3051 games, mean reward 32.33,  307 frame/episode, eps 0.1, speed 63.79 f/s\n",
            "858602 frames: done 3054 games, mean reward 31.74,  235 frame/episode, eps 0.1, speed 66.8 f/s\n",
            "859437 frames: done 3057 games, mean reward 32.03,  235 frame/episode, eps 0.1, speed 65.06 f/s\n",
            "860077 frames: done 3060 games, mean reward 31.88,  200 frame/episode, eps 0.1, speed 67.38 f/s\n",
            "860835 frames: done 3063 games, mean reward 32.52,  217 frame/episode, eps 0.1, speed 65.78 f/s\n",
            "861684 frames: done 3066 games, mean reward 32.43,  320 frame/episode, eps 0.1, speed 65.71 f/s\n",
            "862514 frames: done 3069 games, mean reward 32.87,  265 frame/episode, eps 0.1, speed 65.72 f/s\n",
            "863495 frames: done 3072 games, mean reward 33.0,  295 frame/episode, eps 0.1, speed 67.84 f/s\n",
            "864319 frames: done 3075 games, mean reward 32.57,  304 frame/episode, eps 0.1, speed 67.5 f/s\n",
            "865191 frames: done 3078 games, mean reward 32.57,  257 frame/episode, eps 0.1, speed 68.21 f/s\n",
            "866070 frames: done 3081 games, mean reward 32.19,  376 frame/episode, eps 0.1, speed 67.45 f/s\n",
            "866883 frames: done 3084 games, mean reward 32.27,  244 frame/episode, eps 0.1, speed 67.64 f/s\n",
            "868202 frames: done 3087 games, mean reward 34.47,  552 frame/episode, eps 0.1, speed 67.94 f/s\n",
            "868944 frames: done 3090 games, mean reward 34.54,  225 frame/episode, eps 0.1, speed 67.88 f/s\n",
            "869930 frames: done 3093 games, mean reward 35.0,  336 frame/episode, eps 0.1, speed 67.05 f/s\n",
            "870799 frames: done 3096 games, mean reward 35.0,  268 frame/episode, eps 0.1, speed 67.68 f/s\n",
            "871460 frames: done 3099 games, mean reward 34.75,  261 frame/episode, eps 0.1, speed 66.78 f/s\n",
            "872299 frames: done 3102 games, mean reward 34.65,  247 frame/episode, eps 0.1, speed 67.9 f/s\n",
            "873282 frames: done 3105 games, mean reward 35.44,  318 frame/episode, eps 0.1, speed 68.33 f/s\n",
            "874143 frames: done 3108 games, mean reward 35.4,  210 frame/episode, eps 0.1, speed 67.98 f/s\n",
            "874915 frames: done 3111 games, mean reward 34.51,  165 frame/episode, eps 0.1, speed 65.98 f/s\n",
            "876001 frames: done 3114 games, mean reward 34.97,  362 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "876846 frames: done 3117 games, mean reward 35.12,  387 frame/episode, eps 0.1, speed 68.15 f/s\n",
            "877602 frames: done 3120 games, mean reward 35.17,  304 frame/episode, eps 0.1, speed 68.0 f/s\n",
            "878407 frames: done 3123 games, mean reward 35.19,  270 frame/episode, eps 0.1, speed 66.12 f/s\n",
            "879324 frames: done 3126 games, mean reward 35.63,  386 frame/episode, eps 0.1, speed 68.47 f/s\n",
            "879971 frames: done 3129 games, mean reward 35.57,  210 frame/episode, eps 0.1, speed 67.59 f/s\n",
            "880898 frames: done 3132 games, mean reward 36.25,  432 frame/episode, eps 0.1, speed 67.43 f/s\n",
            "881587 frames: done 3135 games, mean reward 36.49,  306 frame/episode, eps 0.1, speed 67.9 f/s\n",
            "882569 frames: done 3138 games, mean reward 38.25,  452 frame/episode, eps 0.1, speed 67.52 f/s\n",
            "883340 frames: done 3141 games, mean reward 38.13,  313 frame/episode, eps 0.1, speed 67.7 f/s\n",
            "884078 frames: done 3144 games, mean reward 37.82,  227 frame/episode, eps 0.1, speed 67.09 f/s\n",
            "884895 frames: done 3147 games, mean reward 37.79,  346 frame/episode, eps 0.1, speed 67.62 f/s\n",
            "885727 frames: done 3150 games, mean reward 38.6,  217 frame/episode, eps 0.1, speed 68.27 f/s\n",
            "886513 frames: done 3153 games, mean reward 38.9,  261 frame/episode, eps 0.1, speed 67.18 f/s\n",
            "887428 frames: done 3156 games, mean reward 38.75,  350 frame/episode, eps 0.1, speed 67.29 f/s\n",
            "888208 frames: done 3159 games, mean reward 39.0,  298 frame/episode, eps 0.1, speed 67.54 f/s\n",
            "889211 frames: done 3162 games, mean reward 39.83,  316 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "890415 frames: done 3165 games, mean reward 40.01,  514 frame/episode, eps 0.1, speed 67.83 f/s\n",
            "891328 frames: done 3168 games, mean reward 39.69,  290 frame/episode, eps 0.1, speed 66.95 f/s\n",
            "892117 frames: done 3171 games, mean reward 39.16,  256 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "892868 frames: done 3174 games, mean reward 38.46,  221 frame/episode, eps 0.1, speed 67.84 f/s\n",
            "893682 frames: done 3177 games, mean reward 38.49,  263 frame/episode, eps 0.1, speed 67.31 f/s\n",
            "894532 frames: done 3180 games, mean reward 38.66,  268 frame/episode, eps 0.1, speed 66.59 f/s\n",
            "895334 frames: done 3183 games, mean reward 38.57,  273 frame/episode, eps 0.1, speed 67.21 f/s\n",
            "896199 frames: done 3186 games, mean reward 36.16,  277 frame/episode, eps 0.1, speed 67.37 f/s\n",
            "897053 frames: done 3189 games, mean reward 36.31,  366 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "897791 frames: done 3192 games, mean reward 36.11,  239 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "898510 frames: done 3195 games, mean reward 35.49,  224 frame/episode, eps 0.1, speed 67.43 f/s\n",
            "899195 frames: done 3198 games, mean reward 35.23,  186 frame/episode, eps 0.1, speed 67.26 f/s\n",
            "  --Try 0: t=284, reward=30.0 Best reward updated\n",
            "  --Try 1: t=240, reward=21.0\n",
            "  --Try 2: t=300, reward=55.0 Best reward updated\n",
            "  --Try 3: t=366, reward=89.0 Best reward updated\n",
            "  --Try 4: t=278, reward=46.0\n",
            "  --Try 5: t=319, reward=62.0\n",
            "  --Try 6: t=304, reward=55.0\n",
            "  --Try 7: t=352, reward=87.0\n",
            "  --Try 8: t=318, reward=26.0\n",
            "  --Try 9: t=206, reward=26.0\n",
            "  --Generating animation..\n",
            " --Animationm from 367 frames with reward 89.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 36.84 -> 34.7, model saved\n",
            "899959 frames: done 3201 games, mean reward 34.88,  227 frame/episode, eps 0.1, speed 3.81 f/s\n",
            "900776 frames: done 3204 games, mean reward 34.33,  284 frame/episode, eps 0.1, speed 67.25 f/s\n",
            "901653 frames: done 3207 games, mean reward 34.42,  248 frame/episode, eps 0.1, speed 65.92 f/s\n",
            "902492 frames: done 3210 games, mean reward 34.0,  304 frame/episode, eps 0.1, speed 65.59 f/s\n",
            "903423 frames: done 3213 games, mean reward 34.34,  278 frame/episode, eps 0.1, speed 66.2 f/s\n",
            "904240 frames: done 3216 games, mean reward 33.79,  179 frame/episode, eps 0.1, speed 65.83 f/s\n",
            "905041 frames: done 3219 games, mean reward 35.77,  134 frame/episode, eps 0.1, speed 63.61 f/s\n",
            "905925 frames: done 3222 games, mean reward 35.47,  304 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "906738 frames: done 3225 games, mean reward 35.79,  236 frame/episode, eps 0.1, speed 63.61 f/s\n",
            "907562 frames: done 3228 games, mean reward 35.59,  291 frame/episode, eps 0.1, speed 63.87 f/s\n",
            "908626 frames: done 3231 games, mean reward 35.72,  342 frame/episode, eps 0.1, speed 59.54 f/s\n",
            "909437 frames: done 3234 games, mean reward 35.58,  343 frame/episode, eps 0.1, speed 63.58 f/s\n",
            "910257 frames: done 3237 games, mean reward 35.87,  257 frame/episode, eps 0.1, speed 60.33 f/s\n",
            "911229 frames: done 3240 games, mean reward 33.67,  272 frame/episode, eps 0.1, speed 59.5 f/s\n",
            "912103 frames: done 3243 games, mean reward 33.83,  327 frame/episode, eps 0.1, speed 59.76 f/s\n",
            "912948 frames: done 3246 games, mean reward 35.55,  187 frame/episode, eps 0.1, speed 59.38 f/s\n",
            "913822 frames: done 3249 games, mean reward 34.81,  360 frame/episode, eps 0.1, speed 62.79 f/s\n",
            "914572 frames: done 3252 games, mean reward 34.77,  190 frame/episode, eps 0.1, speed 64.68 f/s\n",
            "915407 frames: done 3255 games, mean reward 34.9,  232 frame/episode, eps 0.1, speed 62.24 f/s\n",
            "916197 frames: done 3258 games, mean reward 34.69,  271 frame/episode, eps 0.1, speed 58.87 f/s\n",
            "916781 frames: done 3261 games, mean reward 33.71,  159 frame/episode, eps 0.1, speed 61.44 f/s\n",
            "917570 frames: done 3264 games, mean reward 32.88,  256 frame/episode, eps 0.1, speed 63.25 f/s\n",
            "918334 frames: done 3267 games, mean reward 32.65,  259 frame/episode, eps 0.1, speed 64.65 f/s\n",
            "919007 frames: done 3270 games, mean reward 32.53,  182 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "919823 frames: done 3273 games, mean reward 32.74,  265 frame/episode, eps 0.1, speed 63.67 f/s\n",
            "920569 frames: done 3276 games, mean reward 32.89,  309 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "921425 frames: done 3279 games, mean reward 32.93,  343 frame/episode, eps 0.1, speed 64.84 f/s\n",
            "922192 frames: done 3282 games, mean reward 32.51,  290 frame/episode, eps 0.1, speed 64.56 f/s\n",
            "922954 frames: done 3285 games, mean reward 32.36,  289 frame/episode, eps 0.1, speed 64.67 f/s\n",
            "923703 frames: done 3288 games, mean reward 31.87,  337 frame/episode, eps 0.1, speed 64.83 f/s\n",
            "924328 frames: done 3291 games, mean reward 31.12,  220 frame/episode, eps 0.1, speed 64.96 f/s\n",
            "925241 frames: done 3294 games, mean reward 30.95,  277 frame/episode, eps 0.1, speed 64.83 f/s\n",
            "926049 frames: done 3297 games, mean reward 31.55,  283 frame/episode, eps 0.1, speed 64.8 f/s\n",
            "926959 frames: done 3300 games, mean reward 32.02,  333 frame/episode, eps 0.1, speed 63.67 f/s\n",
            "927709 frames: done 3303 games, mean reward 31.74,  282 frame/episode, eps 0.1, speed 63.28 f/s\n",
            "928576 frames: done 3306 games, mean reward 31.86,  277 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "929654 frames: done 3309 games, mean reward 32.36,  433 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "930453 frames: done 3312 games, mean reward 32.51,  216 frame/episode, eps 0.1, speed 65.34 f/s\n",
            "931247 frames: done 3315 games, mean reward 32.65,  277 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "931985 frames: done 3318 games, mean reward 31.05,  255 frame/episode, eps 0.1, speed 63.92 f/s\n",
            "932731 frames: done 3321 games, mean reward 31.19,  259 frame/episode, eps 0.1, speed 64.98 f/s\n",
            "933633 frames: done 3324 games, mean reward 30.61,  353 frame/episode, eps 0.1, speed 63.81 f/s\n",
            "934545 frames: done 3327 games, mean reward 30.47,  228 frame/episode, eps 0.1, speed 64.04 f/s\n",
            "935498 frames: done 3330 games, mean reward 30.92,  375 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "936434 frames: done 3333 games, mean reward 31.59,  386 frame/episode, eps 0.1, speed 64.58 f/s\n",
            "937050 frames: done 3336 games, mean reward 30.91,  169 frame/episode, eps 0.1, speed 63.51 f/s\n",
            "938057 frames: done 3339 games, mean reward 30.99,  245 frame/episode, eps 0.1, speed 64.42 f/s\n",
            "938768 frames: done 3342 games, mean reward 31.23,  210 frame/episode, eps 0.1, speed 63.58 f/s\n",
            "939536 frames: done 3345 games, mean reward 28.58,  261 frame/episode, eps 0.1, speed 65.88 f/s\n",
            "940472 frames: done 3348 games, mean reward 28.72,  346 frame/episode, eps 0.1, speed 65.18 f/s\n",
            "941242 frames: done 3351 games, mean reward 28.12,  277 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "941976 frames: done 3354 games, mean reward 28.1,  185 frame/episode, eps 0.1, speed 64.77 f/s\n",
            "942806 frames: done 3357 games, mean reward 28.21,  265 frame/episode, eps 0.1, speed 63.8 f/s\n",
            "943620 frames: done 3360 games, mean reward 28.12,  291 frame/episode, eps 0.1, speed 65.05 f/s\n",
            "944872 frames: done 3363 games, mean reward 28.54,  237 frame/episode, eps 0.1, speed 65.15 f/s\n",
            "945742 frames: done 3366 games, mean reward 28.9,  272 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "946423 frames: done 3369 games, mean reward 28.5,  310 frame/episode, eps 0.1, speed 64.25 f/s\n",
            "947254 frames: done 3372 games, mean reward 28.59,  227 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "947954 frames: done 3375 games, mean reward 28.68,  208 frame/episode, eps 0.1, speed 63.98 f/s\n",
            "948794 frames: done 3378 games, mean reward 28.73,  267 frame/episode, eps 0.1, speed 64.61 f/s\n",
            "949705 frames: done 3381 games, mean reward 29.19,  273 frame/episode, eps 0.1, speed 65.67 f/s\n",
            "950557 frames: done 3384 games, mean reward 29.29,  370 frame/episode, eps 0.1, speed 65.26 f/s\n",
            "951335 frames: done 3387 games, mean reward 29.7,  304 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "952125 frames: done 3390 games, mean reward 29.8,  286 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "952904 frames: done 3393 games, mean reward 30.1,  276 frame/episode, eps 0.1, speed 63.47 f/s\n",
            "953669 frames: done 3396 games, mean reward 29.95,  318 frame/episode, eps 0.1, speed 63.51 f/s\n",
            "954559 frames: done 3399 games, mean reward 29.35,  378 frame/episode, eps 0.1, speed 64.89 f/s\n",
            "  --Try 0: t=214, reward=33.0 Best reward updated\n",
            "  --Try 1: t=293, reward=51.0 Best reward updated\n",
            "  --Try 2: t=257, reward=37.0\n",
            "  --Try 3: t=216, reward=26.0\n",
            "  --Try 4: t=247, reward=36.0\n",
            "  --Try 5: t=249, reward=39.0\n",
            "  --Try 6: t=247, reward=36.0\n",
            "  --Try 7: t=258, reward=35.0\n",
            "  --Try 8: t=258, reward=40.0\n",
            "  --Try 9: t=201, reward=18.0\n",
            "  --Generating animation..\n",
            " --Animationm from 294 frames with reward 51.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 34.7 -> 29.11, model saved\n",
            "955137 frames: done 3402 games, mean reward 29.08,  217 frame/episode, eps 0.1, speed 64.17 f/s\n",
            "955956 frames: done 3405 games, mean reward 28.87,  328 frame/episode, eps 0.1, speed 64.95 f/s\n",
            "956820 frames: done 3408 games, mean reward 28.5,  284 frame/episode, eps 0.1, speed 63.82 f/s\n",
            "957669 frames: done 3411 games, mean reward 27.98,  223 frame/episode, eps 0.1, speed 64.38 f/s\n",
            "958366 frames: done 3414 games, mean reward 27.86,  208 frame/episode, eps 0.1, speed 64.02 f/s\n",
            "959049 frames: done 3417 games, mean reward 27.73,  252 frame/episode, eps 0.1, speed 64.76 f/s\n",
            "959860 frames: done 3420 games, mean reward 27.87,  223 frame/episode, eps 0.1, speed 64.04 f/s\n",
            "960744 frames: done 3423 games, mean reward 29.24,  237 frame/episode, eps 0.1, speed 64.39 f/s\n",
            "961589 frames: done 3426 games, mean reward 29.92,  288 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "962462 frames: done 3429 games, mean reward 29.68,  361 frame/episode, eps 0.1, speed 65.07 f/s\n",
            "963465 frames: done 3432 games, mean reward 29.26,  287 frame/episode, eps 0.1, speed 64.18 f/s\n",
            "964271 frames: done 3435 games, mean reward 28.93,  274 frame/episode, eps 0.1, speed 63.79 f/s\n",
            "964992 frames: done 3438 games, mean reward 28.97,  275 frame/episode, eps 0.1, speed 64.59 f/s\n",
            "965906 frames: done 3441 games, mean reward 29.59,  255 frame/episode, eps 0.1, speed 64.95 f/s\n",
            "966737 frames: done 3444 games, mean reward 30.33,  299 frame/episode, eps 0.1, speed 64.69 f/s\n",
            "967593 frames: done 3447 games, mean reward 30.15,  357 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "968413 frames: done 3450 games, mean reward 30.72,  210 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "969164 frames: done 3453 games, mean reward 30.91,  223 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "969937 frames: done 3456 games, mean reward 31.24,  228 frame/episode, eps 0.1, speed 63.25 f/s\n",
            "970760 frames: done 3459 games, mean reward 31.55,  253 frame/episode, eps 0.1, speed 63.58 f/s\n",
            "971396 frames: done 3462 games, mean reward 31.53,  210 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "972236 frames: done 3465 games, mean reward 31.25,  234 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "972941 frames: done 3468 games, mean reward 31.36,  246 frame/episode, eps 0.1, speed 64.86 f/s\n",
            "973638 frames: done 3471 games, mean reward 31.27,  208 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "974393 frames: done 3474 games, mean reward 31.29,  288 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "975305 frames: done 3477 games, mean reward 31.57,  279 frame/episode, eps 0.1, speed 65.3 f/s\n",
            "976170 frames: done 3480 games, mean reward 31.59,  250 frame/episode, eps 0.1, speed 64.39 f/s\n",
            "976823 frames: done 3483 games, mean reward 31.15,  171 frame/episode, eps 0.1, speed 65.54 f/s\n",
            "977609 frames: done 3486 games, mean reward 31.4,  324 frame/episode, eps 0.1, speed 64.55 f/s\n",
            "978343 frames: done 3489 games, mean reward 31.4,  229 frame/episode, eps 0.1, speed 64.71 f/s\n",
            "979257 frames: done 3492 games, mean reward 32.06,  216 frame/episode, eps 0.1, speed 65.15 f/s\n",
            "980125 frames: done 3495 games, mean reward 32.2,  319 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "980817 frames: done 3498 games, mean reward 32.2,  150 frame/episode, eps 0.1, speed 64.05 f/s\n",
            "981645 frames: done 3501 games, mean reward 32.88,  288 frame/episode, eps 0.1, speed 65.18 f/s\n",
            "982337 frames: done 3504 games, mean reward 32.67,  270 frame/episode, eps 0.1, speed 64.49 f/s\n",
            "983132 frames: done 3507 games, mean reward 32.89,  270 frame/episode, eps 0.1, speed 65.16 f/s\n",
            "983946 frames: done 3510 games, mean reward 32.8,  272 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "984756 frames: done 3513 games, mean reward 33.4,  281 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "985498 frames: done 3516 games, mean reward 33.69,  262 frame/episode, eps 0.1, speed 65.51 f/s\n",
            "986437 frames: done 3519 games, mean reward 33.99,  396 frame/episode, eps 0.1, speed 64.33 f/s\n",
            "987239 frames: done 3522 games, mean reward 32.47,  195 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "987922 frames: done 3525 games, mean reward 32.05,  220 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "989016 frames: done 3528 games, mean reward 32.19,  337 frame/episode, eps 0.1, speed 64.48 f/s\n",
            "990024 frames: done 3531 games, mean reward 33.15,  395 frame/episode, eps 0.1, speed 64.63 f/s\n",
            "990969 frames: done 3534 games, mean reward 33.29,  287 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "991806 frames: done 3537 games, mean reward 34.19,  243 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "992757 frames: done 3540 games, mean reward 33.78,  397 frame/episode, eps 0.1, speed 65.17 f/s\n",
            "993598 frames: done 3543 games, mean reward 34.01,  334 frame/episode, eps 0.1, speed 65.19 f/s\n",
            "994464 frames: done 3546 games, mean reward 34.46,  256 frame/episode, eps 0.1, speed 64.38 f/s\n",
            "995361 frames: done 3549 games, mean reward 34.68,  305 frame/episode, eps 0.1, speed 65.8 f/s\n",
            "996215 frames: done 3552 games, mean reward 34.44,  376 frame/episode, eps 0.1, speed 64.43 f/s\n",
            "996998 frames: done 3555 games, mean reward 33.96,  279 frame/episode, eps 0.1, speed 63.57 f/s\n",
            "997790 frames: done 3558 games, mean reward 33.91,  224 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "998658 frames: done 3561 games, mean reward 34.37,  261 frame/episode, eps 0.1, speed 64.43 f/s\n",
            "999444 frames: done 3564 games, mean reward 34.93,  246 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "1000286 frames: done 3567 games, mean reward 35.63,  284 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "1001077 frames: done 3570 games, mean reward 36.28,  334 frame/episode, eps 0.1, speed 65.43 f/s\n",
            "1002093 frames: done 3573 games, mean reward 39.13,  295 frame/episode, eps 0.1, speed 63.97 f/s\n",
            "1002894 frames: done 3576 games, mean reward 39.14,  367 frame/episode, eps 0.1, speed 64.88 f/s\n",
            "1003694 frames: done 3579 games, mean reward 38.78,  344 frame/episode, eps 0.1, speed 63.54 f/s\n",
            "1004272 frames: done 3582 games, mean reward 38.26,  328 frame/episode, eps 0.1, speed 65.05 f/s\n",
            "1005131 frames: done 3585 games, mean reward 39.07,  214 frame/episode, eps 0.1, speed 65.4 f/s\n",
            "1006236 frames: done 3588 games, mean reward 39.71,  362 frame/episode, eps 0.1, speed 65.13 f/s\n",
            "1007124 frames: done 3591 games, mean reward 39.43,  257 frame/episode, eps 0.1, speed 65.07 f/s\n",
            "1008199 frames: done 3594 games, mean reward 41.01,  227 frame/episode, eps 0.1, speed 66.03 f/s\n",
            "1009155 frames: done 3597 games, mean reward 41.89,  347 frame/episode, eps 0.1, speed 65.4 f/s\n",
            "1010050 frames: done 3600 games, mean reward 41.74,  320 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "  --Try 0: t=586, reward=40.0 Best reward updated\n",
            "  --Try 1: t=300, reward=41.0 Best reward updated\n",
            "  --Try 2: t=495, reward=66.0 Best reward updated\n",
            "  --Try 3: t=387, reward=40.0\n",
            "  --Try 4: t=323, reward=30.0\n",
            "  --Try 5: t=381, reward=221.0 Best reward updated\n",
            "  --Try 6: t=251, reward=29.0\n",
            "  --Try 7: t=237, reward=35.0\n",
            "  --Try 8: t=416, reward=148.0\n",
            "  --Try 9: t=442, reward=221.0\n",
            "  --Generating animation..\n",
            " --Animationm from 382 frames with reward 221.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 29.11 -> 41.74, model saved\n",
            "1010878 frames: done 3603 games, mean reward 42.2,  257 frame/episode, eps 0.1, speed 65.04 f/s\n",
            "1011493 frames: done 3606 games, mean reward 41.82,  138 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1012324 frames: done 3609 games, mean reward 41.8,  179 frame/episode, eps 0.1, speed 65.75 f/s\n",
            "1013105 frames: done 3612 games, mean reward 41.69,  259 frame/episode, eps 0.1, speed 65.26 f/s\n",
            "1013876 frames: done 3615 games, mean reward 41.68,  279 frame/episode, eps 0.1, speed 65.74 f/s\n",
            "1014682 frames: done 3618 games, mean reward 41.73,  280 frame/episode, eps 0.1, speed 65.99 f/s\n",
            "1015411 frames: done 3621 games, mean reward 41.43,  162 frame/episode, eps 0.1, speed 65.69 f/s\n",
            "1016203 frames: done 3624 games, mean reward 42.04,  266 frame/episode, eps 0.1, speed 66.49 f/s\n",
            "1016991 frames: done 3627 games, mean reward 41.93,  264 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "1017751 frames: done 3630 games, mean reward 42.12,  299 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "1018493 frames: done 3633 games, mean reward 41.16,  314 frame/episode, eps 0.1, speed 65.76 f/s\n",
            "1019302 frames: done 3636 games, mean reward 40.58,  268 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "1019985 frames: done 3639 games, mean reward 40.58,  175 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "1020856 frames: done 3642 games, mean reward 40.54,  241 frame/episode, eps 0.1, speed 65.41 f/s\n",
            "1021658 frames: done 3645 games, mean reward 39.42,  268 frame/episode, eps 0.1, speed 65.58 f/s\n",
            "1022410 frames: done 3648 games, mean reward 39.43,  223 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "1023295 frames: done 3651 games, mean reward 39.94,  302 frame/episode, eps 0.1, speed 64.96 f/s\n",
            "1024246 frames: done 3654 games, mean reward 40.39,  298 frame/episode, eps 0.1, speed 65.6 f/s\n",
            "1024969 frames: done 3657 games, mean reward 40.35,  210 frame/episode, eps 0.1, speed 65.72 f/s\n",
            "1025739 frames: done 3660 games, mean reward 40.24,  283 frame/episode, eps 0.1, speed 65.57 f/s\n",
            "1026713 frames: done 3663 games, mean reward 39.99,  415 frame/episode, eps 0.1, speed 62.88 f/s\n",
            "1027609 frames: done 3666 games, mean reward 39.8,  210 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "1028474 frames: done 3669 games, mean reward 39.79,  348 frame/episode, eps 0.1, speed 65.86 f/s\n",
            "1029294 frames: done 3672 games, mean reward 37.16,  224 frame/episode, eps 0.1, speed 64.24 f/s\n",
            "1030143 frames: done 3675 games, mean reward 37.45,  321 frame/episode, eps 0.1, speed 65.7 f/s\n",
            "1030874 frames: done 3678 games, mean reward 37.22,  282 frame/episode, eps 0.1, speed 65.09 f/s\n",
            "1031545 frames: done 3681 games, mean reward 37.44,  265 frame/episode, eps 0.1, speed 64.8 f/s\n",
            "1032510 frames: done 3684 games, mean reward 37.04,  325 frame/episode, eps 0.1, speed 65.58 f/s\n",
            "1033237 frames: done 3687 games, mean reward 36.56,  193 frame/episode, eps 0.1, speed 65.25 f/s\n",
            "1034054 frames: done 3690 games, mean reward 36.14,  241 frame/episode, eps 0.1, speed 65.81 f/s\n",
            "1034840 frames: done 3693 games, mean reward 34.65,  305 frame/episode, eps 0.1, speed 65.42 f/s\n",
            "1035757 frames: done 3696 games, mean reward 34.41,  368 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "1036544 frames: done 3699 games, mean reward 34.14,  269 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "1037310 frames: done 3702 games, mean reward 33.98,  240 frame/episode, eps 0.1, speed 65.91 f/s\n",
            "1038098 frames: done 3705 games, mean reward 34.24,  261 frame/episode, eps 0.1, speed 65.89 f/s\n",
            "1038898 frames: done 3708 games, mean reward 33.7,  229 frame/episode, eps 0.1, speed 64.68 f/s\n",
            "1039758 frames: done 3711 games, mean reward 33.88,  326 frame/episode, eps 0.1, speed 65.22 f/s\n",
            "1040718 frames: done 3714 games, mean reward 33.99,  434 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "1041414 frames: done 3717 games, mean reward 33.52,  268 frame/episode, eps 0.1, speed 65.31 f/s\n",
            "1042315 frames: done 3720 games, mean reward 33.32,  333 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "1042974 frames: done 3723 games, mean reward 33.33,  197 frame/episode, eps 0.1, speed 65.47 f/s\n",
            "1043818 frames: done 3726 games, mean reward 33.54,  286 frame/episode, eps 0.1, speed 65.75 f/s\n",
            "1044569 frames: done 3729 games, mean reward 33.33,  230 frame/episode, eps 0.1, speed 64.24 f/s\n",
            "1045297 frames: done 3732 games, mean reward 32.92,  303 frame/episode, eps 0.1, speed 65.2 f/s\n",
            "1046243 frames: done 3735 games, mean reward 32.26,  339 frame/episode, eps 0.1, speed 64.62 f/s\n",
            "1047090 frames: done 3738 games, mean reward 32.22,  264 frame/episode, eps 0.1, speed 63.83 f/s\n",
            "1048068 frames: done 3741 games, mean reward 33.17,  318 frame/episode, eps 0.1, speed 64.99 f/s\n",
            "1048877 frames: done 3744 games, mean reward 33.67,  243 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "1049624 frames: done 3747 games, mean reward 33.13,  293 frame/episode, eps 0.1, speed 65.04 f/s\n",
            "1050370 frames: done 3750 games, mean reward 32.93,  264 frame/episode, eps 0.1, speed 65.79 f/s\n",
            "1051177 frames: done 3753 games, mean reward 33.13,  261 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "1052204 frames: done 3756 games, mean reward 33.3,  383 frame/episode, eps 0.1, speed 65.17 f/s\n",
            "1053016 frames: done 3759 games, mean reward 33.29,  297 frame/episode, eps 0.1, speed 64.98 f/s\n",
            "1053978 frames: done 3762 games, mean reward 33.97,  327 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "1054770 frames: done 3765 games, mean reward 34.19,  303 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "1055742 frames: done 3768 games, mean reward 36.14,  393 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "1056612 frames: done 3771 games, mean reward 36.92,  248 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "1057486 frames: done 3774 games, mean reward 37.21,  296 frame/episode, eps 0.1, speed 65.69 f/s\n",
            "1058347 frames: done 3777 games, mean reward 37.03,  326 frame/episode, eps 0.1, speed 65.94 f/s\n",
            "1059182 frames: done 3780 games, mean reward 37.43,  241 frame/episode, eps 0.1, speed 64.86 f/s\n",
            "1060037 frames: done 3783 games, mean reward 37.6,  270 frame/episode, eps 0.1, speed 65.17 f/s\n",
            "1060950 frames: done 3786 games, mean reward 37.5,  269 frame/episode, eps 0.1, speed 65.75 f/s\n",
            "1061777 frames: done 3789 games, mean reward 37.73,  248 frame/episode, eps 0.1, speed 66.64 f/s\n",
            "1062495 frames: done 3792 games, mean reward 37.92,  251 frame/episode, eps 0.1, speed 66.59 f/s\n",
            "1063309 frames: done 3795 games, mean reward 37.89,  313 frame/episode, eps 0.1, speed 65.9 f/s\n",
            "1064059 frames: done 3798 games, mean reward 37.84,  301 frame/episode, eps 0.1, speed 66.08 f/s\n",
            "  --Try 0: t=323, reward=69.0 Best reward updated\n",
            "  --Try 1: t=458, reward=304.0 Best reward updated\n",
            "  --Try 2: t=328, reward=61.0\n",
            "  --Try 3: t=225, reward=27.0\n",
            "  --Try 4: t=278, reward=43.0\n",
            "  --Try 5: t=269, reward=16.0\n",
            "  --Try 6: t=246, reward=35.0\n",
            "  --Try 7: t=552, reward=237.0\n",
            "  --Try 8: t=264, reward=38.0\n",
            "  --Try 9: t=388, reward=98.0\n",
            "  --Generating animation..\n",
            " --Animationm from 459 frames with reward 304.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 41.74 -> 37.86, model saved\n",
            "1064864 frames: done 3801 games, mean reward 37.82,  234 frame/episode, eps 0.1, speed 2.96 f/s\n",
            "1065638 frames: done 3804 games, mean reward 37.67,  263 frame/episode, eps 0.1, speed 64.98 f/s\n",
            "1066457 frames: done 3807 games, mean reward 38.52,  328 frame/episode, eps 0.1, speed 65.45 f/s\n",
            "1067257 frames: done 3810 games, mean reward 38.77,  280 frame/episode, eps 0.1, speed 65.65 f/s\n",
            "1068180 frames: done 3813 games, mean reward 39.26,  196 frame/episode, eps 0.1, speed 65.17 f/s\n",
            "1068870 frames: done 3816 games, mean reward 39.39,  241 frame/episode, eps 0.1, speed 66.12 f/s\n",
            "1069754 frames: done 3819 games, mean reward 39.75,  327 frame/episode, eps 0.1, speed 65.39 f/s\n",
            "1070507 frames: done 3822 games, mean reward 39.59,  239 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "1071172 frames: done 3825 games, mean reward 39.34,  241 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "1071857 frames: done 3828 games, mean reward 38.96,  207 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "1072676 frames: done 3831 games, mean reward 39.41,  301 frame/episode, eps 0.1, speed 65.89 f/s\n",
            "1073513 frames: done 3834 games, mean reward 40.09,  266 frame/episode, eps 0.1, speed 65.99 f/s\n",
            "1074754 frames: done 3837 games, mean reward 40.12,  323 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "1075481 frames: done 3840 games, mean reward 39.79,  278 frame/episode, eps 0.1, speed 65.53 f/s\n",
            "1076355 frames: done 3843 games, mean reward 39.91,  323 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "1077126 frames: done 3846 games, mean reward 40.11,  330 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "1078035 frames: done 3849 games, mean reward 40.25,  286 frame/episode, eps 0.1, speed 65.71 f/s\n",
            "1078898 frames: done 3852 games, mean reward 40.37,  254 frame/episode, eps 0.1, speed 65.67 f/s\n",
            "1079908 frames: done 3855 games, mean reward 40.47,  257 frame/episode, eps 0.1, speed 65.52 f/s\n",
            "1080760 frames: done 3858 games, mean reward 40.56,  394 frame/episode, eps 0.1, speed 65.72 f/s\n",
            "1081614 frames: done 3861 games, mean reward 40.2,  333 frame/episode, eps 0.1, speed 65.23 f/s\n",
            "1082384 frames: done 3864 games, mean reward 39.62,  245 frame/episode, eps 0.1, speed 63.26 f/s\n",
            "1083108 frames: done 3867 games, mean reward 39.67,  282 frame/episode, eps 0.1, speed 65.26 f/s\n",
            "1083921 frames: done 3870 games, mean reward 36.35,  277 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "1084795 frames: done 3873 games, mean reward 36.4,  277 frame/episode, eps 0.1, speed 66.1 f/s\n",
            "1085722 frames: done 3876 games, mean reward 36.87,  357 frame/episode, eps 0.1, speed 65.95 f/s\n",
            "1086582 frames: done 3879 games, mean reward 36.66,  297 frame/episode, eps 0.1, speed 65.37 f/s\n",
            "1087271 frames: done 3882 games, mean reward 36.17,  185 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "1088077 frames: done 3885 games, mean reward 35.67,  192 frame/episode, eps 0.1, speed 65.34 f/s\n",
            "1088806 frames: done 3888 games, mean reward 35.38,  205 frame/episode, eps 0.1, speed 65.48 f/s\n",
            "1089740 frames: done 3891 games, mean reward 36.04,  298 frame/episode, eps 0.1, speed 66.1 f/s\n",
            "1090461 frames: done 3894 games, mean reward 35.81,  271 frame/episode, eps 0.1, speed 65.59 f/s\n",
            "1091226 frames: done 3897 games, mean reward 35.78,  273 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "1091865 frames: done 3900 games, mean reward 35.19,  187 frame/episode, eps 0.1, speed 66.79 f/s\n",
            "1092718 frames: done 3903 games, mean reward 35.57,  307 frame/episode, eps 0.1, speed 65.49 f/s\n",
            "1093380 frames: done 3906 games, mean reward 35.19,  180 frame/episode, eps 0.1, speed 64.75 f/s\n",
            "1094114 frames: done 3909 games, mean reward 34.93,  288 frame/episode, eps 0.1, speed 65.52 f/s\n",
            "1095062 frames: done 3912 games, mean reward 34.07,  236 frame/episode, eps 0.1, speed 66.22 f/s\n",
            "1096031 frames: done 3915 games, mean reward 36.43,  418 frame/episode, eps 0.1, speed 65.97 f/s\n",
            "1096892 frames: done 3918 games, mean reward 36.95,  339 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "1097757 frames: done 3921 games, mean reward 37.39,  262 frame/episode, eps 0.1, speed 64.88 f/s\n",
            "1098674 frames: done 3924 games, mean reward 37.63,  358 frame/episode, eps 0.1, speed 65.88 f/s\n",
            "1099534 frames: done 3927 games, mean reward 38.64,  307 frame/episode, eps 0.1, speed 65.38 f/s\n",
            "1100317 frames: done 3930 games, mean reward 38.78,  257 frame/episode, eps 0.1, speed 64.96 f/s\n",
            "1101239 frames: done 3933 games, mean reward 38.74,  249 frame/episode, eps 0.1, speed 65.45 f/s\n",
            "1102025 frames: done 3936 games, mean reward 39.07,  307 frame/episode, eps 0.1, speed 65.49 f/s\n",
            "1102878 frames: done 3939 games, mean reward 38.99,  267 frame/episode, eps 0.1, speed 63.49 f/s\n",
            "1103868 frames: done 3942 games, mean reward 38.8,  353 frame/episode, eps 0.1, speed 65.88 f/s\n",
            "1104739 frames: done 3945 games, mean reward 39.02,  281 frame/episode, eps 0.1, speed 64.81 f/s\n",
            "1105392 frames: done 3948 games, mean reward 38.58,  148 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1106181 frames: done 3951 games, mean reward 38.13,  275 frame/episode, eps 0.1, speed 65.46 f/s\n",
            "1107066 frames: done 3954 games, mean reward 37.41,  368 frame/episode, eps 0.1, speed 66.04 f/s\n",
            "1107745 frames: done 3957 games, mean reward 37.6,  271 frame/episode, eps 0.1, speed 66.37 f/s\n",
            "1108706 frames: done 3960 games, mean reward 37.38,  348 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "1109476 frames: done 3963 games, mean reward 37.77,  331 frame/episode, eps 0.1, speed 65.2 f/s\n",
            "1110290 frames: done 3966 games, mean reward 38.13,  268 frame/episode, eps 0.1, speed 63.37 f/s\n",
            "1111204 frames: done 3969 games, mean reward 38.17,  260 frame/episode, eps 0.1, speed 66.16 f/s\n",
            "1111897 frames: done 3972 games, mean reward 38.25,  281 frame/episode, eps 0.1, speed 61.07 f/s\n",
            "1112631 frames: done 3975 games, mean reward 38.3,  257 frame/episode, eps 0.1, speed 63.64 f/s\n",
            "1113316 frames: done 3978 games, mean reward 37.63,  265 frame/episode, eps 0.1, speed 61.64 f/s\n",
            "1114218 frames: done 3981 games, mean reward 38.21,  380 frame/episode, eps 0.1, speed 60.63 f/s\n",
            "1115154 frames: done 3984 games, mean reward 40.04,  274 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "1116265 frames: done 3987 games, mean reward 40.02,  334 frame/episode, eps 0.1, speed 63.8 f/s\n",
            "1116863 frames: done 3990 games, mean reward 39.32,  173 frame/episode, eps 0.1, speed 64.12 f/s\n",
            "1117739 frames: done 3993 games, mean reward 38.88,  332 frame/episode, eps 0.1, speed 63.81 f/s\n",
            "1118478 frames: done 3996 games, mean reward 39.12,  213 frame/episode, eps 0.1, speed 63.59 f/s\n",
            "1119199 frames: done 3999 games, mean reward 39.15,  270 frame/episode, eps 0.1, speed 64.24 f/s\n",
            "  --Try 0: t=413, reward=175.0 Best reward updated\n",
            "  --Try 1: t=429, reward=69.0\n",
            "  --Try 2: t=513, reward=175.0\n",
            "  --Try 3: t=338, reward=27.0\n",
            "  --Try 4: t=248, reward=35.0\n",
            "  --Try 5: t=488, reward=351.0 Best reward updated\n",
            "  --Try 6: t=346, reward=69.0\n",
            "  --Try 7: t=268, reward=39.0\n",
            "  --Try 8: t=245, reward=33.0\n",
            "  --Try 9: t=312, reward=38.0\n",
            "  --Generating animation..\n",
            " --Animationm from 489 frames with reward 351.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 37.86 -> 39.44, model saved\n",
            "1120043 frames: done 4002 games, mean reward 39.57,  239 frame/episode, eps 0.1, speed 63.9 f/s\n",
            "1120821 frames: done 4005 games, mean reward 39.43,  276 frame/episode, eps 0.1, speed 63.91 f/s\n",
            "1121618 frames: done 4008 games, mean reward 39.47,  275 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "1122564 frames: done 4011 games, mean reward 39.08,  218 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "1123461 frames: done 4014 games, mean reward 39.42,  385 frame/episode, eps 0.1, speed 63.25 f/s\n",
            "1124392 frames: done 4017 games, mean reward 37.34,  316 frame/episode, eps 0.1, speed 64.67 f/s\n",
            "1125106 frames: done 4020 games, mean reward 36.69,  191 frame/episode, eps 0.1, speed 64.05 f/s\n",
            "1126104 frames: done 4023 games, mean reward 36.7,  370 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "1126821 frames: done 4026 games, mean reward 36.54,  252 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "1127880 frames: done 4029 games, mean reward 36.54,  302 frame/episode, eps 0.1, speed 64.17 f/s\n",
            "1128759 frames: done 4032 games, mean reward 36.52,  288 frame/episode, eps 0.1, speed 63.97 f/s\n",
            "1129857 frames: done 4035 games, mean reward 38.25,  310 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "1130527 frames: done 4038 games, mean reward 38.07,  201 frame/episode, eps 0.1, speed 64.87 f/s\n",
            "1131366 frames: done 4041 games, mean reward 37.77,  257 frame/episode, eps 0.1, speed 64.39 f/s\n",
            "1132161 frames: done 4044 games, mean reward 37.69,  232 frame/episode, eps 0.1, speed 64.61 f/s\n",
            "1132883 frames: done 4047 games, mean reward 37.59,  171 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "1133598 frames: done 4050 games, mean reward 37.89,  263 frame/episode, eps 0.1, speed 63.19 f/s\n",
            "1134435 frames: done 4053 games, mean reward 38.08,  299 frame/episode, eps 0.1, speed 65.04 f/s\n",
            "1135059 frames: done 4056 games, mean reward 38.13,  325 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "1135817 frames: done 4059 games, mean reward 38.0,  268 frame/episode, eps 0.1, speed 64.52 f/s\n",
            "1136521 frames: done 4062 games, mean reward 38.36,  279 frame/episode, eps 0.1, speed 64.53 f/s\n",
            "1137397 frames: done 4065 games, mean reward 37.96,  337 frame/episode, eps 0.1, speed 62.02 f/s\n",
            "1138217 frames: done 4068 games, mean reward 37.32,  326 frame/episode, eps 0.1, speed 64.22 f/s\n",
            "1139028 frames: done 4071 games, mean reward 37.88,  294 frame/episode, eps 0.1, speed 63.9 f/s\n",
            "1140077 frames: done 4074 games, mean reward 39.69,  271 frame/episode, eps 0.1, speed 65.15 f/s\n",
            "1140926 frames: done 4077 games, mean reward 40.17,  283 frame/episode, eps 0.1, speed 64.36 f/s\n",
            "1141789 frames: done 4080 games, mean reward 40.1,  297 frame/episode, eps 0.1, speed 64.46 f/s\n",
            "1142541 frames: done 4083 games, mean reward 38.27,  228 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "1143389 frames: done 4086 games, mean reward 37.77,  220 frame/episode, eps 0.1, speed 63.84 f/s\n",
            "1144219 frames: done 4089 games, mean reward 37.87,  229 frame/episode, eps 0.1, speed 63.91 f/s\n",
            "1144904 frames: done 4092 games, mean reward 38.04,  244 frame/episode, eps 0.1, speed 64.77 f/s\n",
            "1145734 frames: done 4095 games, mean reward 37.62,  278 frame/episode, eps 0.1, speed 64.09 f/s\n",
            "1146659 frames: done 4098 games, mean reward 37.97,  315 frame/episode, eps 0.1, speed 63.99 f/s\n",
            "1147457 frames: done 4101 games, mean reward 37.73,  265 frame/episode, eps 0.1, speed 64.24 f/s\n",
            "1148329 frames: done 4104 games, mean reward 38.02,  271 frame/episode, eps 0.1, speed 64.55 f/s\n",
            "1149207 frames: done 4107 games, mean reward 38.38,  308 frame/episode, eps 0.1, speed 63.72 f/s\n",
            "1149919 frames: done 4110 games, mean reward 38.42,  224 frame/episode, eps 0.1, speed 64.51 f/s\n",
            "1150731 frames: done 4113 games, mean reward 38.73,  241 frame/episode, eps 0.1, speed 64.31 f/s\n",
            "1151577 frames: done 4116 games, mean reward 38.35,  243 frame/episode, eps 0.1, speed 62.96 f/s\n",
            "1152248 frames: done 4119 games, mean reward 37.5,  177 frame/episode, eps 0.1, speed 64.24 f/s\n",
            "1152974 frames: done 4122 games, mean reward 37.24,  216 frame/episode, eps 0.1, speed 64.03 f/s\n",
            "1153953 frames: done 4125 games, mean reward 39.06,  451 frame/episode, eps 0.1, speed 63.34 f/s\n",
            "1154807 frames: done 4128 games, mean reward 39.05,  248 frame/episode, eps 0.1, speed 64.21 f/s\n",
            "1155634 frames: done 4131 games, mean reward 38.51,  255 frame/episode, eps 0.1, speed 64.53 f/s\n",
            "1156529 frames: done 4134 games, mean reward 37.42,  242 frame/episode, eps 0.1, speed 64.79 f/s\n",
            "1157298 frames: done 4137 games, mean reward 36.89,  268 frame/episode, eps 0.1, speed 63.56 f/s\n",
            "1158054 frames: done 4140 games, mean reward 36.95,  245 frame/episode, eps 0.1, speed 64.87 f/s\n",
            "1158823 frames: done 4143 games, mean reward 36.7,  269 frame/episode, eps 0.1, speed 63.96 f/s\n",
            "1159611 frames: done 4146 games, mean reward 36.79,  232 frame/episode, eps 0.1, speed 64.14 f/s\n",
            "1160362 frames: done 4149 games, mean reward 37.13,  222 frame/episode, eps 0.1, speed 63.75 f/s\n",
            "1161103 frames: done 4152 games, mean reward 36.87,  256 frame/episode, eps 0.1, speed 63.56 f/s\n",
            "1161876 frames: done 4155 games, mean reward 36.98,  292 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "1162558 frames: done 4158 games, mean reward 36.64,  202 frame/episode, eps 0.1, speed 63.4 f/s\n",
            "1163295 frames: done 4161 games, mean reward 36.4,  249 frame/episode, eps 0.1, speed 64.73 f/s\n",
            "1164226 frames: done 4164 games, mean reward 36.52,  351 frame/episode, eps 0.1, speed 64.14 f/s\n",
            "1165056 frames: done 4167 games, mean reward 36.61,  253 frame/episode, eps 0.1, speed 64.89 f/s\n",
            "1165844 frames: done 4170 games, mean reward 36.61,  254 frame/episode, eps 0.1, speed 62.97 f/s\n",
            "1166645 frames: done 4173 games, mean reward 34.1,  287 frame/episode, eps 0.1, speed 64.41 f/s\n",
            "1167432 frames: done 4176 games, mean reward 34.28,  265 frame/episode, eps 0.1, speed 64.26 f/s\n",
            "1168338 frames: done 4179 games, mean reward 34.76,  279 frame/episode, eps 0.1, speed 64.65 f/s\n",
            "1169302 frames: done 4182 games, mean reward 35.11,  312 frame/episode, eps 0.1, speed 64.04 f/s\n",
            "1170157 frames: done 4185 games, mean reward 35.2,  254 frame/episode, eps 0.1, speed 63.71 f/s\n",
            "1171064 frames: done 4188 games, mean reward 35.23,  355 frame/episode, eps 0.1, speed 64.36 f/s\n",
            "1171862 frames: done 4191 games, mean reward 35.87,  352 frame/episode, eps 0.1, speed 63.91 f/s\n",
            "1172745 frames: done 4194 games, mean reward 36.71,  253 frame/episode, eps 0.1, speed 64.65 f/s\n",
            "1173571 frames: done 4197 games, mean reward 36.95,  364 frame/episode, eps 0.1, speed 64.6 f/s\n",
            "1174423 frames: done 4200 games, mean reward 37.1,  257 frame/episode, eps 0.1, speed 64.37 f/s\n",
            "  --Try 0: t=320, reward=60.0 Best reward updated\n",
            "  --Try 1: t=294, reward=51.0\n",
            "  --Try 2: t=314, reward=62.0 Best reward updated\n",
            "  --Try 3: t=298, reward=54.0\n",
            "  --Try 4: t=345, reward=63.0 Best reward updated\n",
            "  --Try 5: t=279, reward=41.0\n",
            "  --Try 6: t=529, reward=327.0 Best reward updated\n",
            "  --Try 7: t=310, reward=41.0\n",
            "  --Try 8: t=276, reward=38.0\n",
            "  --Try 9: t=274, reward=48.0\n",
            "  --Generating animation..\n",
            " --Animationm from 530 frames with reward 327.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 39.44 -> 37.1, model saved\n",
            "1175194 frames: done 4203 games, mean reward 37.14,  234 frame/episode, eps 0.1, speed 63.51 f/s\n",
            "1176046 frames: done 4206 games, mean reward 37.55,  275 frame/episode, eps 0.1, speed 63.64 f/s\n",
            "1176906 frames: done 4209 games, mean reward 37.46,  197 frame/episode, eps 0.1, speed 64.07 f/s\n",
            "1177615 frames: done 4212 games, mean reward 37.35,  273 frame/episode, eps 0.1, speed 64.02 f/s\n",
            "1178371 frames: done 4215 games, mean reward 36.85,  292 frame/episode, eps 0.1, speed 63.78 f/s\n",
            "1179392 frames: done 4218 games, mean reward 36.91,  462 frame/episode, eps 0.1, speed 63.9 f/s\n",
            "1180281 frames: done 4221 games, mean reward 39.26,  427 frame/episode, eps 0.1, speed 64.37 f/s\n",
            "1180994 frames: done 4224 games, mean reward 39.4,  209 frame/episode, eps 0.1, speed 63.27 f/s\n",
            "1181806 frames: done 4227 games, mean reward 37.42,  347 frame/episode, eps 0.1, speed 64.36 f/s\n",
            "1182563 frames: done 4230 games, mean reward 37.91,  265 frame/episode, eps 0.1, speed 64.15 f/s\n",
            "1183320 frames: done 4233 games, mean reward 37.38,  203 frame/episode, eps 0.1, speed 64.15 f/s\n",
            "1184287 frames: done 4236 games, mean reward 37.8,  339 frame/episode, eps 0.1, speed 63.38 f/s\n",
            "1185130 frames: done 4239 games, mean reward 37.87,  254 frame/episode, eps 0.1, speed 63.36 f/s\n",
            "1185756 frames: done 4242 games, mean reward 37.36,  218 frame/episode, eps 0.1, speed 63.37 f/s\n",
            "1186548 frames: done 4245 games, mean reward 37.26,  325 frame/episode, eps 0.1, speed 63.53 f/s\n",
            "1187359 frames: done 4248 games, mean reward 36.96,  287 frame/episode, eps 0.1, speed 64.29 f/s\n",
            "1188295 frames: done 4251 games, mean reward 37.39,  315 frame/episode, eps 0.1, speed 63.98 f/s\n",
            "1189183 frames: done 4254 games, mean reward 37.69,  271 frame/episode, eps 0.1, speed 63.71 f/s\n",
            "1189956 frames: done 4257 games, mean reward 37.79,  238 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "1190717 frames: done 4260 games, mean reward 37.89,  293 frame/episode, eps 0.1, speed 62.51 f/s\n",
            "1191490 frames: done 4263 games, mean reward 37.47,  315 frame/episode, eps 0.1, speed 64.76 f/s\n",
            "1192276 frames: done 4266 games, mean reward 37.47,  223 frame/episode, eps 0.1, speed 64.11 f/s\n",
            "1193125 frames: done 4269 games, mean reward 37.79,  303 frame/episode, eps 0.1, speed 63.78 f/s\n",
            "1193982 frames: done 4272 games, mean reward 37.9,  285 frame/episode, eps 0.1, speed 63.6 f/s\n",
            "1194835 frames: done 4275 games, mean reward 38.27,  252 frame/episode, eps 0.1, speed 64.44 f/s\n",
            "1195674 frames: done 4278 games, mean reward 37.41,  377 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "1196494 frames: done 4281 games, mean reward 37.31,  282 frame/episode, eps 0.1, speed 64.41 f/s\n",
            "1197399 frames: done 4284 games, mean reward 37.08,  303 frame/episode, eps 0.1, speed 63.94 f/s\n",
            "1198170 frames: done 4287 games, mean reward 36.99,  290 frame/episode, eps 0.1, speed 63.56 f/s\n",
            "1199102 frames: done 4290 games, mean reward 37.22,  302 frame/episode, eps 0.1, speed 64.57 f/s\n",
            "1200118 frames: done 4293 games, mean reward 38.18,  490 frame/episode, eps 0.1, speed 63.99 f/s\n",
            "1200871 frames: done 4296 games, mean reward 37.82,  254 frame/episode, eps 0.1, speed 64.84 f/s\n",
            "1201684 frames: done 4299 games, mean reward 36.94,  263 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "1202431 frames: done 4302 games, mean reward 36.5,  256 frame/episode, eps 0.1, speed 64.87 f/s\n",
            "1203379 frames: done 4305 games, mean reward 36.4,  322 frame/episode, eps 0.1, speed 65.58 f/s\n",
            "1204028 frames: done 4308 games, mean reward 35.42,  273 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "1204899 frames: done 4311 games, mean reward 36.15,  248 frame/episode, eps 0.1, speed 64.61 f/s\n",
            "1205791 frames: done 4314 games, mean reward 36.73,  277 frame/episode, eps 0.1, speed 65.14 f/s\n",
            "1206567 frames: done 4317 games, mean reward 37.22,  291 frame/episode, eps 0.1, speed 64.74 f/s\n",
            "1207400 frames: done 4320 games, mean reward 37.69,  298 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "1208382 frames: done 4323 games, mean reward 36.33,  359 frame/episode, eps 0.1, speed 63.13 f/s\n",
            "1209184 frames: done 4326 games, mean reward 36.52,  306 frame/episode, eps 0.1, speed 64.28 f/s\n",
            "1210109 frames: done 4329 games, mean reward 36.34,  299 frame/episode, eps 0.1, speed 64.66 f/s\n",
            "1210897 frames: done 4332 games, mean reward 36.21,  319 frame/episode, eps 0.1, speed 63.33 f/s\n",
            "1211681 frames: done 4335 games, mean reward 36.21,  280 frame/episode, eps 0.1, speed 64.47 f/s\n",
            "1212440 frames: done 4338 games, mean reward 36.14,  211 frame/episode, eps 0.1, speed 63.29 f/s\n",
            "1213214 frames: done 4341 games, mean reward 36.11,  319 frame/episode, eps 0.1, speed 65.56 f/s\n",
            "1213965 frames: done 4344 games, mean reward 36.44,  260 frame/episode, eps 0.1, speed 64.82 f/s\n",
            "1214639 frames: done 4347 games, mean reward 35.8,  234 frame/episode, eps 0.1, speed 63.33 f/s\n",
            "1215458 frames: done 4350 games, mean reward 35.61,  250 frame/episode, eps 0.1, speed 64.61 f/s\n",
            "1216409 frames: done 4353 games, mean reward 36.01,  336 frame/episode, eps 0.1, speed 64.03 f/s\n",
            "1217249 frames: done 4356 games, mean reward 35.83,  232 frame/episode, eps 0.1, speed 64.29 f/s\n",
            "1218081 frames: done 4359 games, mean reward 36.23,  341 frame/episode, eps 0.1, speed 64.91 f/s\n",
            "1218932 frames: done 4362 games, mean reward 36.46,  317 frame/episode, eps 0.1, speed 64.79 f/s\n",
            "1219731 frames: done 4365 games, mean reward 36.26,  324 frame/episode, eps 0.1, speed 64.45 f/s\n",
            "1220567 frames: done 4368 games, mean reward 35.83,  284 frame/episode, eps 0.1, speed 63.74 f/s\n",
            "1221553 frames: done 4371 games, mean reward 36.1,  182 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "1222574 frames: done 4374 games, mean reward 37.64,  262 frame/episode, eps 0.1, speed 64.47 f/s\n",
            "1223276 frames: done 4377 games, mean reward 37.57,  237 frame/episode, eps 0.1, speed 64.69 f/s\n",
            "1223885 frames: done 4380 games, mean reward 37.23,  176 frame/episode, eps 0.1, speed 64.29 f/s\n",
            "1224668 frames: done 4383 games, mean reward 37.28,  245 frame/episode, eps 0.1, speed 63.84 f/s\n",
            "1225435 frames: done 4386 games, mean reward 37.09,  190 frame/episode, eps 0.1, speed 64.53 f/s\n",
            "1226366 frames: done 4389 games, mean reward 36.98,  232 frame/episode, eps 0.1, speed 65.01 f/s\n",
            "1227124 frames: done 4392 games, mean reward 37.2,  253 frame/episode, eps 0.1, speed 64.34 f/s\n",
            "1227895 frames: done 4395 games, mean reward 35.86,  262 frame/episode, eps 0.1, speed 64.5 f/s\n",
            "1228585 frames: done 4398 games, mean reward 36.02,  280 frame/episode, eps 0.1, speed 65.11 f/s\n",
            "  --Try 0: t=268, reward=38.0 Best reward updated\n",
            "  --Try 1: t=355, reward=71.0 Best reward updated\n",
            "  --Try 2: t=439, reward=43.0\n",
            "  --Try 3: t=525, reward=240.0 Best reward updated\n",
            "  --Try 4: t=368, reward=130.0\n",
            "  --Try 5: t=613, reward=200.0\n",
            "  --Try 6: t=346, reward=75.0\n",
            "  --Try 7: t=609, reward=112.0\n",
            "  --Try 8: t=468, reward=235.0\n",
            "  --Try 9: t=360, reward=28.0\n",
            "  --Generating animation..\n",
            " --Animationm from 526 frames with reward 240.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 37.1 -> 36.19, model saved\n",
            "1229449 frames: done 4401 games, mean reward 36.41,  304 frame/episode, eps 0.1, speed 2.87 f/s\n",
            "1230358 frames: done 4404 games, mean reward 36.9,  285 frame/episode, eps 0.1, speed 62.79 f/s\n",
            "1231105 frames: done 4407 games, mean reward 37.13,  242 frame/episode, eps 0.1, speed 66.06 f/s\n",
            "1232076 frames: done 4410 games, mean reward 38.44,  247 frame/episode, eps 0.1, speed 65.83 f/s\n",
            "1232779 frames: done 4413 games, mean reward 38.13,  227 frame/episode, eps 0.1, speed 64.23 f/s\n",
            "1233771 frames: done 4416 games, mean reward 38.53,  299 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "1234665 frames: done 4419 games, mean reward 38.35,  348 frame/episode, eps 0.1, speed 63.12 f/s\n",
            "1235642 frames: done 4422 games, mean reward 40.8,  523 frame/episode, eps 0.1, speed 64.74 f/s\n",
            "1236644 frames: done 4425 games, mean reward 42.53,  410 frame/episode, eps 0.1, speed 65.02 f/s\n",
            "1237432 frames: done 4428 games, mean reward 42.11,  257 frame/episode, eps 0.1, speed 65.33 f/s\n",
            "1238374 frames: done 4431 games, mean reward 42.01,  346 frame/episode, eps 0.1, speed 67.09 f/s\n",
            "1239183 frames: done 4434 games, mean reward 42.5,  234 frame/episode, eps 0.1, speed 66.29 f/s\n",
            "1239929 frames: done 4437 games, mean reward 42.52,  238 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1240762 frames: done 4440 games, mean reward 42.79,  297 frame/episode, eps 0.1, speed 66.22 f/s\n",
            "1241545 frames: done 4443 games, mean reward 43.31,  237 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "1242362 frames: done 4446 games, mean reward 43.6,  280 frame/episode, eps 0.1, speed 66.9 f/s\n",
            "1243036 frames: done 4449 games, mean reward 43.59,  199 frame/episode, eps 0.1, speed 66.48 f/s\n",
            "1243923 frames: done 4452 games, mean reward 44.1,  271 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "1244854 frames: done 4455 games, mean reward 44.64,  317 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "1245798 frames: done 4458 games, mean reward 46.84,  230 frame/episode, eps 0.1, speed 67.07 f/s\n",
            "1246604 frames: done 4461 games, mean reward 46.5,  287 frame/episode, eps 0.1, speed 66.38 f/s\n",
            "1247615 frames: done 4464 games, mean reward 48.67,  416 frame/episode, eps 0.1, speed 67.24 f/s\n",
            "1248227 frames: done 4467 games, mean reward 48.39,  251 frame/episode, eps 0.1, speed 67.17 f/s\n",
            "1249038 frames: done 4470 games, mean reward 48.02,  308 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "1249958 frames: done 4473 games, mean reward 46.18,  369 frame/episode, eps 0.1, speed 66.23 f/s\n",
            "1250716 frames: done 4476 games, mean reward 46.36,  230 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "1251564 frames: done 4479 games, mean reward 46.64,  238 frame/episode, eps 0.1, speed 66.46 f/s\n",
            "1252296 frames: done 4482 games, mean reward 46.97,  178 frame/episode, eps 0.1, speed 66.31 f/s\n",
            "1253182 frames: done 4485 games, mean reward 47.26,  306 frame/episode, eps 0.1, speed 65.02 f/s\n",
            "1253851 frames: done 4488 games, mean reward 47.03,  265 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "1254601 frames: done 4491 games, mean reward 46.83,  228 frame/episode, eps 0.1, speed 65.86 f/s\n",
            "1255428 frames: done 4494 games, mean reward 46.79,  195 frame/episode, eps 0.1, speed 65.83 f/s\n",
            "1256211 frames: done 4497 games, mean reward 47.31,  252 frame/episode, eps 0.1, speed 65.56 f/s\n",
            "1256953 frames: done 4500 games, mean reward 47.12,  274 frame/episode, eps 0.1, speed 66.27 f/s\n",
            "1257653 frames: done 4503 games, mean reward 46.14,  185 frame/episode, eps 0.1, speed 66.85 f/s\n",
            "1258307 frames: done 4506 games, mean reward 45.93,  219 frame/episode, eps 0.1, speed 67.0 f/s\n",
            "1258980 frames: done 4509 games, mean reward 44.5,  291 frame/episode, eps 0.1, speed 66.34 f/s\n",
            "1259623 frames: done 4512 games, mean reward 44.22,  180 frame/episode, eps 0.1, speed 66.41 f/s\n",
            "1260333 frames: done 4515 games, mean reward 43.73,  217 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "1261214 frames: done 4518 games, mean reward 43.38,  201 frame/episode, eps 0.1, speed 65.8 f/s\n",
            "1261823 frames: done 4521 games, mean reward 43.54,  189 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "1262545 frames: done 4524 games, mean reward 40.04,  235 frame/episode, eps 0.1, speed 66.67 f/s\n",
            "1263192 frames: done 4527 games, mean reward 38.0,  201 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "1263909 frames: done 4530 games, mean reward 37.55,  223 frame/episode, eps 0.1, speed 65.81 f/s\n",
            "1264637 frames: done 4533 games, mean reward 36.64,  269 frame/episode, eps 0.1, speed 65.41 f/s\n",
            "1265415 frames: done 4536 games, mean reward 36.52,  260 frame/episode, eps 0.1, speed 63.34 f/s\n",
            "1266105 frames: done 4539 games, mean reward 36.48,  214 frame/episode, eps 0.1, speed 62.58 f/s\n",
            "1267060 frames: done 4542 games, mean reward 36.05,  181 frame/episode, eps 0.1, speed 65.78 f/s\n",
            "1267811 frames: done 4545 games, mean reward 35.74,  178 frame/episode, eps 0.1, speed 65.62 f/s\n",
            "1268615 frames: done 4548 games, mean reward 35.88,  238 frame/episode, eps 0.1, speed 65.8 f/s\n",
            "1269486 frames: done 4551 games, mean reward 35.65,  317 frame/episode, eps 0.1, speed 65.54 f/s\n",
            "1270230 frames: done 4554 games, mean reward 35.01,  241 frame/episode, eps 0.1, speed 65.76 f/s\n",
            "1271036 frames: done 4557 games, mean reward 32.57,  172 frame/episode, eps 0.1, speed 65.72 f/s\n",
            "1271718 frames: done 4560 games, mean reward 32.52,  207 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "1272345 frames: done 4563 games, mean reward 31.58,  212 frame/episode, eps 0.1, speed 65.24 f/s\n",
            "1273211 frames: done 4566 games, mean reward 30.25,  262 frame/episode, eps 0.1, speed 64.68 f/s\n",
            "1273949 frames: done 4569 games, mean reward 30.3,  285 frame/episode, eps 0.1, speed 65.93 f/s\n",
            "1274659 frames: done 4572 games, mean reward 29.72,  222 frame/episode, eps 0.1, speed 66.27 f/s\n",
            "1275474 frames: done 4575 games, mean reward 30.11,  325 frame/episode, eps 0.1, speed 65.5 f/s\n",
            "1276274 frames: done 4578 games, mean reward 30.18,  294 frame/episode, eps 0.1, speed 65.21 f/s\n",
            "1276975 frames: done 4581 games, mean reward 29.41,  163 frame/episode, eps 0.1, speed 65.49 f/s\n",
            "1277884 frames: done 4584 games, mean reward 29.11,  293 frame/episode, eps 0.1, speed 66.56 f/s\n",
            "1278662 frames: done 4587 games, mean reward 29.4,  223 frame/episode, eps 0.1, speed 66.81 f/s\n",
            "1279642 frames: done 4590 games, mean reward 29.48,  276 frame/episode, eps 0.1, speed 65.84 f/s\n",
            "1280390 frames: done 4593 games, mean reward 29.26,  242 frame/episode, eps 0.1, speed 66.42 f/s\n",
            "1281372 frames: done 4596 games, mean reward 29.48,  363 frame/episode, eps 0.1, speed 66.19 f/s\n",
            "1282252 frames: done 4599 games, mean reward 31.56,  262 frame/episode, eps 0.1, speed 65.43 f/s\n",
            "  --Try 0: t=275, reward=48.0 Best reward updated\n",
            "  --Try 1: t=260, reward=39.0\n",
            "  --Try 2: t=361, reward=97.0 Best reward updated\n",
            "  --Try 3: t=462, reward=70.0\n",
            "  --Try 4: t=283, reward=41.0\n",
            "  --Try 5: t=313, reward=61.0\n",
            "  --Try 6: t=304, reward=50.0\n",
            "  --Try 7: t=342, reward=53.0\n",
            "  --Try 8: t=261, reward=23.0\n",
            "  --Try 9: t=282, reward=31.0\n",
            "  --Generating animation..\n",
            " --Animationm from 362 frames with reward 97.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New best mean reward 36.19 -> 31.38, model saved\n",
            "1283102 frames: done 4602 games, mean reward 31.33,  268 frame/episode, eps 0.1, speed 65.7 f/s\n",
            "1283979 frames: done 4605 games, mean reward 31.68,  394 frame/episode, eps 0.1, speed 66.65 f/s\n",
            "1284751 frames: done 4608 games, mean reward 32.05,  300 frame/episode, eps 0.1, speed 66.0 f/s\n",
            "1285601 frames: done 4611 games, mean reward 31.98,  337 frame/episode, eps 0.1, speed 65.81 f/s\n",
            "1286439 frames: done 4614 games, mean reward 31.88,  202 frame/episode, eps 0.1, speed 66.22 f/s\n",
            "1287431 frames: done 4617 games, mean reward 31.97,  309 frame/episode, eps 0.1, speed 65.92 f/s\n",
            "1288252 frames: done 4620 games, mean reward 32.67,  273 frame/episode, eps 0.1, speed 66.85 f/s\n",
            "1288944 frames: done 4623 games, mean reward 32.9,  207 frame/episode, eps 0.1, speed 66.92 f/s\n",
            "1289735 frames: done 4626 games, mean reward 33.39,  169 frame/episode, eps 0.1, speed 65.83 f/s\n",
            "1290514 frames: done 4629 games, mean reward 33.76,  235 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "1291330 frames: done 4632 games, mean reward 34.02,  288 frame/episode, eps 0.1, speed 65.96 f/s\n",
            "1292275 frames: done 4635 games, mean reward 34.37,  279 frame/episode, eps 0.1, speed 66.47 f/s\n",
            "1293109 frames: done 4638 games, mean reward 34.56,  268 frame/episode, eps 0.1, speed 65.43 f/s\n",
            "1293892 frames: done 4641 games, mean reward 34.55,  309 frame/episode, eps 0.1, speed 66.09 f/s\n",
            "1294754 frames: done 4644 games, mean reward 34.76,  363 frame/episode, eps 0.1, speed 66.6 f/s\n",
            "1295667 frames: done 4647 games, mean reward 35.42,  330 frame/episode, eps 0.1, speed 66.21 f/s\n",
            "1296495 frames: done 4650 games, mean reward 35.21,  286 frame/episode, eps 0.1, speed 66.92 f/s\n",
            "1297296 frames: done 4653 games, mean reward 34.88,  314 frame/episode, eps 0.1, speed 65.54 f/s\n",
            "1298084 frames: done 4656 games, mean reward 34.68,  240 frame/episode, eps 0.1, speed 65.45 f/s\n",
            "1298910 frames: done 4659 games, mean reward 35.18,  257 frame/episode, eps 0.1, speed 66.92 f/s\n",
            "1299678 frames: done 4662 games, mean reward 35.48,  284 frame/episode, eps 0.1, speed 66.51 f/s\n",
            "1300539 frames: done 4665 games, mean reward 35.58,  312 frame/episode, eps 0.1, speed 66.15 f/s\n",
            "1301339 frames: done 4668 games, mean reward 35.77,  250 frame/episode, eps 0.1, speed 63.9 f/s\n",
            "1302070 frames: done 4671 games, mean reward 35.68,  264 frame/episode, eps 0.1, speed 65.81 f/s\n",
            "1303033 frames: done 4674 games, mean reward 35.53,  358 frame/episode, eps 0.1, speed 66.64 f/s\n",
            "1303783 frames: done 4677 games, mean reward 35.26,  241 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1304664 frames: done 4680 games, mean reward 36.1,  246 frame/episode, eps 0.1, speed 65.4 f/s\n",
            "1305472 frames: done 4683 games, mean reward 36.63,  280 frame/episode, eps 0.1, speed 67.13 f/s\n",
            "1306233 frames: done 4686 games, mean reward 36.68,  229 frame/episode, eps 0.1, speed 66.08 f/s\n",
            "1307104 frames: done 4689 games, mean reward 37.23,  280 frame/episode, eps 0.1, speed 66.53 f/s\n",
            "1308133 frames: done 4692 games, mean reward 38.56,  310 frame/episode, eps 0.1, speed 66.3 f/s\n",
            "1309361 frames: done 4695 games, mean reward 42.14,  361 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1310275 frames: done 4698 games, mean reward 40.45,  228 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "1311100 frames: done 4701 games, mean reward 41.91,  239 frame/episode, eps 0.1, speed 65.99 f/s\n",
            "1311972 frames: done 4704 games, mean reward 42.1,  257 frame/episode, eps 0.1, speed 65.59 f/s\n",
            "1312679 frames: done 4707 games, mean reward 41.92,  191 frame/episode, eps 0.1, speed 64.8 f/s\n",
            "1313468 frames: done 4710 games, mean reward 41.47,  226 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "1314439 frames: done 4713 games, mean reward 44.52,  543 frame/episode, eps 0.1, speed 60.36 f/s\n",
            "1315167 frames: done 4716 games, mean reward 44.44,  218 frame/episode, eps 0.1, speed 61.06 f/s\n",
            "1316028 frames: done 4719 games, mean reward 44.65,  245 frame/episode, eps 0.1, speed 63.88 f/s\n",
            "1316746 frames: done 4722 games, mean reward 44.3,  259 frame/episode, eps 0.1, speed 62.6 f/s\n",
            "1317820 frames: done 4725 games, mean reward 44.39,  340 frame/episode, eps 0.1, speed 61.62 f/s\n",
            "1318629 frames: done 4728 games, mean reward 44.35,  343 frame/episode, eps 0.1, speed 61.49 f/s\n",
            "1319364 frames: done 4731 games, mean reward 44.31,  234 frame/episode, eps 0.1, speed 59.67 f/s\n",
            "1320172 frames: done 4734 games, mean reward 44.58,  406 frame/episode, eps 0.1, speed 61.31 f/s\n",
            "1321112 frames: done 4737 games, mean reward 45.23,  299 frame/episode, eps 0.1, speed 59.74 f/s\n",
            "1321983 frames: done 4740 games, mean reward 45.06,  231 frame/episode, eps 0.1, speed 62.33 f/s\n",
            "1322937 frames: done 4743 games, mean reward 45.79,  288 frame/episode, eps 0.1, speed 65.65 f/s\n",
            "1323890 frames: done 4746 games, mean reward 47.78,  392 frame/episode, eps 0.1, speed 65.12 f/s\n",
            "1324696 frames: done 4749 games, mean reward 47.63,  151 frame/episode, eps 0.1, speed 65.13 f/s\n",
            "1325582 frames: done 4752 games, mean reward 47.33,  309 frame/episode, eps 0.1, speed 65.1 f/s\n",
            "1326427 frames: done 4755 games, mean reward 47.45,  318 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "1327409 frames: done 4758 games, mean reward 47.78,  380 frame/episode, eps 0.1, speed 66.14 f/s\n",
            "1328243 frames: done 4761 games, mean reward 49.62,  221 frame/episode, eps 0.1, speed 62.13 f/s\n",
            "Game solved in 1328828 frames! Average score of 50.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADvElEQVR4nO3cMW7TYBiA4Rh1RpyAiYEjVBygysBl\n6Ak4QY+BOABDxMCIehjEgBADA2aioEp1oTa18/Z5Vud3/uHVF8dyMozjuIOKR2tvAJYkaFIETYqg\nSRE0KSdTB4dhcAuEzRnHcbjpmAlNiqBJETQpgiZl8kvhFl1cXPzzmvPz81nnuL5+qXPMtYU9XHd9\nT/fxnn8yoUk5ugl93f+Ynmt8CizhvqfhFpnQpBz9hOa32z4VHsIEN6FJMaGP2G0Td43r+LWZ0KQc\n/YReYgpt5RzH8J5bZ0KTImhShqlffXsemi3yPDQPxuSXQl86ODYmNCmCJkXQpAiaFEGTImhSBE2K\noEkRNCmCJkXQpAiaFEGTImhSZv2m8CH8zwP3b85jyyY0KYImRdCkCJoUQZMiaFIETYqgSRE0KYIm\nRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KbP+Oelyv19qH3Dl44y1JjQp\ngiZF0KQImhRBkzLrLsePZ1+W2gcswoQmRdCkCJoUQZMiaFIETcqs23afH39bah+wCBOaFEGTImhS\nBE2KoEmZd5fj+fel9gG/fbr7UhOaFEGTImhSBE2KoEmZdZfjzY+nS+0DrpzNWGtCkyJoUgRNiqBJ\nETQps+5yfH/7eqFtwB/O7v6HuiY0KYImRdCkCJoUQZMiaFJm3bb7cDhdah9w5eXZxZ3XmtCkCJoU\nQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYIm\nRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIEfYvL\n/X53ud+vvQ3+kqBJETQpgiblZO0NbN3p4bD2FvgHJjQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF\n0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJ\nETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpJ1MH3z35el/74Mhd\n7vezz3F6OOx2u93uxfv30y989erGQyY0KYImRdCkTF5Dw9/6df27NhOaFBOazblt2o8Tx4ZxvPnw\nMAxTa2EV4zgONx1zyUGKoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAialMnHR+HYmNCk\nCJoUQZMiaFIETYqgSfkJYelloK/FTmcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAvQkbaluvOo",
        "colab_type": "code",
        "outputId": "93687eb4-d6ed-4e5b-f772-5be11f353829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "w = 50\n",
        "plt.plot(np.convolve(np.array(total_rewards), np.ones(w), 'valid') / w)\n",
        "plt.title('Moving average of per episodes reward')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Moving average of per episodes reward')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6fo53FSECC_",
        "colab_type": "text"
      },
      "source": [
        "## Play"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixGvAEEnEBr2",
        "colab_type": "code",
        "outputId": "c6b7c115-9717-40e3-d938-ff4c06050096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(600, 400))\n",
        "display.start()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1000x800x24', ':1005'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1000x800x24', ':1005'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqxs77OIEC4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "58d51a62-72a9-42be-fd3b-247e2b7d34af"
      },
      "source": [
        "#create animation\n",
        "anim, t, tot_r = create_animation(net, args, epsilon = 0.05, device = device, try_num=10)\n",
        "#play mp4\n",
        "anim"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  --Try 0: t=287, reward=50.0 Best reward updated\n",
            "  --Try 1: t=228, reward=27.0\n",
            "  --Try 2: t=432, reward=219.0 Best reward updated\n",
            "  --Try 3: t=373, reward=101.0\n",
            "  --Try 4: t=432, reward=106.0\n",
            "  --Try 5: t=499, reward=240.0 Best reward updated\n",
            "  --Try 6: t=236, reward=36.0\n",
            "  --Try 7: t=278, reward=48.0\n",
            "  --Try 8: t=381, reward=66.0\n",
            "  --Try 9: t=262, reward=38.0\n",
            "  --Generating animation..\n",
            " --Animationm from 500 frames with reward 240.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADu0lEQVR4nO3dMW7TYBiAYYw6I07AxMAReoIqA5eh\nJ+AEPQbiAAwRAyPqYRADQgwMNVtbVdQttYmTN8+zOn/yD6++JJbjDOM4PoOK52tvAJYkaFIETYqg\nSRE0KSdTB4dhcAqEvTOO43DfMROaFEGTImhSBE3K5JfCfXRxcfHPa87Pz2c9x931Sz3HXPuwh7vu\n7mkXr3mbCU3KwU3ou/7H9FzjXWAJu56G+8iEJuXgJzQ3HnpXOIYJbkKTYkIfsIcm7hqf49dmQpNy\n8BN6iSm0L89xCK+570xoUgRNyjD1q2/XQ7OPXA/N0Zj8UuhLB4fGhCZF0KQImhRBkyJoUgRNiqBJ\nETQpgiZF0KQImhRBkyJoUgRNyqzfFB7DfR7YvTmXLZvQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAia\nFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpMy6c9LlZrPUPuDa1xlrTWhS\nBE2KoEkRNCmCJmXWWY6r1z+W2gcswoQmRdCkCJoUQZMiaFIETcqs03bfX/xaah+wCBOaFEGTImhS\nBE2KoEmZd5bjze+l9gE3vj19qQlNiqBJETQpgiZF0KTMOsvx4erVUvuAa2cz1prQpAiaFEGTImhS\nBE3KrLMcvz++X2gbcMvZ02+oa0KTImhSBE2KoEkRNCmCJmXWabsv29Ol9gHX3p5dPHmtCU2KoEkR\nNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhS\nBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAia\nFEGTImhSBE2KoEkRNCmCJkXQpBx90JebzbPLzWbtbbCQow+aFkGTImhSTtbewNpOt9u1t8CCTGhS\nBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAia\nFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTMvnHm59e/tzVPjgC\nl5vN4x74+fP08Xfv7j1kQpMiaFIETcrR/3k9u3O63T7qcY/+rP0XJjQpJjR756FJPk4cG8bx/sPD\nMEythVWM4zjcd8xHDlIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkTF4+CofGhCZF\n0KQImhRBkyJoUgRNyh9Xh2UWF+vvWQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXI0pUvpYvW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save to GDrive\n",
        "T=len(total_rewards)\n",
        "anim_save_file_name = os.path.join(SAVE_FOLDER, f'{args.env}-{T}-{t}frame_{tot_r}')\n",
        "anim.save(f'{anim_save_file_name}.mp4')\n",
        "anim.save(f'{anim_save_file_name}.gif', writer='animation.PillowWriter', fps=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}