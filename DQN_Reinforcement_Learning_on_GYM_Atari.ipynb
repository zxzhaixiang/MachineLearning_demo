{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN Reinforcement Learning on GYM Atari.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxzhaixiang/MachineLearning_demo/blob/master/DQN_Reinforcement_Learning_on_GYM_Atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQ8dw3q91LN",
        "colab_type": "text"
      },
      "source": [
        "# Download Pretrained Model\n",
        "This model is only trained to play Pong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yhcdlikck8-",
        "colab_type": "text"
      },
      "source": [
        "To keep Colab from timeout, Press F12 and paste the following JavaScript code the the console.\n",
        "\n",
        "```JavaScript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Working\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a0xunL8GJ_X",
        "colab_type": "text"
      },
      "source": [
        "# Colab Installs + Regular Imports\n",
        "If you're running this script outside of a notebook set Colab to 'False'\n",
        "gsync allows this notebook to save pretrained models directly to your Google Drive account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZCQ_tadt2Q1",
        "colab_type": "code",
        "outputId": "c7f96585-3de1-4d31-bc42-87d102d00015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=d696e40f93f0ec21009cf87c8b6d88b1d1a99365656623ee17e43e74de119f30\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 155.9 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbNWFaHAEGBi",
        "colab_type": "code",
        "outputId": "ef8d0913-8d72-4505-deb8-ed230c57efd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install torchviz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.3 [783 kB]\n",
            "Fetched 783 kB in 1s (1,087 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.3_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/69/ec/8221a07850d69fa3c57c02e526edd23d18c7c05d58ed103e3b19172757c1/PyVirtualDisplay-0.2.5-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/63/57755fadd28c989d578862f1ed7995348ed666333e03cdab6f6ea3f26ab0/EasyProcess-0.2.8-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.8 pyvirtualdisplay-0.2.5\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.3.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.17.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=9f0f22c36342e766406a6891f9a5aca2c403ef905ae0ad4394820fe7b3086b79\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Amw1q8s_2vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Colab PyTorch utilities\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "import gym\n",
        "import gym.spaces\n",
        "from torchsummary import summary\n",
        "from torchviz import make_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09pa4NBFugi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V19C0zuPAwff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bf5b90a-3fe2-467f-f535-8ea274bba8ec"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device is {}'.format(device))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_SWzWbBA0D3",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive to save/load model weights (Optional)\n",
        "It is time consuming to train reinforcement learning, even for such a simple game. Colab only gives us 12 hr of usage. Although it is enough for game like Breakout, we still want to save the model weight somewhere eles in case we want to do a hot restart. The simplest solution is to mount your google drive and save the model weight there. It is completely optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3WsPj1TA8_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5e06b5ab-71dc-4fc2-f92b-aedb71429ed5"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsn1-3JxBC6M",
        "colab_type": "text"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6r-2pymBywK",
        "colab_type": "text"
      },
      "source": [
        "Parameters\n",
        "* REPLAY_SIZE: Maximum number of experiences stored in replay memory\n",
        "* TARGET_UPDATE_FREQ: How many frames in between syncing target DQN with behaviour DQN\n",
        "* LEARNING_STARTS: Number of experiences to add to replay memory before training network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bypK0vuqBIgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENV_NAME = \"PongNoFrameskip-v4\"\n",
        "# MODEL = \"PretrainedModels/PongNoFrameskip-v4-407.dat\"\n",
        "ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
        "MODEL = \"BreakoutNoFrameskip-v4.dat\"\n",
        "GDRIVE_FOLDER = \"BreakoutModels\"\n",
        "\n",
        "MEAN_REWARD_BOUND = 50\n",
        "\n",
        "FRAME_SKIPPING = 8\n",
        "\n",
        "GAMMA = 0.95\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10 ** 5 * 2\n",
        "LEARNING_STARTS = 10**4 * 2\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "TARGET_UPDATE_FREQ = 10000\n",
        "\n",
        "EPSILON_DECAY = 10**5 * 5\n",
        "EPSILON_START = 0.9\n",
        "EPSILON_FINAL = 0.1\n",
        "\n",
        "MODEL_SAVE_STEP = 200 \n",
        "\n",
        "LOAD_MODEL_NAME = 'BreakoutNoFrameskip-v4-8600.dat' #set to null if cold start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_QwnCaBVz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_FOLDER = os.path.join('/content/drive/My Drive/',GDRIVE_FOLDER)\n",
        "if (not os.path.isdir(SAVE_FOLDER)):\n",
        "    os.mkdir(SAVE_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpp316gJGXZp",
        "colab_type": "text"
      },
      "source": [
        "# OpenAI Gym Wrappers\n",
        "These wrappers make it easier to interact with OpenAI Gym\n",
        "\n",
        "Wrappers include:\n",
        "\n",
        "\n",
        "*   Frame skipping\n",
        "*   Frame processing (downsampling and greyscaling)\n",
        "* Image normalization and converting to PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZyTsre_3lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taken from OpenAI baseline wrappers\n",
        "# https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
        "        super(FireResetEnv, self).__init__(env)\n",
        "        print(env.unwrapped.get_action_meanings())\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)\n",
        "\n",
        "    def reset(self):\n",
        "        self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        return obs\n",
        "\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Downsamples image to 84x84\n",
        "    Greyscales image\n",
        "\n",
        "    Returns numpy array\n",
        "    \"\"\"\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = np.reshape(frame, [210, 160, 3]).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
        "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env_name, frame_skip):\n",
        "    env = gym.make(env_name)\n",
        "    env = MaxAndSkipEnv(env,skip = frame_skip)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    return ScaledFloatFrame(env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyeLIpznGhBu",
        "colab_type": "text"
      },
      "source": [
        "# DQN Architecture\n",
        "Deep-Q-Networks (DQNs) are composed of: \n",
        "* 3 convolution layers\n",
        "* 2 fully-connected linear layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyvSSjc1GjIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9fVaD2M0wLc",
        "colab_type": "text"
      },
      "source": [
        "# Experience Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KVzom9K0zIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
        "\n",
        "\n",
        "class ExperienceReplay:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
        "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
        "               np.array(dones, dtype=np.uint8), np.array(next_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyc4Y9bB01t0",
        "colab_type": "text"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCPK9nrO05Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, env, replay_memory):\n",
        "        self.env = env\n",
        "        self.replay_memory = replay_memory\n",
        "        self._reset()\n",
        "        self.last_action = 0\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state = env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Select action\n",
        "        Execute action and step environment\n",
        "        Add state/action/reward to experience replay\n",
        "        \"\"\"\n",
        "        done_reward = None\n",
        "        if np.random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_a = np.array([self.state], copy=False)\n",
        "            state_v = torch.tensor(state_a).to(device)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        # do step in the environment\n",
        "        new_state, reward, is_done, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "        new_state = new_state\n",
        "\n",
        "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
        "        self.replay_memory.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dKt-mco0910",
        "colab_type": "text"
      },
      "source": [
        "# Loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ARCnK-B1C3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_loss(batch, net, target_net, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Calculate MSE between actual state action values,\n",
        "    and expected state action values from DQN\n",
        "    \"\"\"\n",
        "    states, actions, rewards, dones, next_states = batch\n",
        "\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "    done = torch.BoolTensor(dones).to(device)\n",
        "\n",
        "    state_action_values = net(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
        "    next_state_values = target_net(next_states_v).max(1)[0]\n",
        "    next_state_values[done] = 0.0\n",
        "    next_state_values = next_state_values.detach()\n",
        "\n",
        "    expected_state_action_values = next_state_values * GAMMA + rewards_v\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYEFJAn1FOK",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWejS6k7OIFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1cd1a9d-b585-4a93-9f87-2a7fba634d67"
      },
      "source": [
        "print(\"ReplayMemory will require {}gb of GPU RAM\".format(round(REPLAY_SIZE * 32 * 84 * 84 / 1e+9, 2)))\n",
        "class ColabArgParse():\n",
        "    def __init__(self, cuda, env, reward, model):\n",
        "        self.cuda = cuda\n",
        "        self.env = env\n",
        "        self.reward = reward\n",
        "        self.model = model\n",
        "\n",
        "args = ColabArgParse(device, ENV_NAME, MEAN_REWARD_BOUND, MODEL)\n",
        "\n",
        "env = make_env(args.env, frame_skip = FRAME_SKIPPING)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "target_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "\n",
        "replay_memory = ExperienceReplay(REPLAY_SIZE)\n",
        "agent = Agent(env, replay_memory)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "summary(net, env.observation_space.shape)\n",
        "print(net)\n",
        "make_dot(net(torch.zeros([1,*env.observation_space.shape]).to(device)), params=dict(net.named_parameters()))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ReplayMemory will require 45.16gb of GPU RAM\n",
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
            "              ReLU-2           [-1, 32, 20, 20]               0\n",
            "            Conv2d-3             [-1, 64, 9, 9]          32,832\n",
            "              ReLU-4             [-1, 64, 9, 9]               0\n",
            "            Conv2d-5             [-1, 64, 7, 7]          36,928\n",
            "              ReLU-6             [-1, 64, 7, 7]               0\n",
            "            Linear-7                  [-1, 512]       1,606,144\n",
            "              ReLU-8                  [-1, 512]               0\n",
            "            Linear-9                    [-1, 4]           2,052\n",
            "================================================================\n",
            "Total params: 1,686,180\n",
            "Trainable params: 1,686,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 0.33\n",
            "Params size (MB): 6.43\n",
            "Estimated Total Size (MB): 6.87\n",
            "----------------------------------------------------------------\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f6eb58fa5f8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"452pt\" height=\"690pt\"\n viewBox=\"0.00 0.00 452.00 690.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 686)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-686 448,-686 448,4 -4,4\"/>\n<!-- 140113469221464 -->\n<g id=\"node1\" class=\"node\">\n<title>140113469221464</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"356.5,-21 252.5,-21 252.5,0 356.5,0 356.5,-21\"/>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140113463386064 -->\n<g id=\"node2\" class=\"node\">\n<title>140113463386064</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"239.5,-91 183.5,-91 183.5,-57 239.5,-57 239.5,-91\"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.2.bias</text>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4)</text>\n</g>\n<!-- 140113463386064&#45;&gt;140113469221464 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140113463386064&#45;&gt;140113469221464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.4223,-56.9832C250.1045,-47.641 266.9893,-36.1122 280.5201,-26.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"282.5752,-29.7082 288.8602,-21.1788 278.628,-23.9273 282.5752,-29.7082\"/>\n</g>\n<!-- 140113463350496 -->\n<g id=\"node3\" class=\"node\">\n<title>140113463350496</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"351.5,-84.5 257.5,-84.5 257.5,-63.5 351.5,-63.5 351.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140113463350496&#45;&gt;140113469221464 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140113463350496&#45;&gt;140113469221464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M304.5,-63.2281C304.5,-54.5091 304.5,-41.9699 304.5,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.0001,-31.1128 304.5,-21.1128 301.0001,-31.1129 308.0001,-31.1128\"/>\n</g>\n<!-- 140113469428848 -->\n<g id=\"node4\" class=\"node\">\n<title>140113469428848</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"355.5,-154.5 251.5,-154.5 251.5,-133.5 355.5,-133.5 355.5,-154.5\"/>\n<text text-anchor=\"middle\" x=\"303.5\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140113469428848&#45;&gt;140113463350496 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140113469428848&#45;&gt;140113463350496</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M303.6519,-133.3685C303.7972,-123.1925 304.0206,-107.5606 304.2016,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.7034,-94.7806 304.3467,-84.7315 300.7041,-94.6805 307.7034,-94.7806\"/>\n</g>\n<!-- 140113469429520 -->\n<g id=\"node5\" class=\"node\">\n<title>140113469429520</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"239.5,-231 183.5,-231 183.5,-197 239.5,-197 239.5,-231\"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.0.bias</text>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140113469429520&#45;&gt;140113469428848 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140113469429520&#45;&gt;140113469428848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.2416,-196.6966C248.6068,-185.7666 267.0787,-171.7119 281.3325,-160.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.7491,-163.4258 289.5881,-154.5852 279.5104,-157.855 283.7491,-163.4258\"/>\n</g>\n<!-- 140113469332952 -->\n<g id=\"node6\" class=\"node\">\n<title>140113469332952</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"349,-224.5 258,-224.5 258,-203.5 349,-203.5 349,-224.5\"/>\n<text text-anchor=\"middle\" x=\"303.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 140113469332952&#45;&gt;140113469428848 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140113469332952&#45;&gt;140113469428848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M303.5,-203.3685C303.5,-193.1925 303.5,-177.5606 303.5,-164.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.0001,-164.7315 303.5,-154.7315 300.0001,-164.7316 307.0001,-164.7315\"/>\n</g>\n<!-- 140113469332224 -->\n<g id=\"node7\" class=\"node\">\n<title>140113469332224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"349.5,-294.5 255.5,-294.5 255.5,-273.5 349.5,-273.5 349.5,-294.5\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-280.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140113469332224&#45;&gt;140113469332952 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140113469332224&#45;&gt;140113469332952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.6519,-273.3685C302.7972,-263.1925 303.0206,-247.5606 303.2016,-234.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.7034,-234.7806 303.3467,-224.7315 299.7041,-234.6805 306.7034,-234.7806\"/>\n</g>\n<!-- 140115368511696 -->\n<g id=\"node8\" class=\"node\">\n<title>140115368511696</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"381,-358 224,-358 224,-337 381,-337 381,-358\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140115368511696&#45;&gt;140113469332224 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140115368511696&#45;&gt;140113469332224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.5,-336.7281C302.5,-328.0091 302.5,-315.4699 302.5,-304.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.0001,-304.6128 302.5,-294.6128 299.0001,-304.6129 306.0001,-304.6128\"/>\n</g>\n<!-- 140112259681080 -->\n<g id=\"node9\" class=\"node\">\n<title>140112259681080</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"242.5,-421.5 148.5,-421.5 148.5,-400.5 242.5,-400.5 242.5,-421.5\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140112259681080&#45;&gt;140115368511696 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140112259681080&#45;&gt;140115368511696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M213.6511,-400.2281C230.7399,-390.0866 256.5382,-374.7764 275.9401,-363.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.8036,-366.2263 284.617,-358.1128 274.2311,-360.2065 277.8036,-366.2263\"/>\n</g>\n<!-- 140112259680856 -->\n<g id=\"node10\" class=\"node\">\n<title>140112259680856</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"274,-485 117,-485 117,-464 274,-464 274,-485\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140112259680856&#45;&gt;140112259681080 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140112259680856&#45;&gt;140112259681080</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M195.5,-463.7281C195.5,-455.0091 195.5,-442.4699 195.5,-431.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0001,-431.6128 195.5,-421.6128 192.0001,-431.6129 199.0001,-431.6128\"/>\n</g>\n<!-- 140112259680744 -->\n<g id=\"node11\" class=\"node\">\n<title>140112259680744</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"135.5,-548.5 41.5,-548.5 41.5,-527.5 135.5,-527.5 135.5,-548.5\"/>\n<text text-anchor=\"middle\" x=\"88.5\" y=\"-534.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140112259680744&#45;&gt;140112259680856 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140112259680744&#45;&gt;140112259680856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.6511,-527.2281C123.7399,-517.0866 149.5382,-501.7764 168.9401,-490.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.8036,-493.2263 177.617,-485.1128 167.2311,-487.2065 170.8036,-493.2263\"/>\n</g>\n<!-- 140112259680408 -->\n<g id=\"node12\" class=\"node\">\n<title>140112259680408</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"167,-612 10,-612 10,-591 167,-591 167,-612\"/>\n<text text-anchor=\"middle\" x=\"88.5\" y=\"-598.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140112259680408&#45;&gt;140112259680744 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140112259680408&#45;&gt;140112259680744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M88.5,-590.7281C88.5,-582.0091 88.5,-569.4699 88.5,-558.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.0001,-558.6128 88.5,-548.6128 85.0001,-558.6129 92.0001,-558.6128\"/>\n</g>\n<!-- 140112259681304 -->\n<g id=\"node13\" class=\"node\">\n<title>140112259681304</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"83,-682 0,-682 0,-648 83,-648 83,-682\"/>\n<text text-anchor=\"middle\" x=\"41.5\" y=\"-668.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.0.weight</text>\n<text text-anchor=\"middle\" x=\"41.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 4, 8, 8)</text>\n</g>\n<!-- 140112259681304&#45;&gt;140112259680408 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140112259681304&#45;&gt;140112259680408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0951,-647.9832C60.3763,-639.4969 67.9931,-629.2062 74.4616,-620.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.3194,-622.4888 80.4555,-612.3687 71.6929,-618.3243 77.3194,-622.4888\"/>\n</g>\n<!-- 140112259681248 -->\n<g id=\"node14\" class=\"node\">\n<title>140112259681248</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"171.5,-682 101.5,-682 101.5,-648 171.5,-648 171.5,-682\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-668.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.0.bias</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-655.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140112259681248&#45;&gt;140112259680408 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140112259681248&#45;&gt;140112259680408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.6369,-647.9832C117.222,-639.4969 109.4433,-629.2062 102.8371,-620.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.5379,-618.2355 96.7157,-612.3687 99.9538,-622.4566 105.5379,-618.2355\"/>\n</g>\n<!-- 140112259680352 -->\n<g id=\"node15\" class=\"node\">\n<title>140112259680352</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"237,-555 154,-555 154,-521 237,-521 237,-555\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.2.weight</text>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 32, 4, 4)</text>\n</g>\n<!-- 140112259680352&#45;&gt;140112259680856 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140112259680352&#45;&gt;140112259680856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M195.5,-520.9832C195.5,-513.1157 195.5,-503.6973 195.5,-495.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0001,-495.3686 195.5,-485.3687 192.0001,-495.3687 199.0001,-495.3686\"/>\n</g>\n<!-- 140112259680632 -->\n<g id=\"node16\" class=\"node\">\n<title>140112259680632</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"325.5,-555 255.5,-555 255.5,-521 325.5,-521 325.5,-555\"/>\n<text text-anchor=\"middle\" x=\"290.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.2.bias</text>\n<text text-anchor=\"middle\" x=\"290.5\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140112259680632&#45;&gt;140112259680856 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140112259680632&#45;&gt;140112259680856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M265.0417,-520.9832C251.0653,-511.641 233.8174,-500.1122 219.9956,-490.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"221.735,-487.8261 211.4762,-485.1788 217.845,-493.6458 221.735,-487.8261\"/>\n</g>\n<!-- 140112259681024 -->\n<g id=\"node17\" class=\"node\">\n<title>140112259681024</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"344,-428 261,-428 261,-394 344,-394 344,-428\"/>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.4.weight</text>\n<text text-anchor=\"middle\" x=\"302.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 64, 3, 3)</text>\n</g>\n<!-- 140112259681024&#45;&gt;140115368511696 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140112259681024&#45;&gt;140115368511696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M302.5,-393.9832C302.5,-386.1157 302.5,-376.6973 302.5,-368.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.0001,-368.3686 302.5,-358.3687 299.0001,-368.3687 306.0001,-368.3686\"/>\n</g>\n<!-- 140112259680688 -->\n<g id=\"node18\" class=\"node\">\n<title>140112259680688</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"432.5,-428 362.5,-428 362.5,-394 432.5,-394 432.5,-428\"/>\n<text text-anchor=\"middle\" x=\"397.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv.4.bias</text>\n<text text-anchor=\"middle\" x=\"397.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140112259680688&#45;&gt;140115368511696 -->\n<g id=\"edge17\" class=\"edge\">\n<title>140112259680688&#45;&gt;140115368511696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M372.0417,-393.9832C358.0653,-384.641 340.8174,-373.1122 326.9956,-363.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"328.735,-360.8261 318.4762,-358.1788 324.845,-366.6458 328.735,-360.8261\"/>\n</g>\n<!-- 140113469333288 -->\n<g id=\"node19\" class=\"node\">\n<title>140113469333288</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"441,-224.5 368,-224.5 368,-203.5 441,-203.5 441,-224.5\"/>\n<text text-anchor=\"middle\" x=\"404.5\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140113469333288&#45;&gt;140113469428848 -->\n<g id=\"edge18\" class=\"edge\">\n<title>140113469333288&#45;&gt;140113469428848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M389.1603,-203.3685C372.6024,-191.8927 346.033,-173.4783 326.8726,-160.1988\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"328.8659,-157.3219 318.6532,-154.5022 324.8784,-163.0752 328.8659,-157.3219\"/>\n</g>\n<!-- 140115368549848 -->\n<g id=\"node20\" class=\"node\">\n<title>140115368549848</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"443,-301 368,-301 368,-267 443,-267 443,-301\"/>\n<text text-anchor=\"middle\" x=\"405.5\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.0.weight</text>\n<text text-anchor=\"middle\" x=\"405.5\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512, 3136)</text>\n</g>\n<!-- 140115368549848&#45;&gt;140113469333288 -->\n<g id=\"edge19\" class=\"edge\">\n<title>140115368549848&#45;&gt;140113469333288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M405.2528,-266.6966C405.1152,-257.0634 404.9429,-245.003 404.7979,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"408.2967,-234.7402 404.6542,-224.7913 401.2975,-234.8403 408.2967,-234.7402\"/>\n</g>\n<!-- 140113463417040 -->\n<g id=\"node21\" class=\"node\">\n<title>140113463417040</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"444,-84.5 371,-84.5 371,-63.5 444,-63.5 444,-84.5\"/>\n<text text-anchor=\"middle\" x=\"407.5\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140113463417040&#45;&gt;140113469221464 -->\n<g id=\"edge20\" class=\"edge\">\n<title>140113463417040&#45;&gt;140113469221464</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M390.0275,-63.2281C373.6519,-53.1325 348.9682,-37.9149 330.3209,-26.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.0636,-23.3814 321.7145,-21.1128 328.3901,-29.3401 332.0636,-23.3814\"/>\n</g>\n<!-- 140113469429464 -->\n<g id=\"node22\" class=\"node\">\n<title>140113469429464</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"443.5,-161 373.5,-161 373.5,-127 443.5,-127 443.5,-161\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc.2.weight</text>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4, 512)</text>\n</g>\n<!-- 140113469429464&#45;&gt;140113463417040 -->\n<g id=\"edge21\" class=\"edge\">\n<title>140113469429464&#45;&gt;140113463417040</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M408.2528,-126.6966C408.1152,-117.0634 407.9429,-105.003 407.7979,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"411.2967,-94.7402 407.6542,-84.7913 404.2975,-94.8403 411.2967,-94.7402\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnN8eLhjQR4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07388c5e-d118-4bca-dd86-e6b5632be922"
      },
      "source": [
        "if LOAD_MODEL_NAME:\n",
        "    net.load_state_dict(torch.load(os.path.join(SAVE_FOLDER, LOAD_MODEL_NAME)))\n",
        "    target_net.load_state_dict(net.state_dict())\n",
        "    total_rewards = pickle.load(open(os.path.join(SAVE_FOLDER, 'output.pkl'), 'rb'))\n",
        "    print(\"Models loaded from Google Drive!\")\n",
        "    # Lower exploration rate IMPORTANT\n",
        "    EPSILON_START = EPSILON_FINAL\n",
        "    print(f'Set epsilon start as {EPSILON_START}')\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Models loaded from Google Drive!\n",
            "Set epsilon start as 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cGRFQ49ySq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_animation(net, args, epsilon = 0.05, device = 'cuda', try_num = 10):\n",
        "\n",
        "    def display_frames_as_gif(frames):\n",
        "        \"\"\"\n",
        "        Displays a list of frames as a gif, with controls\n",
        "        \"\"\"\n",
        "        #plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 72)\n",
        "        patch = plt.imshow(frames[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "        def animate(i):\n",
        "            patch.set_data(frames[i])\n",
        "\n",
        "        anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=100)\n",
        "        rc('animation', html='jshtml')\n",
        "        return anim\n",
        "\n",
        "    best_reward, best_frames = -100, None\n",
        "    for i in range(try_num):\n",
        "        agent._reset()\n",
        "        frames = []\n",
        "        for t in range(1000):\n",
        "            tmp_reward = agent.play_step(net, epsilon = 0.05, device = device)\n",
        "            frames.append(agent.env.render(mode = 'rgb_array'))\n",
        "            if tmp_reward is not None:\n",
        "                break\n",
        "        print(f'  --Try {i}: t={t}, reward={tmp_reward}', end = '')\n",
        "        if tmp_reward is not None and tmp_reward>best_reward:\n",
        "            best_reward = tmp_reward\n",
        "            best_frames = frames.copy()\n",
        "            best_t = t\n",
        "            print(f' Best reward updated')\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    print('  --Generating animation..')\n",
        "    anim = display_frames_as_gif(best_frames)\n",
        "    print(f' --Animationm from {len(best_frames)} frames with reward {best_reward} generated')\n",
        "    return anim, len(best_frames), best_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxf6rZ3Q9Z-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model_animation(net, args, T):\n",
        "    torch.save(net.state_dict(), f'{args.env}-{T}.dat')\n",
        "    torch.save(net.state_dict(), os.path.join(SAVE_FOLDER, f'{args.env}-{T}.dat'))\n",
        "    pickle.dump(total_rewards,open(os.path.join(SAVE_FOLDER, 'output.pkl'),'wb'))\n",
        "\n",
        "    anim, t, tot_r = create_animation(net, args, epsilon = 0.05, device = device, try_num=10)\n",
        "\n",
        "    anim_save_file_name = os.path.join(SAVE_FOLDER, f'{args.env}-{T}-{t}frame_{tot_r}')\n",
        "    anim.save(f'{anim_save_file_name}.mp4')\n",
        "    anim.save(f'{anim_save_file_name}.gif', writer='matplotlib.animation.PillowWriter', fps=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFWrNxvRTL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay = 5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDZ6Kub4Gopl",
        "colab_type": "code",
        "outputId": "b7a5af90-b90c-4a22-eaf7-2a66cf9ff806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "total_rewards = []\n",
        "best_mean_reward = None\n",
        "frame_idx = 0\n",
        "timestep_frame = 0\n",
        "timestep = time.time()\n",
        "\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY)\n",
        "\n",
        "    reward = agent.play_step(net, epsilon, device=device)\n",
        "\n",
        "    if reward is not None: #episode finished\n",
        "        total_rewards.append(reward)\n",
        "        delta_frame = frame_idx - timestep_frame\n",
        "        speed = delta_frame / (time.time() - timestep)\n",
        "        timestep_frame = frame_idx\n",
        "        timestep = time.time()\n",
        "        mean_reward = np.mean(total_rewards[-100:])\n",
        "        if (len(total_rewards)%3==0):\n",
        "            print(f\"{frame_idx} frames: done {len(total_rewards)} games, mean reward {round(mean_reward,3)}, \",\n",
        "                    f\"{delta_frame:3d} frame/episode, eps {round(epsilon,3)}, speed {round(speed,2)} f/s\")\n",
        "\n",
        "        #if (best_mean_reward is None or best_mean_reward < mean_reward) and len(total_rewards) % MODEL_SAVE_STEP == 0:\n",
        "        if len(total_rewards) % MODEL_SAVE_STEP == 0:\n",
        "            save_model_animation(net, args, len(total_rewards))\n",
        "            if best_mean_reward is not None:\n",
        "                print(\"New best mean reward {} -> {}, model saved\".format(round(best_mean_reward, 3), round(mean_reward, 3)))\n",
        "            best_mean_reward = mean_reward\n",
        "        if mean_reward > args.reward and len(total_rewards) > 10:\n",
        "            print(\"Game solved in {} frames! Average score of {}\".format(frame_idx, mean_reward))\n",
        "            break\n",
        "\n",
        "    if len(replay_memory) < LEARNING_STARTS:\n",
        "        continue\n",
        "\n",
        "    if frame_idx % TARGET_UPDATE_FREQ == 0:\n",
        "        target_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = replay_memory.sample(BATCH_SIZE)\n",
        "    loss_t = calculate_loss(batch, net, target_net, device=device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "env.close()\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1088 frames: done 3 games, mean reward 26.0,  308 frame/episode, eps 0.1, speed 259.03 f/s\n",
            "1906 frames: done 6 games, mean reward 22.833,  238 frame/episode, eps 0.1, speed 266.13 f/s\n",
            "2773 frames: done 9 games, mean reward 22.222,  340 frame/episode, eps 0.1, speed 256.19 f/s\n",
            "3755 frames: done 12 games, mean reward 21.833,  426 frame/episode, eps 0.1, speed 261.55 f/s\n",
            "4612 frames: done 15 games, mean reward 23.333,  304 frame/episode, eps 0.1, speed 267.21 f/s\n",
            "5568 frames: done 18 games, mean reward 23.333,  389 frame/episode, eps 0.1, speed 258.14 f/s\n",
            "6457 frames: done 21 games, mean reward 23.524,  377 frame/episode, eps 0.1, speed 260.05 f/s\n",
            "7670 frames: done 24 games, mean reward 24.333,  307 frame/episode, eps 0.1, speed 252.0 f/s\n",
            "8705 frames: done 27 games, mean reward 24.593,  280 frame/episode, eps 0.1, speed 254.32 f/s\n",
            "9705 frames: done 30 games, mean reward 24.733,  270 frame/episode, eps 0.1, speed 253.04 f/s\n",
            "10667 frames: done 33 games, mean reward 25.97,  322 frame/episode, eps 0.1, speed 257.85 f/s\n",
            "11725 frames: done 36 games, mean reward 26.417,  309 frame/episode, eps 0.1, speed 248.04 f/s\n",
            "12622 frames: done 39 games, mean reward 26.564,  182 frame/episode, eps 0.1, speed 243.12 f/s\n",
            "13498 frames: done 42 games, mean reward 26.643,  252 frame/episode, eps 0.1, speed 254.74 f/s\n",
            "14453 frames: done 45 games, mean reward 26.778,  308 frame/episode, eps 0.1, speed 249.89 f/s\n",
            "15294 frames: done 48 games, mean reward 27.042,  241 frame/episode, eps 0.1, speed 250.82 f/s\n",
            "16114 frames: done 51 games, mean reward 27.02,  374 frame/episode, eps 0.1, speed 251.89 f/s\n",
            "17139 frames: done 54 games, mean reward 26.648,  140 frame/episode, eps 0.1, speed 253.62 f/s\n",
            "18037 frames: done 57 games, mean reward 27.544,  309 frame/episode, eps 0.1, speed 233.85 f/s\n",
            "19455 frames: done 60 games, mean reward 28.383,  504 frame/episode, eps 0.1, speed 250.09 f/s\n",
            "20570 frames: done 63 games, mean reward 28.254,  415 frame/episode, eps 0.1, speed 68.38 f/s\n",
            "21676 frames: done 66 games, mean reward 28.258,  438 frame/episode, eps 0.1, speed 71.22 f/s\n",
            "22762 frames: done 69 games, mean reward 28.638,  363 frame/episode, eps 0.1, speed 67.94 f/s\n",
            "23626 frames: done 72 games, mean reward 29.0,  339 frame/episode, eps 0.1, speed 68.74 f/s\n",
            "24692 frames: done 75 games, mean reward 28.68,  361 frame/episode, eps 0.1, speed 68.27 f/s\n",
            "25539 frames: done 78 games, mean reward 28.436,  189 frame/episode, eps 0.1, speed 66.89 f/s\n",
            "26425 frames: done 81 games, mean reward 28.383,  160 frame/episode, eps 0.1, speed 70.7 f/s\n",
            "27169 frames: done 84 games, mean reward 28.107,  252 frame/episode, eps 0.1, speed 68.41 f/s\n",
            "28145 frames: done 87 games, mean reward 28.402,  418 frame/episode, eps 0.1, speed 69.32 f/s\n",
            "29220 frames: done 90 games, mean reward 28.367,  378 frame/episode, eps 0.1, speed 70.56 f/s\n",
            "30110 frames: done 93 games, mean reward 28.505,  299 frame/episode, eps 0.1, speed 64.49 f/s\n",
            "31292 frames: done 96 games, mean reward 28.76,  430 frame/episode, eps 0.1, speed 66.78 f/s\n",
            "32111 frames: done 99 games, mean reward 28.626,  250 frame/episode, eps 0.1, speed 68.28 f/s\n",
            "33122 frames: done 102 games, mean reward 28.91,  453 frame/episode, eps 0.1, speed 69.0 f/s\n",
            "33991 frames: done 105 games, mean reward 29.14,  266 frame/episode, eps 0.1, speed 69.43 f/s\n",
            "34957 frames: done 108 games, mean reward 29.82,  386 frame/episode, eps 0.1, speed 69.71 f/s\n",
            "36321 frames: done 111 games, mean reward 30.23,  296 frame/episode, eps 0.1, speed 67.91 f/s\n",
            "37389 frames: done 114 games, mean reward 30.58,  508 frame/episode, eps 0.1, speed 67.62 f/s\n",
            "38633 frames: done 117 games, mean reward 30.76,  296 frame/episode, eps 0.1, speed 67.02 f/s\n",
            "39499 frames: done 120 games, mean reward 30.84,  237 frame/episode, eps 0.1, speed 67.23 f/s\n",
            "40406 frames: done 123 games, mean reward 30.66,  280 frame/episode, eps 0.1, speed 66.61 f/s\n",
            "41249 frames: done 126 games, mean reward 30.45,  298 frame/episode, eps 0.1, speed 64.94 f/s\n",
            "42129 frames: done 129 games, mean reward 30.51,  187 frame/episode, eps 0.1, speed 67.79 f/s\n",
            "43140 frames: done 132 games, mean reward 30.6,  453 frame/episode, eps 0.1, speed 67.81 f/s\n",
            "44223 frames: done 135 games, mean reward 30.55,  489 frame/episode, eps 0.1, speed 66.72 f/s\n",
            "45283 frames: done 138 games, mean reward 30.31,  372 frame/episode, eps 0.1, speed 65.76 f/s\n",
            "45935 frames: done 141 games, mean reward 29.96,  221 frame/episode, eps 0.1, speed 68.48 f/s\n",
            "46995 frames: done 144 games, mean reward 30.22,  383 frame/episode, eps 0.1, speed 68.52 f/s\n",
            "47795 frames: done 147 games, mean reward 30.28,  283 frame/episode, eps 0.1, speed 66.74 f/s\n",
            "48481 frames: done 150 games, mean reward 30.29,  256 frame/episode, eps 0.1, speed 66.07 f/s\n",
            "49351 frames: done 153 games, mean reward 29.94,  310 frame/episode, eps 0.1, speed 67.49 f/s\n",
            "49966 frames: done 156 games, mean reward 29.55,  288 frame/episode, eps 0.1, speed 66.1 f/s\n",
            "50886 frames: done 159 games, mean reward 28.69,  246 frame/episode, eps 0.1, speed 65.86 f/s\n",
            "51858 frames: done 162 games, mean reward 28.53,  284 frame/episode, eps 0.1, speed 64.57 f/s\n",
            "52757 frames: done 165 games, mean reward 28.38,  397 frame/episode, eps 0.1, speed 65.35 f/s\n",
            "53599 frames: done 168 games, mean reward 27.83,  295 frame/episode, eps 0.1, speed 66.93 f/s\n",
            "54585 frames: done 171 games, mean reward 27.62,  383 frame/episode, eps 0.1, speed 65.27 f/s\n",
            "55731 frames: done 174 games, mean reward 27.74,  332 frame/episode, eps 0.1, speed 65.87 f/s\n",
            "56597 frames: done 177 games, mean reward 27.87,  258 frame/episode, eps 0.1, speed 65.11 f/s\n",
            "57342 frames: done 180 games, mean reward 27.73,  323 frame/episode, eps 0.1, speed 63.81 f/s\n",
            "58312 frames: done 183 games, mean reward 28.37,  267 frame/episode, eps 0.1, speed 66.02 f/s\n",
            "59169 frames: done 186 games, mean reward 28.01,  228 frame/episode, eps 0.1, speed 65.73 f/s\n",
            "59981 frames: done 189 games, mean reward 27.7,  329 frame/episode, eps 0.1, speed 64.77 f/s\n",
            "60935 frames: done 192 games, mean reward 27.65,  384 frame/episode, eps 0.1, speed 67.7 f/s\n",
            "61755 frames: done 195 games, mean reward 27.59,  257 frame/episode, eps 0.1, speed 64.08 f/s\n",
            "62593 frames: done 198 games, mean reward 27.1,  287 frame/episode, eps 0.1, speed 65.61 f/s\n",
            "Try 0: t=387, reward=22.0\n",
            "  update best reward\n",
            "Try 1: t=367, reward=37.0\n",
            "  update best reward\n",
            "Try 2: t=372, reward=27.0\n",
            "Try 3: t=235, reward=13.0\n",
            "Try 4: t=462, reward=25.0\n",
            "Try 5: t=213, reward=17.0\n",
            "Try 6: t=246, reward=13.0\n",
            "Try 7: t=261, reward=19.0\n",
            "Try 8: t=432, reward=38.0\n",
            "  update best reward\n",
            "Try 9: t=234, reward=9.0\n",
            "Generating animation..\n",
            "Animationm from 433 frames with reward 38.0 generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter matplotlib.animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "63809 frames: done 201 games, mean reward 27.07,  234 frame/episode, eps 0.1, speed 8.46 f/s\n",
            "64727 frames: done 204 games, mean reward 26.6,  291 frame/episode, eps 0.1, speed 62.76 f/s\n",
            "65468 frames: done 207 games, mean reward 26.11,  204 frame/episode, eps 0.1, speed 63.46 f/s\n",
            "66620 frames: done 210 games, mean reward 26.4,  345 frame/episode, eps 0.1, speed 64.59 f/s\n",
            "67573 frames: done 213 games, mean reward 25.99,  270 frame/episode, eps 0.1, speed 63.36 f/s\n",
            "68343 frames: done 216 games, mean reward 25.65,  246 frame/episode, eps 0.1, speed 64.36 f/s\n",
            "69078 frames: done 219 games, mean reward 25.21,  358 frame/episode, eps 0.1, speed 64.18 f/s\n",
            "70007 frames: done 222 games, mean reward 25.25,  352 frame/episode, eps 0.1, speed 63.53 f/s\n",
            "70881 frames: done 225 games, mean reward 25.17,  368 frame/episode, eps 0.1, speed 62.96 f/s\n",
            "71594 frames: done 228 games, mean reward 24.94,  184 frame/episode, eps 0.1, speed 66.03 f/s\n",
            "72516 frames: done 231 games, mean reward 25.32,  350 frame/episode, eps 0.1, speed 64.57 f/s\n",
            "73350 frames: done 234 games, mean reward 25.32,  213 frame/episode, eps 0.1, speed 62.65 f/s\n",
            "74208 frames: done 237 games, mean reward 25.45,  264 frame/episode, eps 0.1, speed 63.52 f/s\n",
            "75315 frames: done 240 games, mean reward 25.66,  347 frame/episode, eps 0.1, speed 63.35 f/s\n",
            "76316 frames: done 243 games, mean reward 25.93,  372 frame/episode, eps 0.1, speed 63.56 f/s\n",
            "77391 frames: done 246 games, mean reward 26.02,  335 frame/episode, eps 0.1, speed 55.43 f/s\n",
            "78178 frames: done 249 games, mean reward 26.01,  281 frame/episode, eps 0.1, speed 66.73 f/s\n",
            "79147 frames: done 252 games, mean reward 26.19,  368 frame/episode, eps 0.1, speed 65.19 f/s\n",
            "79901 frames: done 255 games, mean reward 26.61,  170 frame/episode, eps 0.1, speed 63.74 f/s\n",
            "80824 frames: done 258 games, mean reward 26.39,  277 frame/episode, eps 0.1, speed 63.25 f/s\n",
            "81732 frames: done 261 games, mean reward 26.59,  249 frame/episode, eps 0.1, speed 61.52 f/s\n",
            "82689 frames: done 264 games, mean reward 26.97,  325 frame/episode, eps 0.1, speed 66.39 f/s\n",
            "83471 frames: done 267 games, mean reward 27.18,  219 frame/episode, eps 0.1, speed 63.1 f/s\n",
            "84239 frames: done 270 games, mean reward 27.1,  179 frame/episode, eps 0.1, speed 66.54 f/s\n",
            "85227 frames: done 273 games, mean reward 26.96,  395 frame/episode, eps 0.1, speed 64.48 f/s\n",
            "86151 frames: done 276 games, mean reward 26.91,  381 frame/episode, eps 0.1, speed 62.28 f/s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-5f8bd04bed62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-f1e349eb39c5>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADvElEQVR4nO3cMW7TYBiA4Rh1RpyAiYEjVBygysBl\n6Ak4QY+BOABDxMCIehjEgBADA2aioEp1oTa18/Z5Vud3/uHVF8dyMozjuIOKR2tvAJYkaFIETYqg\nSRE0KSdTB4dhcAuEzRnHcbjpmAlNiqBJETQpgiZl8kvhFl1cXPzzmvPz81nnuL5+qXPMtYU9XHd9\nT/fxnn8yoUk5ugl93f+Ynmt8CizhvqfhFpnQpBz9hOa32z4VHsIEN6FJMaGP2G0Td43r+LWZ0KQc\n/YReYgpt5RzH8J5bZ0KTImhShqlffXsemi3yPDQPxuSXQl86ODYmNCmCJkXQpAiaFEGTImhSBE2K\noEkRNCmCJkXQpAiaFEGTImhSZv2m8CH8zwP3b85jyyY0KYImRdCkCJoUQZMiaFIETYqgSRE0KYIm\nRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KbP+Oelyv19qH3Dl44y1JjQp\ngiZF0KQImhRBkzLrLsePZ1+W2gcswoQmRdCkCJoUQZMiaFIETcqs23afH39bah+wCBOaFEGTImhS\nBE2KoEmZd5fj+fel9gG/fbr7UhOaFEGTImhSBE2KoEmZdZfjzY+nS+0DrpzNWGtCkyJoUgRNiqBJ\nETQps+5yfH/7eqFtwB/O7v6HuiY0KYImRdCkCJoUQZMiaFJm3bb7cDhdah9w5eXZxZ3XmtCkCJoU\nQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYIm\nRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIEfYvL\n/X53ud+vvQ3+kqBJETQpgiblZO0NbN3p4bD2FvgHJjQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF\n0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJ\nETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpJ1MH3z35el/74Mhd\n7vezz3F6OOx2u93uxfv30y989erGQyY0KYImRdCkTF5Dw9/6df27NhOaFBOazblt2o8Tx4ZxvPnw\nMAxTa2EV4zgONx1zyUGKoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAialMnHR+HYmNCk\nCJoUQZMiaFIETYqgSfkJYelloK/FTmcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAvQkbaluvOo",
        "colab_type": "code",
        "outputId": "a0f2c017-75dd-46ea-861d-9d0a509508c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "w = 50\n",
        "plt.plot(np.convolve(np.array(total_rewards), np.ones(w), 'valid') / w)\n",
        "plt.title('Moving average of per episodes reward')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Moving average of per episodes reward')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUv4fMI21qwpBstAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6fo53FSECC_",
        "colab_type": "text"
      },
      "source": [
        "## Play"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixGvAEEnEBr2",
        "colab_type": "code",
        "outputId": "fe3a9174-3fc5-4a37-a003-b12033d9ffa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(600, 400))\n",
        "display.start()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '600x400x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '600x400x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqxs77OIEC4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "a8df3c77-f8db-4eff-aa58-15f60c5cca02"
      },
      "source": [
        "anim, t, tot_r = create_animation(net, args, epsilon = 0.05, device = device, try_num=10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Try 0: t=387, reward=25.0\n",
            "  update best reward\n",
            "Try 1: t=326, reward=42.0\n",
            "  update best reward\n",
            "Try 2: t=387, reward=25.0\n",
            "Try 3: t=387, reward=25.0\n",
            "Try 4: t=387, reward=25.0\n",
            "Try 5: t=382, reward=38.0\n",
            "Try 6: t=567, reward=25.0\n",
            "Try 7: t=611, reward=25.0\n",
            "Try 8: t=387, reward=25.0\n",
            "Try 9: t=310, reward=17.0\n",
            "generating animationm from 327 frames with reward 42.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "MovieWriter animation.PillowWriter unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADvElEQVR4nO3dMW7TYBiA4Rp1RpyAiYEjVBygysBl\n6Ak4QY+BOABD1YER9TCIASGGDjVbW1WqK2o3Tt48z+r8zj+8+pJYTjKM43gEFa/W3gAsSdCkCJoU\nQZMiaFKOpw4Ow+ASCDtnHMfhsWMmNCmCJkXQpAialMkPhbvo/Pz8v9ecnZ3NOsfD9UudY65d2MND\nD/e0jee8z4QmZe8m9EMvMT3XeBVYwran4S4yoUnZ+wnNnadeFQ5hgpvQpJjQe+ypibvG+/i1mdCk\n7P2EXmIK7co59uE5d50JTYqgSRmmvvXtfmh2kfuhORiTHwp96GDfmNCkCJoUQZMiaFIETYqgSRE0\nKYImRdCkCJoUQZMiaFIETYqgSZn1ncJD+J0Htm/ObcsmNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmC\nJkXQpAiaFEGTImhSBE2KoEkRNCmCJkXQpAiaFEGTImhSBE2KoEkRNCmzfjnparNZah9w68eMtSY0\nKYImRdCkCJoUQZMy6yrHzbvfS+0DFmFCkyJoUgRNiqBJETQpgiZl1mW7X6//LrUPWIQJTYqgSRE0\nKYImRdCkzLvK8f56qX3AnZ/PX2pCkyJoUgRNiqBJETQps65yfLl5u9Q+4NbpjLUmNCmCJkXQpAia\nFEGTMusqx/XXzwttA+45ff4P6prQpAiaFEGTImhSBE2KoEmZddnu+8XJUvuAWx9Pz5+91oQmRdCk\nCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0\nKYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIE\nTYqgSRE0KYImRdCkCJoUQZMiaFIOPuirzeboarNZexss5OCDpkXQpAialOO1N7C2k4uLtbfAgkxo\nUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQI\nmhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkyJoUgRNiqBJETQpgiZF0KQImhRBkzL5x5vf3vzZ1j54\nYVebzexzbOtPSj9cXk4/4NOnRw+Z0KQImhRBk3Lwf15/KLb1/ndtJjQpJjQ756lXk3Hi2DCOjx8e\nhmFqLaxiHMfhsWPecpAiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImZfL2Udg3JjQp\ngiZF0KQImhRBkyJoUv4BWEtloMReNGUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXI0pUvpYvW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T=len(total_rewards)\n",
        "anim_save_file_name = os.path.join(SAVE_FOLDER, f'{args.env}-{T}-{t}frame_{tot_r}')\n",
        "anim.save(f'{anim_save_file_name}.mp4')\n",
        "anim.save(f'{anim_save_file_name}.gif', writer='animation.PillowWriter', fps=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}